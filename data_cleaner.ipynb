{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Notebook\n",
    "\n",
    "### This notebook cleans and merges stock-related data and general Reddit posts.\n",
    "### The process is divided into the following sections:\n",
    "###  1. Data Imports and Setup\n",
    "###  2. Data Cleaning for Stock Posts and Comments\n",
    "###  3. Merging and Exporting the Final DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Imports and Setup for Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posts\n",
    "# Subreddit -- Wall Street Bets Posts\n",
    "ws_stock_post = pd.read_csv('./reddit_stock/wallstreetbets/wallstreetbets_stocks_posts.csv') \n",
    "# Subreddit -- Stocks Posts\n",
    "stocks_post = pd.read_csv('./reddit_stock/stocks/stocks_stocks_posts.csv')\n",
    "# General Posts across subreddits\n",
    "posts = pd.read_csv('./reddit_general/all_posts.csv')\n",
    "\n",
    "#Comments\n",
    "# Subreddit -- Wall Street Bets comments\n",
    "wall_street_comments = pd.read_csv('./reddit_stock/wallstreetbets/wallstreetbets_stocks_comments.csv')\n",
    "# Subreddit -- Stocks comments\n",
    "stocks_comments = pd.read_csv('./reddit_stock/stocks/stocks_stocks_comments.csv')\n",
    "# Subreddit -- Stocks comments\n",
    "comments = pd.read_csv('./reddit_general/all_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Data Cleaning for Posts and Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure that there are no unnecessary Empty Cells\n",
    "ws_stock_post = ws_stock_post.dropna(subset='search_term')\n",
    "stocks_post = stocks_post.dropna(subset='search_term')\n",
    "posts = posts.dropna(subset='search_term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the 'score' column is numeric\n",
    "wall_street_comments['score'] = pd.to_numeric(wall_street_comments['score'])\n",
    "stocks_comments['score'] = pd.to_numeric(stocks_comments['score'])\n",
    "comments['score'] = pd.to_numeric(comments['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each DataFrame, I am grouping the data by the 'post_id' column.\n",
    "Within each group, I am sorting the rows by the 'score' column and selecting the top 10 rows for each group.\n",
    "In this case each post will have the top comments to it to add more context to our analysis later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/q70p80s12nz5lpzr087614lw0000gn/T/ipykernel_68016/864448817.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  wall_street_comments = wall_street_comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(10)).reset_index(drop=True)\n",
      "/var/folders/0w/q70p80s12nz5lpzr087614lw0000gn/T/ipykernel_68016/864448817.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stocks_comments = stocks_comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(10)).reset_index(drop=True)\n",
      "/var/folders/0w/q70p80s12nz5lpzr087614lw0000gn/T/ipykernel_68016/864448817.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comments = comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(10)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Group by 'post_id', sort by 'score' within each group, and get the head (top 10)\n",
    "wall_street_comments = wall_street_comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(10)).reset_index(drop=True)\n",
    "\n",
    "# Group by 'post_id', sort by 'score' within each group, and get the head (top 10)\n",
    "stocks_comments = stocks_comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(10)).reset_index(drop=True)\n",
    "\n",
    "# Group by 'search_term', sort by 'score' within each group, and get the head (top 5)\n",
    "comments = comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(10)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have multiple comments per post_id. I want to make sure that all the comments stay together. I am putting all the comments in a list and will group them together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wall_street_comments = wall_street_comments.groupby('post_id')['body'].apply(list).reset_index()\n",
    "\n",
    "stocks_comments = stocks_comments.groupby('post_id')['body'].apply(list).reset_index()\n",
    "\n",
    "comments = comments.groupby('post_id')['body'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now merge the posts and comments together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallstreetbets = pd.merge(ws_stock_post, wall_street_comments, on='post_id', how='left')\n",
    "\n",
    "stocks = pd.merge(stocks_post, stocks_comments, on='post_id', how='left')\n",
    "\n",
    "general = pd.merge(posts, comments, on='post_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making sure the datetime is well structured and removing having a uniform date. (Removing Hours and Seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert 'created_utc' to datetime and keep only the date ---\n",
    "wallstreetbets['created_utc'] = pd.to_datetime(wallstreetbets['created_utc']).dt.date\n",
    "\n",
    "stocks['created_utc'] = pd.to_datetime(stocks['created_utc']).dt.date\n",
    "\n",
    "general['created_utc'] = pd.to_datetime(general['created_utc']).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping some of the columns that are not necessary to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['is_self', 'permalink','url','category','flair']\n",
    "\n",
    "wallstreetbets = wallstreetbets.drop(columns=columns_to_drop)\n",
    "\n",
    "stocks = stocks.drop(columns=columns_to_drop)\n",
    "\n",
    "# The general dataframe doesn't have the column 'category'\n",
    "columns_to_drop.remove('category')\n",
    "general = general.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming The columns to have an appropriate name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {'selftext':'post','body':'comments'}\n",
    "wallstreetbets = wallstreetbets.rename(columns=names)\n",
    "stocks = stocks.rename(columns=names)\n",
    "general = general.rename(columns=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. Merging and Exporting the Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat([wallstreetbets, stocks,general], ignore_index=True)\n",
    "\n",
    "main_df.to_csv('./data/cleaned_stock.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
