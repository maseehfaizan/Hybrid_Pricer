{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Notebook\n",
    "\n",
    "### This notebook cleans and merges stock-related data and general Reddit posts.\n",
    "### The process is divided into the following sections:\n",
    "###  1. Data Imports and Setup\n",
    "###  2. Data Cleaning for Stock Posts and Comments\n",
    "###  3. Merging and Exporting the Final DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Imports and Setup for Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading general and stock specific posts\n",
    "posts = pd.read_csv('./data/reddit/general_posts.csv').dropna(subset='category') ## Making sure to drop any empty cells\n",
    "stock_posts = pd.read_csv('./data/reddit/posts_stock_specific.csv').dropna(subset='category')\n",
    "\n",
    "# Loading comments and stock specific comments\n",
    "comments = pd.read_csv('./data/reddit/general_comments.csv')\n",
    "stock_comments = pd.read_csv('./data/reddit/comments_stock_specific.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure that the scores are considered as actual number and not strings. Moreover, I will sort the comments by score and group them together by their respective post_id. \n",
    "\n",
    "I am only considering the top 15 comments for each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['score'] = pd.to_numeric(comments['score'])\n",
    "stock_comments['score'] = pd.to_numeric(stock_comments['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/q70p80s12nz5lpzr087614lw0000gn/T/ipykernel_57050/1312554599.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stock_comments = stock_comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(15)).reset_index(drop=True)\n",
      "/var/folders/0w/q70p80s12nz5lpzr087614lw0000gn/T/ipykernel_57050/1312554599.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comments = comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(15)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Group by 'post_id', sort by 'score' within each group, and get the head (top 10)\n",
    "stock_comments = stock_comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(15)).reset_index(drop=True)\n",
    "\n",
    "comments = comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(15)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have multiple comments per post_id. I want to make sure that all the comments stay together. I am putting all the comments in a list and will group them together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_comments = stock_comments.groupby('post_id')['body'].apply(list).reset_index()\n",
    "comments = comments.groupby('post_id')['body'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now merge the posts and comments together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.merge(stock_posts, stock_comments, on='post_id', how='left')\n",
    "general = pd.merge(posts, comments, on='post_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making sure the datetime is well structured and removing having a uniform date. (Removing Hours and Seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert 'created_utc' to datetime and keep only the date ---\n",
    "stocks['created_utc'] = pd.to_datetime(stocks['created_utc']).dt.date\n",
    "general['created_utc'] = pd.to_datetime(general['created_utc']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "      <th>is_self</th>\n",
       "      <th>flair</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>category</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1esvxig</td>\n",
       "      <td>CNBC: Harris to propose federal ban on 'corpor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35612</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>2768</td>\n",
       "      <td>BothZookeepergame612</td>\n",
       "      <td>/r/Economics/comments/1esvxig/cnbc_harris_to_p...</td>\n",
       "      <td>https://www.cnbc.com/2024/08/15/harris-corpora...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Economics</td>\n",
       "      <td>general</td>\n",
       "      <td>[The headline sounds way different than the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1f2eubo</td>\n",
       "      <td>Should the world's richest 1% - who gained $42...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18133</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>2815</td>\n",
       "      <td>Impressive-Ad1944</td>\n",
       "      <td>/r/Economics/comments/1f2eubo/should_the_world...</td>\n",
       "      <td>https://www.business-standard.com/world-news/w...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Economics</td>\n",
       "      <td>general</td>\n",
       "      <td>[[removed], While the Walton family is one of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ef14i6</td>\n",
       "      <td>Boomers' iron grip on $76 trillion of wealth p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13372</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>773</td>\n",
       "      <td>GetRichQuickSchemer_</td>\n",
       "      <td>/r/Economics/comments/1ef14i6/boomers_iron_gri...</td>\n",
       "      <td>https://creditnews.com/economy/boomers-iron-gr...</td>\n",
       "      <td>False</td>\n",
       "      <td>News</td>\n",
       "      <td>Economics</td>\n",
       "      <td>general</td>\n",
       "      <td>[Having a large IRA/401K is understandable. \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1cbzoay</td>\n",
       "      <td>Nate Silver: Go to a state school. The Ivy Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12639</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2024-04-24</td>\n",
       "      <td>1432</td>\n",
       "      <td>jivatman</td>\n",
       "      <td>/r/Economics/comments/1cbzoay/nate_silver_go_t...</td>\n",
       "      <td>https://www.natesilver.net/p/go-to-a-state-school</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Economics</td>\n",
       "      <td>general</td>\n",
       "      <td>[The point of the ivies isn't the quality of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1cz1a2v</td>\n",
       "      <td>Some Americans live in a parallel economy wher...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10761</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>3178</td>\n",
       "      <td>mafco</td>\n",
       "      <td>/r/Economics/comments/1cz1a2v/some_americans_l...</td>\n",
       "      <td>https://finance.yahoo.com/news/some-americans-...</td>\n",
       "      <td>False</td>\n",
       "      <td>News</td>\n",
       "      <td>Economics</td>\n",
       "      <td>general</td>\n",
       "      <td>[The Great Bifurcation occurred right around C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                              title selftext  score  \\\n",
       "0  1esvxig  CNBC: Harris to propose federal ban on 'corpor...      NaN  35612   \n",
       "1  1f2eubo  Should the world's richest 1% - who gained $42...      NaN  18133   \n",
       "2  1ef14i6  Boomers' iron grip on $76 trillion of wealth p...      NaN  13372   \n",
       "3  1cbzoay  Nate Silver: Go to a state school. The Ivy Lea...      NaN  12639   \n",
       "4  1cz1a2v  Some Americans live in a parallel economy wher...      NaN  10761   \n",
       "\n",
       "   upvote_ratio created_utc  num_comments                author  \\\n",
       "0          0.87  2024-08-15          2768  BothZookeepergame612   \n",
       "1          0.91  2024-08-27          2815     Impressive-Ad1944   \n",
       "2          0.91  2024-07-29           773  GetRichQuickSchemer_   \n",
       "3          0.92  2024-04-24          1432              jivatman   \n",
       "4          0.85  2024-05-23          3178                 mafco   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/Economics/comments/1esvxig/cnbc_harris_to_p...   \n",
       "1  /r/Economics/comments/1f2eubo/should_the_world...   \n",
       "2  /r/Economics/comments/1ef14i6/boomers_iron_gri...   \n",
       "3  /r/Economics/comments/1cbzoay/nate_silver_go_t...   \n",
       "4  /r/Economics/comments/1cz1a2v/some_americans_l...   \n",
       "\n",
       "                                                 url  is_self flair  \\\n",
       "0  https://www.cnbc.com/2024/08/15/harris-corpora...    False   NaN   \n",
       "1  https://www.business-standard.com/world-news/w...    False   NaN   \n",
       "2  https://creditnews.com/economy/boomers-iron-gr...    False  News   \n",
       "3  https://www.natesilver.net/p/go-to-a-state-school    False   NaN   \n",
       "4  https://finance.yahoo.com/news/some-americans-...    False  News   \n",
       "\n",
       "   subreddit category                                               body  \n",
       "0  Economics  general  [The headline sounds way different than the pr...  \n",
       "1  Economics  general  [[removed], While the Walton family is one of ...  \n",
       "2  Economics  general  [Having a large IRA/401K is understandable. \\n...  \n",
       "3  Economics  general  [The point of the ivies isn't the quality of t...  \n",
       "4  Economics  general  [The Great Bifurcation occurred right around C...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming The columns to have an appropriate name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {'selftext':'post','body':'comments'}\n",
    "stocks = stocks.rename(columns=names)\n",
    "general = general.rename(columns=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. Merging and Exporting the Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat([stocks,general], ignore_index=True)\n",
    "\n",
    "main_df.to_csv('./data/cleaned_stock.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
