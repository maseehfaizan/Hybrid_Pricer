{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Notebook\n",
    "\n",
    "### This notebook cleans and merges stock-related data and general Reddit posts.\n",
    "### The process is divided into the following sections:\n",
    "###  1. Data Imports and Setup\n",
    "###  2. Data Cleaning for Stock Posts and Comments\n",
    "###  3. Merging and Exporting the Final DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import importlib.util\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Imports and Setup for Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading general and stock specific posts\n",
    "posts = pd.read_csv('./data/reddit/general_posts.csv').dropna(subset='category') ## Making sure to drop any empty cells\n",
    "stock_posts = pd.read_csv('./data/reddit/posts_stock_specific.csv').dropna(subset='category')\n",
    "\n",
    "# Loading comments and stock specific comments\n",
    "comments = pd.read_csv('./data/reddit/general_comments.csv')\n",
    "stock_comments = pd.read_csv('./data/reddit/comments_stock_specific.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure that the scores are considered as actual number and not strings. Moreover, I will sort the comments by score and group them together by their respective post_id. \n",
    "\n",
    "I am only considering the top 15 comments for each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['score'] = pd.to_numeric(comments['score'])\n",
    "stock_comments['score'] = pd.to_numeric(stock_comments['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0w/q70p80s12nz5lpzr087614lw0000gn/T/ipykernel_10913/1312554599.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stock_comments = stock_comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(15)).reset_index(drop=True)\n",
      "/var/folders/0w/q70p80s12nz5lpzr087614lw0000gn/T/ipykernel_10913/1312554599.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comments = comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(15)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Group by 'post_id', sort by 'score' within each group, and get the head (top 10)\n",
    "stock_comments = stock_comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(15)).reset_index(drop=True)\n",
    "\n",
    "comments = comments.groupby('post_id').apply(lambda x: x.sort_values(by='score', ascending=False).head(15)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have multiple comments per post_id. I want to make sure that all the comments stay together. I am putting all the comments in a list and will group them together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_comments = stock_comments.groupby('post_id')['body'].apply(list).reset_index()\n",
    "comments = comments.groupby('post_id')['body'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now merge the posts and comments together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.merge(stock_posts, stock_comments, on='post_id', how='left')\n",
    "general = pd.merge(posts, comments, on='post_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making sure the datetime is well structured and removing having a uniform date. (Removing Hours and Seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert 'created_utc' to datetime and keep only the date ---\n",
    "stocks['created_utc'] = pd.to_datetime(stocks['created_utc']).dt.date\n",
    "general['created_utc'] = pd.to_datetime(general['created_utc']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "      <th>is_self</th>\n",
       "      <th>flair</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>category</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1esvxig</td>\n",
       "      <td>CNBC: Harris to propose federal ban on 'corpor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35612</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>2768</td>\n",
       "      <td>BothZookeepergame612</td>\n",
       "      <td>/r/Economics/comments/1esvxig/cnbc_harris_to_p...</td>\n",
       "      <td>https://www.cnbc.com/2024/08/15/harris-corpora...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Economics</td>\n",
       "      <td>general</td>\n",
       "      <td>[The headline sounds way different than the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1f2eubo</td>\n",
       "      <td>Should the world's richest 1% - who gained $42...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18133</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2024-08-27</td>\n",
       "      <td>2815</td>\n",
       "      <td>Impressive-Ad1944</td>\n",
       "      <td>/r/Economics/comments/1f2eubo/should_the_world...</td>\n",
       "      <td>https://www.business-standard.com/world-news/w...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Economics</td>\n",
       "      <td>general</td>\n",
       "      <td>[[removed], While the Walton family is one of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ef14i6</td>\n",
       "      <td>Boomers' iron grip on $76 trillion of wealth p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13372</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>773</td>\n",
       "      <td>GetRichQuickSchemer_</td>\n",
       "      <td>/r/Economics/comments/1ef14i6/boomers_iron_gri...</td>\n",
       "      <td>https://creditnews.com/economy/boomers-iron-gr...</td>\n",
       "      <td>False</td>\n",
       "      <td>News</td>\n",
       "      <td>Economics</td>\n",
       "      <td>general</td>\n",
       "      <td>[Having a large IRA/401K is understandable. \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1cbzoay</td>\n",
       "      <td>Nate Silver: Go to a state school. The Ivy Lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12639</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2024-04-24</td>\n",
       "      <td>1432</td>\n",
       "      <td>jivatman</td>\n",
       "      <td>/r/Economics/comments/1cbzoay/nate_silver_go_t...</td>\n",
       "      <td>https://www.natesilver.net/p/go-to-a-state-school</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Economics</td>\n",
       "      <td>general</td>\n",
       "      <td>[The point of the ivies isn't the quality of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1cz1a2v</td>\n",
       "      <td>Some Americans live in a parallel economy wher...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10761</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>3178</td>\n",
       "      <td>mafco</td>\n",
       "      <td>/r/Economics/comments/1cz1a2v/some_americans_l...</td>\n",
       "      <td>https://finance.yahoo.com/news/some-americans-...</td>\n",
       "      <td>False</td>\n",
       "      <td>News</td>\n",
       "      <td>Economics</td>\n",
       "      <td>general</td>\n",
       "      <td>[The Great Bifurcation occurred right around C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                              title selftext  score  \\\n",
       "0  1esvxig  CNBC: Harris to propose federal ban on 'corpor...      NaN  35612   \n",
       "1  1f2eubo  Should the world's richest 1% - who gained $42...      NaN  18133   \n",
       "2  1ef14i6  Boomers' iron grip on $76 trillion of wealth p...      NaN  13372   \n",
       "3  1cbzoay  Nate Silver: Go to a state school. The Ivy Lea...      NaN  12639   \n",
       "4  1cz1a2v  Some Americans live in a parallel economy wher...      NaN  10761   \n",
       "\n",
       "   upvote_ratio created_utc  num_comments                author  \\\n",
       "0          0.87  2024-08-15          2768  BothZookeepergame612   \n",
       "1          0.91  2024-08-27          2815     Impressive-Ad1944   \n",
       "2          0.91  2024-07-29           773  GetRichQuickSchemer_   \n",
       "3          0.92  2024-04-24          1432              jivatman   \n",
       "4          0.85  2024-05-23          3178                 mafco   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/Economics/comments/1esvxig/cnbc_harris_to_p...   \n",
       "1  /r/Economics/comments/1f2eubo/should_the_world...   \n",
       "2  /r/Economics/comments/1ef14i6/boomers_iron_gri...   \n",
       "3  /r/Economics/comments/1cbzoay/nate_silver_go_t...   \n",
       "4  /r/Economics/comments/1cz1a2v/some_americans_l...   \n",
       "\n",
       "                                                 url  is_self flair  \\\n",
       "0  https://www.cnbc.com/2024/08/15/harris-corpora...    False   NaN   \n",
       "1  https://www.business-standard.com/world-news/w...    False   NaN   \n",
       "2  https://creditnews.com/economy/boomers-iron-gr...    False  News   \n",
       "3  https://www.natesilver.net/p/go-to-a-state-school    False   NaN   \n",
       "4  https://finance.yahoo.com/news/some-americans-...    False  News   \n",
       "\n",
       "   subreddit category                                               body  \n",
       "0  Economics  general  [The headline sounds way different than the pr...  \n",
       "1  Economics  general  [[removed], While the Walton family is one of ...  \n",
       "2  Economics  general  [Having a large IRA/401K is understandable. \\n...  \n",
       "3  Economics  general  [The point of the ivies isn't the quality of t...  \n",
       "4  Economics  general  [The Great Bifurcation occurred right around C...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming The columns to have an appropriate name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {'selftext':'post','body':'comments'}\n",
    "stocks = stocks.rename(columns=names)\n",
    "general = general.rename(columns=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. Merging and Exporting the Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat([stocks,general], ignore_index=True)\n",
    "\n",
    "main_df.to_csv('./data/cleaned_stock.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Data Cleaner (This will only output yearly data for the 10-K NO 10-Qs for now)\n",
    "\n",
    "The Goal in this section is to clean the raw financial data for it to be useful for my needs\n",
    "\n",
    "1. I am importing the raw data\n",
    "2. I am pivoting the data so the account names are columns (Easier to manipulate)\n",
    "3. I am Removing all the accounts that are not part of 10-K or 10-Q. Essentially if the frame is not for either of those the rows will fall (CY20XXQX or CY20XX)\n",
    "4. I am removing all of the columns that are 95% empty. This is because some of the accounts are available but with no information\n",
    "5. I am doing this for all 500 companies so the data is easier to manipulate, once it is done the raw data will be deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am processing different Financial csv data and cleaning the date up\n",
    "- Import the Financial csv data\n",
    "- sort values by date\n",
    "- Pivot the table to make the concept appear as independant columns across different date&Time\n",
    "- Given that during the pivote there were a lot of duplicate that were generated, I group the columns by filed date and remove any NaN cells as to have a cleaned dataframe\n",
    "- To further clean the data, I removed the columns that are 95% empty. I cannot do any meaning full Time Series analysis on those columns\n",
    "\n",
    "### Output in \"Clean\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data processing...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting data processing...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43msp\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mSymbol\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      6\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mProcessing symbol: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'sp' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Starting data processing...\")\n",
    "sp = pd.read_csv('./data/sp500.csv')\n",
    "sp.head(3)\n",
    "for i in sp['Symbol']:\n",
    "    try:\n",
    "        print(f'Processing symbol: {i}')\n",
    "        file_path = f'./data/financial_data/{i}_raw_financials.csv'\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f'Successfully read data for {i}')\n",
    "\n",
    "        pivoted_df = df.pivot_table(\n",
    "            index=['cik', 'company_name', 'frame', 'unit', 'end', 'filed', 'form'],\n",
    "            columns='concept',\n",
    "            values='value'\n",
    "        ).reset_index()\n",
    "        print(f'Pivoted data for {i}')\n",
    "\n",
    "        metadata_cols = ['cik', 'company_name', 'form', 'frame', 'end', 'unit']\n",
    "        consolidated_df = pd.DataFrame()\n",
    "        grouped = pivoted_df.groupby('end')\n",
    "\n",
    "        for end_date, group in grouped:\n",
    "            row_data = {'end': end_date}\n",
    "            for col in metadata_cols:\n",
    "                if col in group.columns:\n",
    "                    row_data[col] = group[col].iloc[0]\n",
    "            \n",
    "            for col in pivoted_df.columns:\n",
    "                if col not in metadata_cols and col != 'end':\n",
    "                    non_nan_values = group[col].dropna()\n",
    "                    if not non_nan_values.empty:\n",
    "                        row_data[col] = non_nan_values.iloc[0]\n",
    "                    else:\n",
    "                        row_data[col] = None\n",
    "            \n",
    "            consolidated_df = pd.concat([consolidated_df, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "        ##### I only want the yearly data not the quarterly data for now ####\n",
    "        consolidated_df = consolidated_df[consolidated_df['form'] == '10-K']\n",
    "        consolidated_df = consolidated_df[consolidated_df['frame'].astype(str).str.match((r'^CY\\d{4}$'))]\n",
    "        print(f'Filtered by frame format for {i}')\n",
    "\n",
    "\n",
    "        print(f'Filtering columns with >95% empty cells for {i}')\n",
    "        if not consolidated_df.empty:\n",
    "            nan_percentages = consolidated_df.isna().mean()\n",
    "            cleaned_df = consolidated_df.loc[:, nan_percentages < 0.95]\n",
    "            consolidated_df = cleaned_df\n",
    "            print(f'Removed sparse columns for {i}')\n",
    "        else:\n",
    "            print(f'Consolidated dataframe is empty for {i}, skipping NaN column removal.')\n",
    "\n",
    "        output_file_path = f'./data/clean/{i}.csv'\n",
    "        \n",
    "        # Ensure the directory exists before saving\n",
    "        os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "        \n",
    "        consolidated_df.to_csv(output_file_path, index=False)\n",
    "        print(f'Successfully processed and saved data for {i} to {output_file_path}')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found for symbol {i} at path: {file_path}. Skipping this symbol.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: File for symbol {i} is empty: {file_path}. Skipping this symbol.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: A required column is missing for symbol {i} (KeyError: {e}). Skipping this symbol.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while processing symbol {i}: {e}\")\n",
    "        print(f\"Skipping symbol {i} and continuing with the next one.\")\n",
    "\n",
    "print(\"Finished processing all symbols.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here I will further clean the data to construct the Balance Sheet, Income Statement and Cash Flow Statement for the Sector / Industry and save them into the csv files\n",
    "\n",
    "\n",
    "- Check each year (Frame) individually for each financial account\n",
    "- If the primary account has a NaN/empty value in a specific year\n",
    "- Look at the alternative account names for that same year\n",
    "- Use the alternative value when available\n",
    "\n",
    "\n",
    "### Output in financial_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing MMM (Industrials - Industrial Conglomerates)...\n",
      "Processing Industrials - Industrial Conglomerates... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Industrial Conglomerates → IndustrialConglomerates\n",
      "Successfully generated financial statements for MMM\n",
      "\n",
      "Processing AOS (Industrials - Building Products)...\n",
      "Processing Industrials - Building Products... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Building Products → BuildingProducts\n",
      "Successfully generated financial statements for AOS\n",
      "\n",
      "Processing ABT (Health Care - Health Care Equipment)...\n",
      "Processing Health Care - Health Care Equipment... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Found mapping for Health Care Equipment → HealthCareEquipment\n",
      "Successfully generated financial statements for ABT\n",
      "\n",
      "Processing ABBV (Health Care - Biotechnology)...\n",
      "Processing Health Care - Biotechnology... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Found direct mapping for Biotechnology\n",
      "Successfully generated financial statements for ABBV\n",
      "\n",
      "Processing ACN (Information Technology - IT Consulting & Other Services)...\n",
      "Processing Information Technology - IT Consulting & Other Services... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found mapping for IT Consulting & Other Services → ItConsultingAndOtherServices\n",
      "Successfully generated financial statements for ACN\n",
      "\n",
      "Processing ADBE (Information Technology - Application Software)...\n",
      "Processing Information Technology - Application Software... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found mapping for Application Software → ApplicationSoftware\n",
      "Successfully generated financial statements for ADBE\n",
      "\n",
      "Processing AMD (Information Technology - Semiconductors)...\n",
      "Processing Information Technology - Semiconductors... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found direct mapping for Semiconductors\n",
      "Successfully generated financial statements for AMD\n",
      "\n",
      "Processing AES (Utilities - Independent Power Producers & Energy Traders)...\n",
      "dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Processing Utilities - Independent Power Producers & Energy Traders... dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Found mapping for Independent Power Producers & Energy Traders → IndependentPowerProducersEnergyTraders\n",
      "Successfully generated financial statements for AES\n",
      "\n",
      "Processing AFL (Financials - Life & Health Insurance)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Life & Health Insurance... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Life & Health Insurance → LifeHealthInsurance\n",
      "Successfully generated financial statements for AFL\n",
      "\n",
      "Processing A (Health Care - Life Sciences Tools & Services)...\n",
      "Processing Health Care - Life Sciences Tools & Services... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Using mapping for LifeSciencesToolsAndServicesAccounts (variant match with Life Sciences Tools & Services)\n",
      "Successfully generated financial statements for A\n",
      "\n",
      "Processing APD (Materials - Industrial Gases)...\n",
      "Processing Materials - Industrial Gases... dict_keys(['CommodityChemicals', 'ConstructionMaterials', 'Copper', 'FertilizersAgriculturalChemicals', 'Gold', 'IndustrialGases', 'MetalGlassPlasticContainers', 'PaperPlasticPackaging', 'SpecialtyChemicals', 'Steel'])\n",
      "Found mapping for Industrial Gases → IndustrialGases\n",
      "Successfully generated financial statements for APD\n",
      "\n",
      "Processing ABNB (Consumer Discretionary - Hotels, Resorts & Cruise Lines)...\n",
      "Processing Consumer Discretionary - Hotels, Resorts & Cruise Lines... dict_keys(['ApparelRetail', 'ApparelAccessoriesLuxuryGoods', 'AutomobileManufacturers', 'AutomotivePartsEquipment', 'AutomotiveRetail', 'BroadlineRetail', 'CasinosGaming', 'ComputerElectronicsRetail', 'ConsumerElectronics', 'Distributors', 'Footwear', 'HomeFurnishings', 'HomeImprovementRetail', 'Homebuilding', 'HotelsResortsCruiseLines', 'LeisureProducts', 'OtherSpecialtyRetail', 'Restaurants'])\n",
      "Found mapping for Hotels, Resorts & Cruise Lines → HotelsResortsCruiseLines\n",
      "Successfully generated financial statements for ABNB\n",
      "\n",
      "Processing AKAM (Information Technology - Internet Services & Infrastructure)...\n",
      "Processing Information Technology - Internet Services & Infrastructure... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found mapping for Internet Services & Infrastructure → InternetServicesAndInfrastructure\n",
      "Successfully generated financial statements for AKAM\n",
      "\n",
      "Processing ALB (Materials - Specialty Chemicals)...\n",
      "Processing Materials - Specialty Chemicals... dict_keys(['CommodityChemicals', 'ConstructionMaterials', 'Copper', 'FertilizersAgriculturalChemicals', 'Gold', 'IndustrialGases', 'MetalGlassPlasticContainers', 'PaperPlasticPackaging', 'SpecialtyChemicals', 'Steel'])\n",
      "Found mapping for Specialty Chemicals → SpecialtyChemicals\n",
      "Successfully generated financial statements for ALB\n",
      "\n",
      "Processing ARE (Real Estate - Office REITs)...\n",
      "Processing Real Estate - Office REITs... dict_keys(['RealEstateServices', 'RetailREITs', 'SelfStorageREITs', 'SingleFamilyResidentialREITs', 'TelecomTowerREITs', 'TimberREITs', 'DataCenterREITs', 'HealthCareREITs', 'HotelResortREITs', 'IndustrialREITs', 'MultiFamilyResidentialREITs', 'OfficeREITs', 'OtherSpecializedREITs'])\n",
      "Using mapping for OfficeREITs (variant match with Office REITs)\n",
      "Successfully generated financial statements for ARE\n",
      "\n",
      "Processing ALGN (Health Care - Health Care Supplies)...\n",
      "Processing Health Care - Health Care Supplies... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Found mapping for Health Care Supplies → HealthCareSupplies\n",
      "Successfully generated financial statements for ALGN\n",
      "\n",
      "Processing ALLE (Industrials - Building Products)...\n",
      "Processing Industrials - Building Products... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Building Products → BuildingProducts\n",
      "Successfully generated financial statements for ALLE\n",
      "\n",
      "Processing LNT (Utilities - Electric Utilities)...\n",
      "dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Processing Utilities - Electric Utilities... dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Found mapping for Electric Utilities → ElectricUtilities\n",
      "Successfully generated financial statements for LNT\n",
      "\n",
      "Processing ALL (Financials - Property & Casualty Insurance)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Property & Casualty Insurance... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Property & Casualty Insurance → PropertyCasualtyInsurance\n",
      "Successfully generated financial statements for ALL\n",
      "\n",
      "Processing GOOGL (Communication Services - Interactive Media & Services)...\n",
      "dict_keys(['Advertising', 'Broadcasting', 'CableAndSatellite', 'IntegratedTelecommunicationServices', 'InteractiveHomeEntertainment', 'InteractiveMediaAndServices', 'MoviesAndEntertainment', 'Publishing', 'WirelessTelecommunicationServices'])\n",
      "Processing Communication Services - Interactive Media & Services... dict_keys(['Advertising', 'Broadcasting', 'CableAndSatellite', 'IntegratedTelecommunicationServices', 'InteractiveHomeEntertainment', 'InteractiveMediaAndServices', 'MoviesAndEntertainment', 'Publishing', 'WirelessTelecommunicationServices'])\n",
      "Found mapping for Interactive Media & Services → InteractiveMediaAndServices\n",
      "Successfully generated financial statements for GOOGL\n",
      "\n",
      "Processing GOOG (Communication Services - Interactive Media & Services)...\n",
      "dict_keys(['Advertising', 'Broadcasting', 'CableAndSatellite', 'IntegratedTelecommunicationServices', 'InteractiveHomeEntertainment', 'InteractiveMediaAndServices', 'MoviesAndEntertainment', 'Publishing', 'WirelessTelecommunicationServices'])\n",
      "Processing Communication Services - Interactive Media & Services... dict_keys(['Advertising', 'Broadcasting', 'CableAndSatellite', 'IntegratedTelecommunicationServices', 'InteractiveHomeEntertainment', 'InteractiveMediaAndServices', 'MoviesAndEntertainment', 'Publishing', 'WirelessTelecommunicationServices'])\n",
      "Found mapping for Interactive Media & Services → InteractiveMediaAndServices\n",
      "Successfully generated financial statements for GOOG\n",
      "\n",
      "Processing MO (Consumer Staples - Tobacco)...\n",
      "Processing Consumer Staples - Tobacco... dict_keys(['AgriculturalProductsAndServices', 'Brewers', 'ConsumerStaplesMerchandiseRetail', 'DistillersAndVintners', 'DrugRetail', 'FoodDistributors', 'FoodRetail', 'HouseholdProducts', 'PackagedFoodsAndMeats', 'PersonalCareProducts', 'SoftDrinksNonAlcoholicBeverages', 'Tobacco'])\n",
      "Found direct mapping for Tobacco\n",
      "Successfully generated financial statements for MO\n",
      "\n",
      "Processing AMZN (Consumer Discretionary - Broadline Retail)...\n",
      "Processing Consumer Discretionary - Broadline Retail... dict_keys(['ApparelRetail', 'ApparelAccessoriesLuxuryGoods', 'AutomobileManufacturers', 'AutomotivePartsEquipment', 'AutomotiveRetail', 'BroadlineRetail', 'CasinosGaming', 'ComputerElectronicsRetail', 'ConsumerElectronics', 'Distributors', 'Footwear', 'HomeFurnishings', 'HomeImprovementRetail', 'Homebuilding', 'HotelsResortsCruiseLines', 'LeisureProducts', 'OtherSpecialtyRetail', 'Restaurants'])\n",
      "Found mapping for Broadline Retail → BroadlineRetail\n",
      "Successfully generated financial statements for AMZN\n",
      "\n",
      "Processing AMCR (Materials - Paper & Plastic Packaging Products & Materials)...\n",
      "Processing Materials - Paper & Plastic Packaging Products & Materials... dict_keys(['CommodityChemicals', 'ConstructionMaterials', 'Copper', 'FertilizersAgriculturalChemicals', 'Gold', 'IndustrialGases', 'MetalGlassPlasticContainers', 'PaperPlasticPackaging', 'SpecialtyChemicals', 'Steel'])\n",
      "Using mapping for PaperPlasticPackaging (variant match with Paper & Plastic Packaging Products & Materials)\n",
      "Successfully generated financial statements for AMCR\n",
      "\n",
      "Processing AEE (Utilities - Multi-Utilities)...\n",
      "dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Processing Utilities - Multi-Utilities... dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Found mapping for Multi-Utilities → MultiUtilities\n",
      "Successfully generated financial statements for AEE\n",
      "\n",
      "Processing AEP (Utilities - Electric Utilities)...\n",
      "dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Processing Utilities - Electric Utilities... dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Found mapping for Electric Utilities → ElectricUtilities\n",
      "Successfully generated financial statements for AEP\n",
      "\n",
      "Processing AXP (Financials - Consumer Finance)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Consumer Finance... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Consumer Finance → ConsumerFinance\n",
      "Successfully generated financial statements for AXP\n",
      "\n",
      "Processing AIG (Financials - Multi-line Insurance)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Multi-line Insurance... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Multi-line Insurance → MultiLineInsurance\n",
      "Successfully generated financial statements for AIG\n",
      "\n",
      "Processing AMT (Real Estate - Telecom Tower REITs)...\n",
      "Processing Real Estate - Telecom Tower REITs... dict_keys(['RealEstateServices', 'RetailREITs', 'SelfStorageREITs', 'SingleFamilyResidentialREITs', 'TelecomTowerREITs', 'TimberREITs', 'DataCenterREITs', 'HealthCareREITs', 'HotelResortREITs', 'IndustrialREITs', 'MultiFamilyResidentialREITs', 'OfficeREITs', 'OtherSpecializedREITs'])\n",
      "Using mapping for TelecomTowerREITs (variant match with Telecom Tower REITs)\n",
      "Successfully generated financial statements for AMT\n",
      "\n",
      "Processing AWK (Utilities - Water Utilities)...\n",
      "dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Processing Utilities - Water Utilities... dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Found mapping for Water Utilities → WaterUtilities\n",
      "Successfully generated financial statements for AWK\n",
      "\n",
      "Processing AMP (Financials - Asset Management & Custody Banks)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Asset Management & Custody Banks... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Asset Management & Custody Banks → AssetManagementCustodyBanks\n",
      "Successfully generated financial statements for AMP\n",
      "\n",
      "Processing AME (Industrials - Electrical Components & Equipment)...\n",
      "Processing Industrials - Electrical Components & Equipment... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Electrical Components & Equipment → ElectricalComponentsEquipment\n",
      "Successfully generated financial statements for AME\n",
      "\n",
      "Processing AMGN (Health Care - Biotechnology)...\n",
      "Processing Health Care - Biotechnology... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Found direct mapping for Biotechnology\n",
      "Successfully generated financial statements for AMGN\n",
      "\n",
      "Processing APH (Information Technology - Electronic Components)...\n",
      "Processing Information Technology - Electronic Components... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found mapping for Electronic Components → ElectronicComponents\n",
      "Successfully generated financial statements for APH\n",
      "\n",
      "Processing ADI (Information Technology - Semiconductors)...\n",
      "Processing Information Technology - Semiconductors... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found direct mapping for Semiconductors\n",
      "Successfully generated financial statements for ADI\n",
      "\n",
      "Processing ANSS (Information Technology - Application Software)...\n",
      "Processing Information Technology - Application Software... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found mapping for Application Software → ApplicationSoftware\n",
      "Successfully generated financial statements for ANSS\n",
      "\n",
      "Processing AON (Financials - Insurance Brokers)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Insurance Brokers... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Insurance Brokers → InsuranceBrokers\n",
      "Successfully generated financial statements for AON\n",
      "\n",
      "Processing APA (Energy - Oil & Gas Exploration & Production)...\n",
      "dict_keys(['IntegratedOilGas', 'OilGasEquipmentServices', 'OilGasExplorationProduction', 'OilGasRefiningMarketing', 'OilGasStorageTransportation'])\n",
      "Processing Energy - Oil & Gas Exploration & Production... dict_keys(['IntegratedOilGas', 'OilGasEquipmentServices', 'OilGasExplorationProduction', 'OilGasRefiningMarketing', 'OilGasStorageTransportation'])\n",
      "Found mapping for Oil & Gas Exploration & Production → OilGasExplorationProduction\n",
      "Successfully generated financial statements for APA\n",
      "\n",
      "Processing APO (Financials - Asset Management & Custody Banks)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Asset Management & Custody Banks... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Asset Management & Custody Banks → AssetManagementCustodyBanks\n",
      "Successfully generated financial statements for APO\n",
      "\n",
      "Processing AAPL (Information Technology - Technology Hardware, Storage & Peripherals)...\n",
      "Processing Information Technology - Technology Hardware, Storage & Peripherals... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found mapping for Technology Hardware, Storage & Peripherals → TechnologyHardwareStoragePeripherals\n",
      "Successfully generated financial statements for AAPL\n",
      "\n",
      "Processing AMAT (Information Technology - Semiconductor Materials & Equipment)...\n",
      "Processing Information Technology - Semiconductor Materials & Equipment... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found mapping for Semiconductor Materials & Equipment → SemiconductorMaterialsAndEquipment\n",
      "Successfully generated financial statements for AMAT\n",
      "\n",
      "Processing APTV (Consumer Discretionary - Automotive Parts & Equipment)...\n",
      "Processing Consumer Discretionary - Automotive Parts & Equipment... dict_keys(['ApparelRetail', 'ApparelAccessoriesLuxuryGoods', 'AutomobileManufacturers', 'AutomotivePartsEquipment', 'AutomotiveRetail', 'BroadlineRetail', 'CasinosGaming', 'ComputerElectronicsRetail', 'ConsumerElectronics', 'Distributors', 'Footwear', 'HomeFurnishings', 'HomeImprovementRetail', 'Homebuilding', 'HotelsResortsCruiseLines', 'LeisureProducts', 'OtherSpecialtyRetail', 'Restaurants'])\n",
      "Found mapping for Automotive Parts & Equipment → AutomotivePartsEquipment\n",
      "Successfully generated financial statements for APTV\n",
      "\n",
      "Processing ACGL (Financials - Property & Casualty Insurance)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Property & Casualty Insurance... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Property & Casualty Insurance → PropertyCasualtyInsurance\n",
      "Successfully generated financial statements for ACGL\n",
      "\n",
      "Processing ADM (Consumer Staples - Agricultural Products & Services)...\n",
      "Processing Consumer Staples - Agricultural Products & Services... dict_keys(['AgriculturalProductsAndServices', 'Brewers', 'ConsumerStaplesMerchandiseRetail', 'DistillersAndVintners', 'DrugRetail', 'FoodDistributors', 'FoodRetail', 'HouseholdProducts', 'PackagedFoodsAndMeats', 'PersonalCareProducts', 'SoftDrinksNonAlcoholicBeverages', 'Tobacco'])\n",
      "Found mapping for Agricultural Products & Services → AgriculturalProductsAndServices\n",
      "Successfully generated financial statements for ADM\n",
      "\n",
      "Processing ANET (Information Technology - Communications Equipment)...\n",
      "Processing Information Technology - Communications Equipment... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found mapping for Communications Equipment → CommunicationsEquipment\n",
      "Successfully generated financial statements for ANET\n",
      "\n",
      "Processing AJG (Financials - Insurance Brokers)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Insurance Brokers... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Insurance Brokers → InsuranceBrokers\n",
      "Successfully generated financial statements for AJG\n",
      "\n",
      "Processing AIZ (Financials - Multi-line Insurance)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Multi-line Insurance... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Multi-line Insurance → MultiLineInsurance\n",
      "Successfully generated financial statements for AIZ\n",
      "\n",
      "Processing T (Communication Services - Integrated Telecommunication Services)...\n",
      "dict_keys(['Advertising', 'Broadcasting', 'CableAndSatellite', 'IntegratedTelecommunicationServices', 'InteractiveHomeEntertainment', 'InteractiveMediaAndServices', 'MoviesAndEntertainment', 'Publishing', 'WirelessTelecommunicationServices'])\n",
      "Processing Communication Services - Integrated Telecommunication Services... dict_keys(['Advertising', 'Broadcasting', 'CableAndSatellite', 'IntegratedTelecommunicationServices', 'InteractiveHomeEntertainment', 'InteractiveMediaAndServices', 'MoviesAndEntertainment', 'Publishing', 'WirelessTelecommunicationServices'])\n",
      "Found mapping for Integrated Telecommunication Services → IntegratedTelecommunicationServices\n",
      "Successfully generated financial statements for T\n",
      "\n",
      "Processing ATO (Utilities - Gas Utilities)...\n",
      "dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Processing Utilities - Gas Utilities... dict_keys(['ElectricUtilities', 'GasUtilities', 'IndependentPowerProducersEnergyTraders', 'MultiUtilities', 'WaterUtilities'])\n",
      "Found mapping for Gas Utilities → GasUtilities\n",
      "Successfully generated financial statements for ATO\n",
      "\n",
      "Processing ADSK (Information Technology - Application Software)...\n",
      "Processing Information Technology - Application Software... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found mapping for Application Software → ApplicationSoftware\n",
      "Successfully generated financial statements for ADSK\n",
      "\n",
      "Processing ADP (Industrials - Human Resource & Employment Services)...\n",
      "Processing Industrials - Human Resource & Employment Services... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Human Resource & Employment Services → HumanResourceAndEmploymentServices\n",
      "Successfully generated financial statements for ADP\n",
      "\n",
      "Processing AZO (Consumer Discretionary - Automotive Retail)...\n",
      "Processing Consumer Discretionary - Automotive Retail... dict_keys(['ApparelRetail', 'ApparelAccessoriesLuxuryGoods', 'AutomobileManufacturers', 'AutomotivePartsEquipment', 'AutomotiveRetail', 'BroadlineRetail', 'CasinosGaming', 'ComputerElectronicsRetail', 'ConsumerElectronics', 'Distributors', 'Footwear', 'HomeFurnishings', 'HomeImprovementRetail', 'Homebuilding', 'HotelsResortsCruiseLines', 'LeisureProducts', 'OtherSpecialtyRetail', 'Restaurants'])\n",
      "Found mapping for Automotive Retail → AutomotiveRetail\n",
      "Successfully generated financial statements for AZO\n",
      "\n",
      "Processing AVB (Real Estate - Multi-Family Residential REITs)...\n",
      "Processing Real Estate - Multi-Family Residential REITs... dict_keys(['RealEstateServices', 'RetailREITs', 'SelfStorageREITs', 'SingleFamilyResidentialREITs', 'TelecomTowerREITs', 'TimberREITs', 'DataCenterREITs', 'HealthCareREITs', 'HotelResortREITs', 'IndustrialREITs', 'MultiFamilyResidentialREITs', 'OfficeREITs', 'OtherSpecializedREITs'])\n",
      "Using mapping for MultiFamilyResidentialREITs (variant match with Multi-Family Residential REITs)\n",
      "Successfully generated financial statements for AVB\n",
      "\n",
      "Processing AVY (Materials - Paper & Plastic Packaging Products & Materials)...\n",
      "Processing Materials - Paper & Plastic Packaging Products & Materials... dict_keys(['CommodityChemicals', 'ConstructionMaterials', 'Copper', 'FertilizersAgriculturalChemicals', 'Gold', 'IndustrialGases', 'MetalGlassPlasticContainers', 'PaperPlasticPackaging', 'SpecialtyChemicals', 'Steel'])\n",
      "Using mapping for PaperPlasticPackaging (variant match with Paper & Plastic Packaging Products & Materials)\n",
      "Successfully generated financial statements for AVY\n",
      "\n",
      "Processing AXON (Industrials - Aerospace & Defense)...\n",
      "Processing Industrials - Aerospace & Defense... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Aerospace & Defense → AerospaceDefense\n",
      "Successfully generated financial statements for AXON\n",
      "\n",
      "Processing BKR (Energy - Oil & Gas Equipment & Services)...\n",
      "dict_keys(['IntegratedOilGas', 'OilGasEquipmentServices', 'OilGasExplorationProduction', 'OilGasRefiningMarketing', 'OilGasStorageTransportation'])\n",
      "Processing Energy - Oil & Gas Equipment & Services... dict_keys(['IntegratedOilGas', 'OilGasEquipmentServices', 'OilGasExplorationProduction', 'OilGasRefiningMarketing', 'OilGasStorageTransportation'])\n",
      "Found mapping for Oil & Gas Equipment & Services → OilGasEquipmentServices\n",
      "Successfully generated financial statements for BKR\n",
      "\n",
      "Processing BALL (Materials - Metal, Glass & Plastic Containers)...\n",
      "Processing Materials - Metal, Glass & Plastic Containers... dict_keys(['CommodityChemicals', 'ConstructionMaterials', 'Copper', 'FertilizersAgriculturalChemicals', 'Gold', 'IndustrialGases', 'MetalGlassPlasticContainers', 'PaperPlasticPackaging', 'SpecialtyChemicals', 'Steel'])\n",
      "Found mapping for Metal, Glass & Plastic Containers → MetalGlassPlasticContainers\n",
      "Successfully generated financial statements for BALL\n",
      "\n",
      "Processing BAC (Financials - Diversified Banks)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Diversified Banks... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Diversified Banks → DiversifiedBanks\n",
      "Successfully generated financial statements for BAC\n",
      "\n",
      "Processing BAX (Health Care - Health Care Equipment)...\n",
      "Processing Health Care - Health Care Equipment... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Found mapping for Health Care Equipment → HealthCareEquipment\n",
      "Successfully generated financial statements for BAX\n",
      "\n",
      "Processing BDX (Health Care - Health Care Equipment)...\n",
      "Processing Health Care - Health Care Equipment... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Found mapping for Health Care Equipment → HealthCareEquipment\n",
      "Successfully generated financial statements for BDX\n",
      "\n",
      "Processing BRK.B (Financials - Multi-Sector Holdings)...\n",
      "Error loading data for BRK.B: [Errno 2] No such file or directory: '/Users/maseehfaizan/Desktop/Maseeh/Projects/Hybrid_Pricer/data/clean/BRK.B.csv'\n",
      "Skipping BRK.B - Could not load data.\n",
      "\n",
      "Processing BBY (Consumer Discretionary - Computer & Electronics Retail)...\n",
      "Processing Consumer Discretionary - Computer & Electronics Retail... dict_keys(['ApparelRetail', 'ApparelAccessoriesLuxuryGoods', 'AutomobileManufacturers', 'AutomotivePartsEquipment', 'AutomotiveRetail', 'BroadlineRetail', 'CasinosGaming', 'ComputerElectronicsRetail', 'ConsumerElectronics', 'Distributors', 'Footwear', 'HomeFurnishings', 'HomeImprovementRetail', 'Homebuilding', 'HotelsResortsCruiseLines', 'LeisureProducts', 'OtherSpecialtyRetail', 'Restaurants'])\n",
      "Found mapping for Computer & Electronics Retail → ComputerElectronicsRetail\n",
      "Successfully generated financial statements for BBY\n",
      "\n",
      "Processing TECH (Health Care - Life Sciences Tools & Services)...\n",
      "Processing Health Care - Life Sciences Tools & Services... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Using mapping for LifeSciencesToolsAndServicesAccounts (variant match with Life Sciences Tools & Services)\n",
      "Successfully generated financial statements for TECH\n",
      "\n",
      "Processing BIIB (Health Care - Biotechnology)...\n",
      "Processing Health Care - Biotechnology... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Found direct mapping for Biotechnology\n",
      "Successfully generated financial statements for BIIB\n",
      "\n",
      "Processing BLK (Financials - Asset Management & Custody Banks)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Asset Management & Custody Banks... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Asset Management & Custody Banks → AssetManagementCustodyBanks\n",
      "Successfully generated financial statements for BLK\n",
      "\n",
      "Processing BX (Financials - Asset Management & Custody Banks)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Asset Management & Custody Banks... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Asset Management & Custody Banks → AssetManagementCustodyBanks\n",
      "Successfully generated financial statements for BX\n",
      "\n",
      "Processing BK (Financials - Asset Management & Custody Banks)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Asset Management & Custody Banks... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Asset Management & Custody Banks → AssetManagementCustodyBanks\n",
      "Successfully generated financial statements for BK\n",
      "\n",
      "Processing BA (Industrials - Aerospace & Defense)...\n",
      "Processing Industrials - Aerospace & Defense... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Aerospace & Defense → AerospaceDefense\n",
      "Successfully generated financial statements for BA\n",
      "\n",
      "Processing BKNG (Consumer Discretionary - Hotels, Resorts & Cruise Lines)...\n",
      "Processing Consumer Discretionary - Hotels, Resorts & Cruise Lines... dict_keys(['ApparelRetail', 'ApparelAccessoriesLuxuryGoods', 'AutomobileManufacturers', 'AutomotivePartsEquipment', 'AutomotiveRetail', 'BroadlineRetail', 'CasinosGaming', 'ComputerElectronicsRetail', 'ConsumerElectronics', 'Distributors', 'Footwear', 'HomeFurnishings', 'HomeImprovementRetail', 'Homebuilding', 'HotelsResortsCruiseLines', 'LeisureProducts', 'OtherSpecialtyRetail', 'Restaurants'])\n",
      "Found mapping for Hotels, Resorts & Cruise Lines → HotelsResortsCruiseLines\n",
      "Successfully generated financial statements for BKNG\n",
      "\n",
      "Processing BWA (Consumer Discretionary - Automotive Parts & Equipment)...\n",
      "Processing Consumer Discretionary - Automotive Parts & Equipment... dict_keys(['ApparelRetail', 'ApparelAccessoriesLuxuryGoods', 'AutomobileManufacturers', 'AutomotivePartsEquipment', 'AutomotiveRetail', 'BroadlineRetail', 'CasinosGaming', 'ComputerElectronicsRetail', 'ConsumerElectronics', 'Distributors', 'Footwear', 'HomeFurnishings', 'HomeImprovementRetail', 'Homebuilding', 'HotelsResortsCruiseLines', 'LeisureProducts', 'OtherSpecialtyRetail', 'Restaurants'])\n",
      "Found mapping for Automotive Parts & Equipment → AutomotivePartsEquipment\n",
      "Successfully generated financial statements for BWA\n",
      "\n",
      "Processing BSX (Health Care - Health Care Equipment)...\n",
      "Processing Health Care - Health Care Equipment... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Found mapping for Health Care Equipment → HealthCareEquipment\n",
      "Successfully generated financial statements for BSX\n",
      "\n",
      "Processing BMY (Health Care - Pharmaceuticals)...\n",
      "Processing Health Care - Pharmaceuticals... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Using mapping for PharmaceuticalsAccounts (variant match with Pharmaceuticals)\n",
      "Successfully generated financial statements for BMY\n",
      "\n",
      "Processing AVGO (Information Technology - Semiconductors)...\n",
      "Processing Information Technology - Semiconductors... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found direct mapping for Semiconductors\n",
      "Successfully generated financial statements for AVGO\n",
      "\n",
      "Processing BR (Industrials - Data Processing & Outsourced Services)...\n",
      "Processing Industrials - Data Processing & Outsourced Services... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Data Processing & Outsourced Services → DataProcessingOutsourcedServices\n",
      "Successfully generated financial statements for BR\n",
      "\n",
      "Processing BRO (Financials - Insurance Brokers)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Insurance Brokers... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Insurance Brokers → InsuranceBrokers\n",
      "Successfully generated financial statements for BRO\n",
      "\n",
      "Processing BF.B (Consumer Staples - Distillers & Vintners)...\n",
      "Error loading data for BF.B: [Errno 2] No such file or directory: '/Users/maseehfaizan/Desktop/Maseeh/Projects/Hybrid_Pricer/data/clean/BF.B.csv'\n",
      "Skipping BF.B - Could not load data.\n",
      "\n",
      "Processing BLDR (Industrials - Building Products)...\n",
      "Processing Industrials - Building Products... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Building Products → BuildingProducts\n",
      "Successfully generated financial statements for BLDR\n",
      "\n",
      "Processing BG (Consumer Staples - Agricultural Products & Services)...\n",
      "Processing Consumer Staples - Agricultural Products & Services... dict_keys(['AgriculturalProductsAndServices', 'Brewers', 'ConsumerStaplesMerchandiseRetail', 'DistillersAndVintners', 'DrugRetail', 'FoodDistributors', 'FoodRetail', 'HouseholdProducts', 'PackagedFoodsAndMeats', 'PersonalCareProducts', 'SoftDrinksNonAlcoholicBeverages', 'Tobacco'])\n",
      "Found mapping for Agricultural Products & Services → AgriculturalProductsAndServices\n",
      "Successfully generated financial statements for BG\n",
      "\n",
      "Processing BXP (Real Estate - Office REITs)...\n",
      "Processing Real Estate - Office REITs... dict_keys(['RealEstateServices', 'RetailREITs', 'SelfStorageREITs', 'SingleFamilyResidentialREITs', 'TelecomTowerREITs', 'TimberREITs', 'DataCenterREITs', 'HealthCareREITs', 'HotelResortREITs', 'IndustrialREITs', 'MultiFamilyResidentialREITs', 'OfficeREITs', 'OtherSpecializedREITs'])\n",
      "Using mapping for OfficeREITs (variant match with Office REITs)\n",
      "Successfully generated financial statements for BXP\n",
      "\n",
      "Processing CHRW (Industrials - Air Freight & Logistics)...\n",
      "Processing Industrials - Air Freight & Logistics... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Air Freight & Logistics → AirFreightLogistics\n",
      "Successfully generated financial statements for CHRW\n",
      "\n",
      "Processing CDNS (Information Technology - Application Software)...\n",
      "Processing Information Technology - Application Software... dict_keys(['ApplicationSoftware', 'ElectronicComponents', 'ElectronicEquipmentInstruments', 'ElectronicManufacturingServices', 'ItConsultingAndOtherServices', 'InternetServicesAndInfrastructure', 'SemiconductorMaterialsAndEquipment', 'Semiconductors', 'SystemsSoftware', 'TechnologyDistributors', 'TechnologyHardwareStoragePeripherals', 'CommunicationsEquipment'])\n",
      "Found mapping for Application Software → ApplicationSoftware\n",
      "Successfully generated financial statements for CDNS\n",
      "\n",
      "Processing CZR (Consumer Discretionary - Casinos & Gaming)...\n",
      "Processing Consumer Discretionary - Casinos & Gaming... dict_keys(['ApparelRetail', 'ApparelAccessoriesLuxuryGoods', 'AutomobileManufacturers', 'AutomotivePartsEquipment', 'AutomotiveRetail', 'BroadlineRetail', 'CasinosGaming', 'ComputerElectronicsRetail', 'ConsumerElectronics', 'Distributors', 'Footwear', 'HomeFurnishings', 'HomeImprovementRetail', 'Homebuilding', 'HotelsResortsCruiseLines', 'LeisureProducts', 'OtherSpecialtyRetail', 'Restaurants'])\n",
      "Found mapping for Casinos & Gaming → CasinosGaming\n",
      "Successfully generated financial statements for CZR\n",
      "\n",
      "Processing CPT (Real Estate - Multi-Family Residential REITs)...\n",
      "Processing Real Estate - Multi-Family Residential REITs... dict_keys(['RealEstateServices', 'RetailREITs', 'SelfStorageREITs', 'SingleFamilyResidentialREITs', 'TelecomTowerREITs', 'TimberREITs', 'DataCenterREITs', 'HealthCareREITs', 'HotelResortREITs', 'IndustrialREITs', 'MultiFamilyResidentialREITs', 'OfficeREITs', 'OtherSpecializedREITs'])\n",
      "Using mapping for MultiFamilyResidentialREITs (variant match with Multi-Family Residential REITs)\n",
      "Successfully generated financial statements for CPT\n",
      "\n",
      "Processing CPB (Consumer Staples - Packaged Foods & Meats)...\n",
      "Processing Consumer Staples - Packaged Foods & Meats... dict_keys(['AgriculturalProductsAndServices', 'Brewers', 'ConsumerStaplesMerchandiseRetail', 'DistillersAndVintners', 'DrugRetail', 'FoodDistributors', 'FoodRetail', 'HouseholdProducts', 'PackagedFoodsAndMeats', 'PersonalCareProducts', 'SoftDrinksNonAlcoholicBeverages', 'Tobacco'])\n",
      "Found mapping for Packaged Foods & Meats → PackagedFoodsAndMeats\n",
      "Successfully generated financial statements for CPB\n",
      "\n",
      "Processing COF (Financials - Consumer Finance)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Consumer Finance... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Consumer Finance → ConsumerFinance\n",
      "Successfully generated financial statements for COF\n",
      "\n",
      "Processing CAH (Health Care - Health Care Distributors)...\n",
      "Processing Health Care - Health Care Distributors... dict_keys(['Biotechnology', 'HealthCareDistributors', 'HealthCareEquipment', 'HealthCareFacilities', 'HealthCareServices', 'HealthCareSupplies', 'HealthCareTechnology', 'LifeSciencesToolsAndServicesAccounts', 'ManagedHealthCareAccounts', 'PharmaceuticalsAccounts'])\n",
      "Found mapping for Health Care Distributors → HealthCareDistributors\n",
      "Successfully generated financial statements for CAH\n",
      "\n",
      "Processing KMX (Consumer Discretionary - Automotive Retail)...\n",
      "Processing Consumer Discretionary - Automotive Retail... dict_keys(['ApparelRetail', 'ApparelAccessoriesLuxuryGoods', 'AutomobileManufacturers', 'AutomotivePartsEquipment', 'AutomotiveRetail', 'BroadlineRetail', 'CasinosGaming', 'ComputerElectronicsRetail', 'ConsumerElectronics', 'Distributors', 'Footwear', 'HomeFurnishings', 'HomeImprovementRetail', 'Homebuilding', 'HotelsResortsCruiseLines', 'LeisureProducts', 'OtherSpecialtyRetail', 'Restaurants'])\n",
      "Found mapping for Automotive Retail → AutomotiveRetail\n",
      "Successfully generated financial statements for KMX\n",
      "\n",
      "Processing CCL (Consumer Discretionary - Hotels, Resorts & Cruise Lines)...\n",
      "Processing Consumer Discretionary - Hotels, Resorts & Cruise Lines... dict_keys(['ApparelRetail', 'ApparelAccessoriesLuxuryGoods', 'AutomobileManufacturers', 'AutomotivePartsEquipment', 'AutomotiveRetail', 'BroadlineRetail', 'CasinosGaming', 'ComputerElectronicsRetail', 'ConsumerElectronics', 'Distributors', 'Footwear', 'HomeFurnishings', 'HomeImprovementRetail', 'Homebuilding', 'HotelsResortsCruiseLines', 'LeisureProducts', 'OtherSpecialtyRetail', 'Restaurants'])\n",
      "Found mapping for Hotels, Resorts & Cruise Lines → HotelsResortsCruiseLines\n",
      "Successfully generated financial statements for CCL\n",
      "\n",
      "Processing CARR (Industrials - Building Products)...\n",
      "Processing Industrials - Building Products... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Building Products → BuildingProducts\n",
      "Successfully generated financial statements for CARR\n",
      "\n",
      "Processing CAT (Industrials - Construction Machinery & Heavy Transportation Equipment)...\n",
      "Processing Industrials - Construction Machinery & Heavy Transportation Equipment... dict_keys(['AerospaceDefense', 'AgriculturalFarmMachinery', 'AirFreightLogistics', 'BuildingProducts', 'CargoGroundTransportation', 'ConstructionEngineering', 'DataProcessingOutsourcedServices', 'ElectricalComponentsEquipment', 'DiversifiedSupportServices', 'EnvironmentalAndFacilitiesServices', 'HeavyElectricalEquipment', 'HumanResourceAndEmploymentServices', 'IndustrialConglomerates', 'IndustrialMachineryAndSuppliesAndComponents', 'PassengerAirlines', 'PassengerGroundTransportation', 'RailTransportation', 'ResearchAndConsultingServices', 'TradingCompaniesAndDistributors', 'ConstructionMachineryHeavyTransportationEquipment'])\n",
      "Found mapping for Construction Machinery & Heavy Transportation Equipment → ConstructionMachineryHeavyTransportationEquipment\n",
      "Successfully generated financial statements for CAT\n",
      "\n",
      "Processing CBOE (Financials - Financial Exchanges & Data)...\n",
      "dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Processing Financials - Financial Exchanges & Data... dict_keys(['AssetManagementCustodyBanks', 'ConsumerFinance', 'PropertyCasualtyInsurance', 'DiversifiedBanks', 'FinancialExchangesData', 'InsuranceBrokers', 'InvestmentBankingBrokerage', 'LifeHealthInsurance', 'MultiLineInsurance', 'RegionalBanks', 'Reinsurance', 'TransactionPaymentProcessingServices'])\n",
      "Found mapping for Financial Exchanges & Data → FinancialExchangesData\n",
      "Successfully generated financial statements for CBOE\n",
      "\n",
      "Processing CBRE (Real Estate - Real Estate Services)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 665\u001b[39m\n\u001b[32m    662\u001b[39m     sp500 = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m./data/sp500.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    664\u001b[39m     \u001b[38;5;66;03m# Process all companies with specified directories\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[43mprocess_sp500_companies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[43msp500_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43msp500\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/Users/maseehfaizan/Desktop/Maseeh/Projects/Hybrid_Pricer/data/clean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Where ticker.csv files are stored\u001b[39;49;00m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmappings_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/Users/maseehfaizan/Desktop/XBRL_dic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Where sector.py files are stored\u001b[39;49;00m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/Users/maseehfaizan/Desktop/Maseeh/Projects/Hybrid_Pricer/data/financial_statement\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Where to save the generated financial statements\u001b[39;49;00m\n\u001b[32m    670\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 477\u001b[39m, in \u001b[36mprocess_sp500_companies\u001b[39m\u001b[34m(sp500_df, data_dir, mappings_dir, output_dir)\u001b[39m\n\u001b[32m    474\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msector\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msub_industry\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    476\u001b[39m \u001b[38;5;66;03m# Load company data with specified directory\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m df = \u001b[43mload_company_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    479\u001b[39m     debug_msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Could not load data.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 159\u001b[39m, in \u001b[36mload_company_data\u001b[39m\u001b[34m(ticker, data_dir)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    158\u001b[39m     filepath = os.path.join(data_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:236\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    234\u001b[39m     chunks = \u001b[38;5;28mself\u001b[39m._reader.read_low_memory(nrows)\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     data = \u001b[43m_concatenate_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    239\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._reader.read(nrows)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:370\u001b[39m, in \u001b[36m_concatenate_chunks\u001b[39m\u001b[34m(chunks)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# Check each arr for consistent types.\u001b[39;00m\n\u001b[32m    369\u001b[39m dtypes = {a.dtype \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrs}\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m non_cat_dtypes = {x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dtypes \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, CategoricalDtype)}\n\u001b[32m    372\u001b[39m dtype = dtypes.pop()\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, CategoricalDtype):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Global list to store mapping debug information\n",
    "mapping_debug_log = []\n",
    "\n",
    "# Function to load industry mappings from sector-specific Python files\n",
    "# Function to load industry mappings from sector-specific Python files\n",
    "def load_industry_mapping(sector, sub_industry, mappings_dir='.'):\n",
    "    \"\"\"\n",
    "    Load the appropriate industry mapping based on sector and sub-industry.\n",
    "    \n",
    "    Args:\n",
    "        sector (str): GICS Sector \n",
    "        sub_industry (str): GICS Sub-Industry\n",
    "        mappings_dir (str): Directory containing the mapping Python files\n",
    "        \n",
    "    Returns:\n",
    "        dict: The mapping dictionary for the specified sector and sub-industry\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert sector name to filename format\n",
    "        sector_file = sector.lower().replace(' ', '').replace('&', '').replace('-', '') + '.py'\n",
    "        \n",
    "        # Check if file exists (using the specified directory)\n",
    "        sector_file_path = os.path.join(mappings_dir, sector_file)\n",
    "        if not os.path.exists(sector_file_path):\n",
    "            debug_msg = f\"Warning: Mapping file {sector_file_path} not found for {sector} - {sub_industry}.\"\n",
    "            print(debug_msg)\n",
    "            mapping_debug_log.append(debug_msg)\n",
    "            return None\n",
    "        \n",
    "        # Load the module dynamically\n",
    "        spec = importlib.util.spec_from_file_location(sector.lower(), sector_file_path)\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "        \n",
    "        # Get the industry mappings\n",
    "        if hasattr(module, 'industry_mappings'):\n",
    "            industry_mappings = module.industry_mappings\n",
    "            \n",
    "            # Log available keys for debugging\n",
    "            available_keys = list(industry_mappings.keys())\n",
    "            debug_msg = f\"Processing {sector} - {sub_industry}... dict_keys({available_keys})\"\n",
    "            print(debug_msg)\n",
    "            mapping_debug_log.append(debug_msg)\n",
    "            \n",
    "            # Try multiple normalization strategies to find a match\n",
    "            \n",
    "            # Strategy 1: Direct key lookup without normalization\n",
    "            if sub_industry in industry_mappings:\n",
    "                debug_msg = f\"Found direct mapping for {sub_industry}\"\n",
    "                print(debug_msg)\n",
    "                mapping_debug_log.append(debug_msg)\n",
    "                return industry_mappings[sub_industry]\n",
    "            \n",
    "            # Generate different normalized versions of the sub_industry\n",
    "            normalized_versions = [\n",
    "                # Strategy 2: PascalCase with '&' → 'And'\n",
    "                ''.join(word.capitalize() for word in sub_industry.replace('&', ' And ').split()),\n",
    "                \n",
    "                # Strategy 3: PascalCase with '&' removed\n",
    "                ''.join(word.capitalize() for word in sub_industry.replace('&', ' ').split()),\n",
    "                \n",
    "                # Strategy 4: PascalCase with all punctuation removed\n",
    "                ''.join(word.capitalize() for word in ''.join(c if c.isalnum() or c.isspace() else ' ' for c in sub_industry).split()),\n",
    "            ]\n",
    "            \n",
    "            # Try each normalized version\n",
    "            for normalized in normalized_versions:\n",
    "                if normalized in industry_mappings:\n",
    "                    debug_msg = f\"Found mapping for {sub_industry} → {normalized}\"\n",
    "                    print(debug_msg)\n",
    "                    mapping_debug_log.append(debug_msg)\n",
    "                    return industry_mappings[normalized]\n",
    "            \n",
    "            # Try more aggressive partial matching approaches\n",
    "            # Create multiple normalized versions for comparison\n",
    "            sub_variants = [\n",
    "                # Remove spaces, convert to lowercase\n",
    "                sub_industry.lower().replace(' ', ''),\n",
    "                \n",
    "                # Remove spaces, '&', convert to lowercase\n",
    "                sub_industry.lower().replace(' ', '').replace('&', ''),\n",
    "                \n",
    "                # Replace '&' with 'and', remove spaces, convert to lowercase\n",
    "                sub_industry.lower().replace(' ', '').replace('&', 'and'),\n",
    "                \n",
    "                # Remove all non-alphanumeric chars, convert to lowercase\n",
    "                ''.join(c.lower() for c in sub_industry if c.isalnum())\n",
    "            ]\n",
    "            \n",
    "            # Try to match with each key using the variants\n",
    "            for key in industry_mappings:\n",
    "                # Create similar variants for the key\n",
    "                key_variants = [\n",
    "                    # Remove spaces, convert to lowercase\n",
    "                    key.lower().replace(' ', ''),\n",
    "                    \n",
    "                    # Remove spaces, 'And', convert to lowercase\n",
    "                    key.lower().replace(' ', '').replace('and', ''),\n",
    "                    \n",
    "                    # Remove all non-alphanumeric chars, convert to lowercase\n",
    "                    ''.join(c.lower() for c in key if c.isalnum())\n",
    "                ]\n",
    "                \n",
    "                # Check if any variant of sub_industry matches any variant of key\n",
    "                for sub_var in sub_variants:\n",
    "                    for key_var in key_variants:\n",
    "                        if sub_var == key_var or sub_var in key_var or key_var in sub_var:\n",
    "                            debug_msg = f\"Using mapping for {key} (variant match with {sub_industry})\"\n",
    "                            print(debug_msg)\n",
    "                            mapping_debug_log.append(debug_msg)\n",
    "                            return industry_mappings[key]\n",
    "                \n",
    "                # Special case for 'Accounts' suffix\n",
    "                if 'accounts' in key.lower():\n",
    "                    key_no_accounts = key.lower().replace('accounts', '')\n",
    "                    for sub_var in sub_variants:\n",
    "                        if sub_var in key_no_accounts or key_no_accounts in sub_var:\n",
    "                            debug_msg = f\"Using mapping for {key} (matched after removing 'Accounts')\"\n",
    "                            print(debug_msg)\n",
    "                            mapping_debug_log.append(debug_msg)\n",
    "                            return industry_mappings[key]\n",
    "            \n",
    "            # Use first industry mapping as fallback\n",
    "            default_key = next(iter(industry_mappings.keys()))\n",
    "            debug_msg = f\"No specific mapping found for {sub_industry}. Using default mapping for {sector}: {default_key}\"\n",
    "            print(debug_msg)\n",
    "            mapping_debug_log.append(debug_msg)\n",
    "            return industry_mappings[default_key]\n",
    "        else:\n",
    "            debug_msg = f\"No industry_mappings found in {sector_file} for {sector} - {sub_industry}.\"\n",
    "            print(debug_msg)\n",
    "            mapping_debug_log.append(debug_msg)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        debug_msg = f\"Error loading industry mapping for {sector} - {sub_industry}: {str(e)}\"\n",
    "        print(debug_msg)\n",
    "        mapping_debug_log.append(debug_msg)\n",
    "        return None\n",
    "\n",
    "# Load company data from CSV\n",
    "def load_company_data(ticker, data_dir='clean'):\n",
    "    \"\"\"\n",
    "    Load financial data for a specific company.\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Company ticker symbol\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Financial data for the company\n",
    "    \"\"\"\n",
    "    try:\n",
    "        filepath = os.path.join(data_dir, f\"{ticker}.csv\")\n",
    "        df = pd.read_csv(filepath)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Helper function to extract account value using mapping info\n",
    "# Updated helper function to extract account value using mapping info\n",
    "def extract_account_value(df, account_info, available_columns):\n",
    "    \"\"\"\n",
    "    Extract account value from financial data using mapping information.\n",
    "    Checks cell by cell, using alternatives if primary value is NaN.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Company financial data\n",
    "        account_info (dict): Account mapping information\n",
    "        available_columns (set): Available columns in the DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        Series: Account value from primary or alternatives\n",
    "    \"\"\"\n",
    "    # Initialize result series with NaN values\n",
    "    result = pd.Series(np.nan, index=df.index)\n",
    "    \n",
    "    # Iterate through each row (each reporting period)\n",
    "    for idx in df.index:\n",
    "        # Check primary tag first\n",
    "        if 'primary' in account_info and account_info['primary'] in available_columns:\n",
    "            primary_value = df.at[idx, account_info['primary']]\n",
    "            \n",
    "            # If primary value exists and is not NaN, use it\n",
    "            if pd.notna(primary_value):\n",
    "                result.at[idx] = primary_value\n",
    "                continue\n",
    "        \n",
    "        # If primary is NaN or missing, check alternatives\n",
    "        if 'alternatives' in account_info:\n",
    "            for alt in account_info['alternatives']:\n",
    "                if alt in available_columns:\n",
    "                    alt_value = df.at[idx, alt]\n",
    "                    if pd.notna(alt_value):\n",
    "                        result.at[idx] = alt_value\n",
    "                        break  # Use first non-NaN alternative\n",
    "        \n",
    "        # If still NaN, try children as a sum if available\n",
    "        if pd.isna(result.at[idx]) and 'children' in account_info and account_info['children']:\n",
    "            child_values = []\n",
    "            for child in account_info['children']:\n",
    "                if child in available_columns and pd.notna(df.at[idx, child]):\n",
    "                    child_values.append(df.at[idx, child])\n",
    "            \n",
    "            # If we found any child values, sum them\n",
    "            if child_values:\n",
    "                result.at[idx] = sum(child_values)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Function to reconstruct balance sheet\n",
    "def reconstruct_balance_sheet(df, industry_mapping):\n",
    "    \"\"\"\n",
    "    Reconstruct balance sheet using industry-specific mappings.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Company financial data\n",
    "        industry_mapping (dict): Industry-specific mappings\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Reconstructed balance sheet\n",
    "    \"\"\"\n",
    "    # Create new DataFrame for balance sheet\n",
    "    balance_sheet = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Copy metadata columns\n",
    "    id_columns = ['filed', 'company_name', 'end', 'unit', 'form', 'frame', 'cik']\n",
    "    for col in id_columns:\n",
    "        if col in df.columns:\n",
    "            balance_sheet[col] = df[col]\n",
    "    \n",
    "    # Get available columns\n",
    "    available_columns = set(df.columns)\n",
    "    \n",
    "    # Process balance sheet sections dynamically\n",
    "    balance_sheet_sections = ['Assets', 'Liabilities', 'Equity']\n",
    "    \n",
    "    for section in balance_sheet_sections:\n",
    "        if section in industry_mapping:\n",
    "            # Iterate through all sub-accounts in this section as defined in the mapping\n",
    "            for account_name, account_info in industry_mapping[section].items():\n",
    "                value = extract_account_value(df, account_info, available_columns)\n",
    "                balance_sheet[f\"{section} - {account_name}\"] = value\n",
    "    \n",
    "    # Add missing totals and validate\n",
    "    balance_sheet = add_missing_balance_sheet_totals(balance_sheet)\n",
    "    \n",
    "    # Remove columns with only NaN values\n",
    "    balance_sheet = remove_nan_only_columns(balance_sheet)\n",
    "    \n",
    "    return balance_sheet\n",
    "\n",
    "# Function to reconstruct income statement\n",
    "def reconstruct_income_statement(df, industry_mapping):\n",
    "    \"\"\"\n",
    "    Reconstruct income statement using industry-specific mappings.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Company financial data\n",
    "        industry_mapping (dict): Industry-specific mappings\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Reconstructed income statement\n",
    "    \"\"\"\n",
    "    # Create new DataFrame for income statement\n",
    "    income_statement = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Copy metadata columns\n",
    "    id_columns = ['filed', 'company_name', 'end', 'unit', 'form', 'frame', 'cik']\n",
    "    for col in id_columns:\n",
    "        if col in df.columns:\n",
    "            income_statement[col] = df[col]\n",
    "    \n",
    "    # Get available columns\n",
    "    available_columns = set(df.columns)\n",
    "    \n",
    "    # Process Income Statement dynamically\n",
    "    if 'IncomeStatement' in industry_mapping:\n",
    "        income_mapping = industry_mapping['IncomeStatement']\n",
    "        \n",
    "        # Iterate through all sections in the income statement mapping\n",
    "        for section_name, section_data in income_mapping.items():\n",
    "            # Check if this is a nested structure or direct account mapping\n",
    "            if isinstance(section_data, dict) and 'primary' in section_data:\n",
    "                # Direct account mapping (unnested)\n",
    "                value = extract_account_value(df, section_data, available_columns)\n",
    "                income_statement[f\"IncomeStatement - {section_name}\"] = value\n",
    "            else:\n",
    "                # Nested structure - process each account in the section\n",
    "                for account_name, account_info in section_data.items():\n",
    "                    # Check if this is a further nested structure\n",
    "                    if isinstance(account_info, dict) and 'primary' in account_info:\n",
    "                        # Direct account mapping\n",
    "                        value = extract_account_value(df, account_info, available_columns)\n",
    "                        income_statement[f\"IncomeStatement - {section_name} - {account_name}\"] = value\n",
    "                    else:\n",
    "                        # Further nested structure\n",
    "                        for sub_account_name, sub_account_info in account_info.items():\n",
    "                            value = extract_account_value(df, sub_account_info, available_columns)\n",
    "                            income_statement[f\"IncomeStatement - {section_name} - {account_name} - {sub_account_name}\"] = value\n",
    "    \n",
    "    # Remove columns with only NaN values\n",
    "    income_statement = remove_nan_only_columns(income_statement)\n",
    "    \n",
    "    return income_statement\n",
    "\n",
    "# Function to reconstruct cash flow statement\n",
    "def reconstruct_cash_flow_statement(df, industry_mapping):\n",
    "    \"\"\"\n",
    "    Reconstruct cash flow statement using industry-specific mappings.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Company financial data\n",
    "        industry_mapping (dict): Industry-specific mappings\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Reconstructed cash flow statement\n",
    "    \"\"\"\n",
    "    # Create new DataFrame for cash flow statement\n",
    "    cash_flow = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Copy metadata columns\n",
    "    id_columns = ['filed', 'company_name', 'end', 'unit', 'form', 'frame', 'cik']\n",
    "    for col in id_columns:\n",
    "        if col in df.columns:\n",
    "            cash_flow[col] = df[col]\n",
    "    \n",
    "    # Get available columns\n",
    "    available_columns = set(df.columns)\n",
    "    \n",
    "    # Process Cash Flow Statement dynamically\n",
    "    if 'CashFlowStatement' in industry_mapping:\n",
    "        cf_mapping = industry_mapping['CashFlowStatement']\n",
    "        \n",
    "        # Iterate through all sections in the cash flow mapping\n",
    "        for section_name, section_data in cf_mapping.items():\n",
    "            # Process each account in the section\n",
    "            for account_name, account_info in section_data.items():\n",
    "                # Check if this is a nested structure\n",
    "                if isinstance(account_info, dict) and 'primary' in account_info:\n",
    "                    # Direct account mapping\n",
    "                    value = extract_account_value(df, account_info, available_columns)\n",
    "                    cash_flow[f\"CashFlow - {section_name} - {account_name}\"] = value\n",
    "                else:\n",
    "                    # Nested structure\n",
    "                    for sub_account_name, sub_account_info in account_info.items():\n",
    "                        value = extract_account_value(df, sub_account_info, available_columns)\n",
    "                        cash_flow[f\"CashFlow - {section_name} - {account_name} - {sub_account_name}\"] = value\n",
    "    \n",
    "    # Remove columns with only NaN values\n",
    "    cash_flow = remove_nan_only_columns(cash_flow)\n",
    "    \n",
    "    return cash_flow\n",
    "\n",
    "# Function to add missing balance sheet totals (including your validation logic)\n",
    "def add_missing_balance_sheet_totals(balance_sheet):\n",
    "    \"\"\"\n",
    "    Adds missing total columns according to accounting relationships.\n",
    "    \n",
    "    Args:\n",
    "        balance_sheet: DataFrame with reconstructed balance sheet\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with missing totals computed where possible and validation columns\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    result = balance_sheet.copy()\n",
    "    \n",
    "    # Define key total column names\n",
    "    total_assets_col = 'Assets - Total Assets'\n",
    "    total_liabilities_col = 'Liabilities - TotalLiabilities'\n",
    "    total_equity_col = 'Equity - TotalStockholdersEquity'\n",
    "    total_liab_equity_col = 'Equity - TotalLiabilitiesandEquity'\n",
    "    \n",
    "    # Ensure total columns exist before attempting calculations row-wise\n",
    "    for col in [total_assets_col, total_liabilities_col, total_equity_col, total_liab_equity_col]:\n",
    "        if col not in result.columns:\n",
    "            result[col] = pd.NA\n",
    "    \n",
    "    # Process row by row to handle NaN values in specific cells\n",
    "    for idx, row in result.iterrows():\n",
    "        # Case 1: Compute missing Total Liabilities\n",
    "        if (pd.notna(row[total_liab_equity_col]) and\n",
    "            pd.notna(row[total_equity_col]) and\n",
    "            pd.isna(row[total_liabilities_col])):\n",
    "            result.at[idx, total_liabilities_col] = (row[total_liab_equity_col] -\n",
    "                                                    row[total_equity_col])\n",
    "        \n",
    "        # Case 2: Compute missing Total Stockholders Equity\n",
    "        if (pd.notna(row[total_liab_equity_col]) and\n",
    "            pd.notna(row[total_liabilities_col]) and\n",
    "            pd.isna(row[total_equity_col])):\n",
    "            result.at[idx, total_equity_col] = (row[total_liab_equity_col] -\n",
    "                                              row[total_liabilities_col])\n",
    "        \n",
    "        # Case 3: Compute missing Total Liabilities and Equity\n",
    "        if pd.isna(row[total_liab_equity_col]):\n",
    "            if pd.notna(row[total_assets_col]):\n",
    "                # Set Total Liabilities and Equity = Total Assets (accounting equality)\n",
    "                result.at[idx, total_liab_equity_col] = row[total_assets_col]\n",
    "            elif (pd.notna(row[total_liabilities_col]) and\n",
    "                  pd.notna(row[total_equity_col])):\n",
    "                # Compute Total Liabilities and Equity as sum of components\n",
    "                result.at[idx, total_liab_equity_col] = (row[total_liabilities_col] +\n",
    "                                                       row[total_equity_col])\n",
    "    \n",
    "    # Add validation columns\n",
    "    result['Validation - A = L+E Difference'] = (result[total_assets_col] -\n",
    "                                               result[total_liab_equity_col])\n",
    "    \n",
    "    # This check validates if the sum of Liabilities and Equity components equals Total Liabilities and Equity\n",
    "    if total_liabilities_col in result.columns and total_equity_col in result.columns:\n",
    "        result['Validation - L+E Components Sum Difference'] = (result[total_liabilities_col] +\n",
    "                                                              result[total_equity_col] -\n",
    "                                                              result[total_liab_equity_col])\n",
    "    else:\n",
    "        result['Validation - L+E Components Sum Difference'] = pd.NA\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Function to remove columns that only contain NaN values\n",
    "def remove_nan_only_columns(df):\n",
    "    \"\"\"\n",
    "    Removes columns that contain only NaN values.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to clean\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with NaN-only columns removed\n",
    "    \"\"\"\n",
    "    nan_cols = df.columns[df.isnull().all()].tolist()\n",
    "    return df.drop(columns=nan_cols)\n",
    "\n",
    "# Function to process SP500 companies with debug logging\n",
    "def process_sp500_companies(sp500_df, data_dir='clean', mappings_dir='.', output_dir='output'):\n",
    "    \"\"\"\n",
    "    Process all S&P 500 companies to generate financial statements.\n",
    "    \n",
    "    Args:\n",
    "        sp500_df (DataFrame): S&P 500 companies data\n",
    "        data_dir (str): Directory containing company CSV files\n",
    "        mappings_dir (str): Directory containing mapping Python files\n",
    "        output_dir (str): Directory to save output files\n",
    "        \n",
    "    Returns:\n",
    "        dict: Debug information including mapping issues\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Track success and failures\n",
    "    results = {\n",
    "        'processed_successfully': [],\n",
    "        'failed_processing': [],\n",
    "        'mapping_issues': []\n",
    "    }\n",
    "    \n",
    "    # Process each company\n",
    "    for idx, row in sp500_df.iterrows():\n",
    "        ticker = row['Symbol']\n",
    "        sector = row['GICS Sector']\n",
    "        sub_industry = row['GICS Sub-Industry']\n",
    "        \n",
    "        # Clear previous entries in the global debug log for this company\n",
    "        global mapping_debug_log\n",
    "        mapping_debug_log = []\n",
    "        \n",
    "        print(f\"\\nProcessing {ticker} ({sector} - {sub_industry})...\")\n",
    "        \n",
    "        # Load company data with specified directory\n",
    "        df = load_company_data(ticker, data_dir=data_dir)\n",
    "        if df is None:\n",
    "            debug_msg = f\"Skipping {ticker} - Could not load data.\"\n",
    "            print(debug_msg)\n",
    "            results['failed_processing'].append({\n",
    "                'ticker': ticker,\n",
    "                'sector': sector,\n",
    "                'sub_industry': sub_industry,\n",
    "                'reason': 'Data load failure'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Load industry mapping with specified directory\n",
    "        industry_mapping = load_industry_mapping(sector, sub_industry, mappings_dir=mappings_dir)\n",
    "        if industry_mapping is None:\n",
    "            debug_msg = f\"Skipping {ticker} - Could not load industry mapping.\"\n",
    "            print(debug_msg)\n",
    "            results['failed_processing'].append({\n",
    "                'ticker': ticker,\n",
    "                'sector': sector,\n",
    "                'sub_industry': sub_industry,\n",
    "                'reason': 'Mapping load failure'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Generate balance sheet\n",
    "            balance_sheet = reconstruct_balance_sheet(df, industry_mapping)\n",
    "            balance_sheet_path = os.path.join(output_dir, f\"{ticker}_balance_sheet.csv\")\n",
    "            balance_sheet.to_csv(balance_sheet_path, index=False)\n",
    "            \n",
    "            # Generate income statement\n",
    "            income_statement = reconstruct_income_statement(df, industry_mapping)\n",
    "            income_statement_path = os.path.join(output_dir, f\"{ticker}_income_statement.csv\")\n",
    "            income_statement.to_csv(income_statement_path, index=False)\n",
    "            \n",
    "            # Generate cash flow statement\n",
    "            cash_flow = reconstruct_cash_flow_statement(df, industry_mapping)\n",
    "            cash_flow_path = os.path.join(output_dir, f\"{ticker}_cash_flow.csv\")\n",
    "            cash_flow.to_csv(cash_flow_path, index=False)\n",
    "            \n",
    "            success_msg = f\"Successfully generated financial statements for {ticker}\"\n",
    "            print(success_msg)\n",
    "            \n",
    "            # Record success\n",
    "            results['processed_successfully'].append({\n",
    "                'ticker': ticker,\n",
    "                'sector': sector,\n",
    "                'sub_industry': sub_industry\n",
    "            })\n",
    "            \n",
    "            # If we used default mapping, record this as a mapping issue\n",
    "            if any(\"No specific mapping found\" in log for log in mapping_debug_log):\n",
    "                results['mapping_issues'].append({\n",
    "                    'ticker': ticker,\n",
    "                    'sector': sector,\n",
    "                    'sub_industry': sub_industry,\n",
    "                    'debug_logs': mapping_debug_log.copy()\n",
    "                })\n",
    "        \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing {ticker}: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            results['failed_processing'].append({\n",
    "                'ticker': ticker,\n",
    "                'sector': sector,\n",
    "                'sub_industry': sub_industry,\n",
    "                'reason': str(e)\n",
    "            })\n",
    "            continue\n",
    "    \n",
    "    # Save the debug results to a JSON file\n",
    "    debug_file_path = os.path.join(output_dir, \"mapping_debug_results.json\")\n",
    "    import json\n",
    "    with open(debug_file_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nDebug information saved to: {debug_file_path}\")\n",
    "    return results\n",
    "\n",
    "# Function to extract and show mapping issues\n",
    "def show_mapping_issues(results=None):\n",
    "    \"\"\"\n",
    "    Display mapping issues from processing results.\n",
    "    \n",
    "    Args:\n",
    "        results: Results dictionary from process_sp500_companies\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with mapping issues\n",
    "    \"\"\"\n",
    "    if results is None:\n",
    "        # Try to load results from the default location\n",
    "        import json\n",
    "        try:\n",
    "            with open(\"output/mapping_debug_results.json\", 'r') as f:\n",
    "                results = json.load(f)\n",
    "        except:\n",
    "            print(\"No results file found. Run process_sp500_companies first.\")\n",
    "            return None\n",
    "    \n",
    "    # Extract mapping issues\n",
    "    issues_data = []\n",
    "    for issue in results['mapping_issues']:\n",
    "        for log in issue['debug_logs']:\n",
    "            if \"No specific mapping found\" in log:\n",
    "                issues_data.append({\n",
    "                    'ticker': issue['ticker'],\n",
    "                    'sector': issue['sector'],\n",
    "                    'sub_industry': issue['sub_industry'],\n",
    "                    'log_message': log\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if issues_data:\n",
    "        import pandas as pd\n",
    "        issues_df = pd.DataFrame(issues_data)\n",
    "        return issues_df\n",
    "    else:\n",
    "        print(\"No mapping issues found.\")\n",
    "        return None\n",
    "\n",
    "# Display formatted balance sheet (optional for visualization)\n",
    "def display_balance_sheet(balance_sheet, in_billions=True):\n",
    "    \"\"\"\n",
    "    Display balance sheet in a readable format.\n",
    "    \n",
    "    Args:\n",
    "        balance_sheet: DataFrame with balance sheet data\n",
    "        in_billions: If True, display in billions; otherwise in millions\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with formatted balance sheet\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    formatted_bs = balance_sheet.copy()\n",
    "    \n",
    "    # Identify numeric columns\n",
    "    numeric_cols = [col for col in formatted_bs.columns \n",
    "                   if any(col.startswith(prefix) for prefix in ['Assets', 'Liabilities', 'Equity', 'Validation'])]\n",
    "    \n",
    "    # Convert to billions or millions\n",
    "    divisor = 1_000_000_000 if in_billions else 1_000_000\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        # Check if the column is numeric before dividing\n",
    "        if pd.api.types.is_numeric_dtype(formatted_bs[col]):\n",
    "            formatted_bs[col] = formatted_bs[col] / divisor\n",
    "    \n",
    "    # Format the date column if it exists\n",
    "    if 'end' in formatted_bs.columns:\n",
    "        try:\n",
    "            formatted_bs['end'] = pd.to_datetime(formatted_bs['end']).dt.strftime('%Y-%m-%d')\n",
    "        except:\n",
    "            pass  # Keep original format if conversion fails\n",
    "    \n",
    "    # Organize columns by section\n",
    "    metadata_cols = ['filed', 'company_name', 'end', 'unit', 'form', 'frame', 'cik']\n",
    "    asset_cols = [col for col in formatted_bs.columns if col.startswith('Assets')]\n",
    "    liability_cols = [col for col in formatted_bs.columns if col.startswith('Liabilities')]\n",
    "    equity_cols = [col for col in formatted_bs.columns if col.startswith('Equity')]\n",
    "    validation_cols = [col for col in formatted_bs.columns if col.startswith('Validation')]\n",
    "    \n",
    "    # Create ordered list of columns\n",
    "    ordered_cols = (\n",
    "        [col for col in metadata_cols if col in formatted_bs.columns] +\n",
    "        sorted([col for col in asset_cols if 'Total' not in col]) +\n",
    "        sorted([col for col in asset_cols if 'Total' in col]) +\n",
    "        sorted([col for col in liability_cols if 'Total' not in col]) +\n",
    "        sorted([col for col in liability_cols if 'Total' in col]) +\n",
    "        sorted([col for col in equity_cols if 'Total' not in col and 'Liabilities and Equity' not in col]) +\n",
    "        sorted([col for col in equity_cols if 'Total Stockholders Equity' in col]) +\n",
    "        sorted([col for col in equity_cols if 'Liabilities and Equity' in col]) +\n",
    "        validation_cols\n",
    "    )\n",
    "    \n",
    "    # Only include columns that actually exist\n",
    "    final_cols = [col for col in ordered_cols if col in formatted_bs.columns]\n",
    "    \n",
    "    return formatted_bs[final_cols]\n",
    "\n",
    "# Main execution\n",
    "# Load S&P 500 companies data\n",
    "# Load S&P 500 companies data\n",
    "sp500 = pd.read_csv('./data/sp500.csv')\n",
    "\n",
    "# Process all companies with specified directories\n",
    "process_sp500_companies(\n",
    "    sp500_df=sp500,\n",
    "    data_dir='/Users/maseehfaizan/Desktop/Maseeh/Projects/Hybrid_Pricer/data/clean', \n",
    "    mappings_dir='./data/XBRL_dic',  \n",
    "    output_dir='/Users/maseehfaizan/Desktop/Maseeh/Projects/Hybrid_Pricer/data/financial_statement'     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ticker: MTCH\n",
      "Files: ['MTCH_cash_flow.csv', 'MTCH_income_statement.csv', 'MTCH_balance_sheet.csv']\n",
      "Saved: MTCH_master.csv\n",
      "Processing ticker: HWM\n",
      "Files: ['HWM_cash_flow.csv', 'HWM_balance_sheet.csv', 'HWM_income_statement.csv']\n",
      "Saved: HWM_master.csv\n",
      "Processing ticker: IRM\n",
      "Files: ['IRM_cash_flow.csv', 'IRM_balance_sheet.csv', 'IRM_income_statement.csv']\n",
      "Saved: IRM_master.csv\n",
      "Processing ticker: AWK\n",
      "Files: ['AWK_balance_sheet.csv', 'AWK_cash_flow.csv', 'AWK_income_statement.csv']\n",
      "Saved: AWK_master.csv\n",
      "Processing ticker: MMM\n",
      "Files: ['MMM_balance_sheet.csv', 'MMM_cash_flow.csv', 'MMM_income_statement.csv']\n",
      "Saved: MMM_master.csv\n",
      "Processing ticker: AMD\n",
      "Files: ['AMD_income_statement.csv', 'AMD_balance_sheet.csv', 'AMD_cash_flow.csv']\n",
      "Saved: AMD_master.csv\n",
      "Processing ticker: ESS\n",
      "Files: ['ESS_cash_flow.csv', 'ESS_income_statement.csv', 'ESS_balance_sheet.csv']\n",
      "Saved: ESS_master.csv\n",
      "Processing ticker: DGX\n",
      "Files: ['DGX_cash_flow.csv', 'DGX_balance_sheet.csv', 'DGX_income_statement.csv']\n",
      "Saved: DGX_master.csv\n",
      "Processing ticker: SYK\n",
      "Files: ['SYK_income_statement.csv', 'SYK_balance_sheet.csv', 'SYK_cash_flow.csv']\n",
      "Saved: SYK_master.csv\n",
      "Processing ticker: EBAY\n",
      "Files: ['EBAY_cash_flow.csv', 'EBAY_balance_sheet.csv', 'EBAY_income_statement.csv']\n",
      "Saved: EBAY_master.csv\n",
      "Processing ticker: NVR\n",
      "Files: ['NVR_cash_flow.csv', 'NVR_balance_sheet.csv', 'NVR_income_statement.csv']\n",
      "Saved: NVR_master.csv\n",
      "Processing ticker: TRV\n",
      "Files: ['TRV_balance_sheet.csv', 'TRV_cash_flow.csv', 'TRV_income_statement.csv']\n",
      "Saved: TRV_master.csv\n",
      "Processing ticker: SLB\n",
      "Files: ['SLB_cash_flow.csv', 'SLB_balance_sheet.csv', 'SLB_income_statement.csv']\n",
      "Saved: SLB_master.csv\n",
      "Processing ticker: ALLE\n",
      "Files: ['ALLE_balance_sheet.csv', 'ALLE_cash_flow.csv', 'ALLE_income_statement.csv']\n",
      "Saved: ALLE_master.csv\n",
      "Processing ticker: NFLX\n",
      "Files: ['NFLX_cash_flow.csv', 'NFLX_balance_sheet.csv', 'NFLX_income_statement.csv']\n",
      "Saved: NFLX_master.csv\n",
      "Processing ticker: NDAQ\n",
      "Files: ['NDAQ_income_statement.csv', 'NDAQ_balance_sheet.csv', 'NDAQ_cash_flow.csv']\n",
      "Saved: NDAQ_master.csv\n",
      "Processing ticker: BK\n",
      "Files: ['BK_income_statement.csv', 'BK_balance_sheet.csv', 'BK_cash_flow.csv']\n",
      "Saved: BK_master.csv\n",
      "Processing ticker: DELL\n",
      "Files: ['DELL_cash_flow.csv', 'DELL_balance_sheet.csv', 'DELL_income_statement.csv']\n",
      "Saved: DELL_master.csv\n",
      "Processing ticker: GL\n",
      "Files: ['GL_cash_flow.csv', 'GL_balance_sheet.csv', 'GL_income_statement.csv']\n",
      "Saved: GL_master.csv\n",
      "Processing ticker: CRL\n",
      "Files: ['CRL_cash_flow.csv', 'CRL_balance_sheet.csv', 'CRL_income_statement.csv']\n",
      "Saved: CRL_master.csv\n",
      "Processing ticker: HSY\n",
      "Files: ['HSY_income_statement.csv', 'HSY_balance_sheet.csv', 'HSY_cash_flow.csv']\n",
      "Saved: HSY_master.csv\n",
      "Processing ticker: AVY\n",
      "Files: ['AVY_balance_sheet.csv', 'AVY_cash_flow.csv', 'AVY_income_statement.csv']\n",
      "Saved: AVY_master.csv\n",
      "Processing ticker: NKE\n",
      "Files: ['NKE_cash_flow.csv', 'NKE_income_statement.csv', 'NKE_balance_sheet.csv']\n",
      "Saved: NKE_master.csv\n",
      "Processing ticker: EXPE\n",
      "Files: ['EXPE_balance_sheet.csv', 'EXPE_cash_flow.csv', 'EXPE_income_statement.csv']\n",
      "Saved: EXPE_master.csv\n",
      "Processing ticker: CPB\n",
      "Files: ['CPB_cash_flow.csv', 'CPB_balance_sheet.csv', 'CPB_income_statement.csv']\n",
      "Saved: CPB_master.csv\n",
      "Processing ticker: XEL\n",
      "Files: ['XEL_income_statement.csv', 'XEL_balance_sheet.csv', 'XEL_cash_flow.csv']\n",
      "Saved: XEL_master.csv\n",
      "Processing ticker: FITB\n",
      "Files: ['FITB_balance_sheet.csv', 'FITB_income_statement.csv', 'FITB_cash_flow.csv']\n",
      "Saved: FITB_master.csv\n",
      "Processing ticker: REGN\n",
      "Files: ['REGN_cash_flow.csv', 'REGN_balance_sheet.csv', 'REGN_income_statement.csv']\n",
      "Saved: REGN_master.csv\n",
      "Processing ticker: ZTS\n",
      "Files: ['ZTS_balance_sheet.csv', 'ZTS_income_statement.csv', 'ZTS_cash_flow.csv']\n",
      "Saved: ZTS_master.csv\n",
      "Processing ticker: WMB\n",
      "Files: ['WMB_income_statement.csv', 'WMB_cash_flow.csv', 'WMB_balance_sheet.csv']\n",
      "Saved: WMB_master.csv\n",
      "Processing ticker: EVRG\n",
      "Files: ['EVRG_cash_flow.csv', 'EVRG_income_statement.csv', 'EVRG_balance_sheet.csv']\n",
      "Saved: EVRG_master.csv\n",
      "Processing ticker: ETN\n",
      "Files: ['ETN_balance_sheet.csv', 'ETN_income_statement.csv', 'ETN_cash_flow.csv']\n",
      "Saved: ETN_master.csv\n",
      "Processing ticker: WBA\n",
      "Files: ['WBA_income_statement.csv', 'WBA_balance_sheet.csv', 'WBA_cash_flow.csv']\n",
      "Saved: WBA_master.csv\n",
      "Processing ticker: FRT\n",
      "Files: ['FRT_income_statement.csv', 'FRT_balance_sheet.csv', 'FRT_cash_flow.csv']\n",
      "Saved: FRT_master.csv\n",
      "Processing ticker: FDX\n",
      "Files: ['FDX_income_statement.csv', 'FDX_balance_sheet.csv', 'FDX_cash_flow.csv']\n",
      "Saved: FDX_master.csv\n",
      "Processing ticker: COST\n",
      "Files: ['COST_income_statement.csv', 'COST_balance_sheet.csv', 'COST_cash_flow.csv']\n",
      "Saved: COST_master.csv\n",
      "Processing ticker: STT\n",
      "Files: ['STT_balance_sheet.csv', 'STT_cash_flow.csv', 'STT_income_statement.csv']\n",
      "Saved: STT_master.csv\n",
      "Processing ticker: INTC\n",
      "Files: ['INTC_cash_flow.csv', 'INTC_balance_sheet.csv', 'INTC_income_statement.csv']\n",
      "Saved: INTC_master.csv\n",
      "Processing ticker: BIIB\n",
      "Files: ['BIIB_cash_flow.csv', 'BIIB_balance_sheet.csv', 'BIIB_income_statement.csv']\n",
      "Saved: BIIB_master.csv\n",
      "Processing ticker: FICO\n",
      "Files: ['FICO_cash_flow.csv', 'FICO_income_statement.csv', 'FICO_balance_sheet.csv']\n",
      "Saved: FICO_master.csv\n",
      "Processing ticker: WFC\n",
      "Files: ['WFC_cash_flow.csv', 'WFC_balance_sheet.csv', 'WFC_income_statement.csv']\n",
      "Saved: WFC_master.csv\n",
      "Processing ticker: EQR\n",
      "Files: ['EQR_balance_sheet.csv', 'EQR_income_statement.csv', 'EQR_cash_flow.csv']\n",
      "Saved: EQR_master.csv\n",
      "Processing ticker: MCD\n",
      "Files: ['MCD_income_statement.csv', 'MCD_cash_flow.csv', 'MCD_balance_sheet.csv']\n",
      "Saved: MCD_master.csv\n",
      "Processing ticker: HPQ\n",
      "Files: ['HPQ_income_statement.csv', 'HPQ_cash_flow.csv', 'HPQ_balance_sheet.csv']\n",
      "Saved: HPQ_master.csv\n",
      "Processing ticker: COF\n",
      "Files: ['COF_balance_sheet.csv', 'COF_cash_flow.csv', 'COF_income_statement.csv']\n",
      "Saved: COF_master.csv\n",
      "Processing ticker: LYV\n",
      "Files: ['LYV_income_statement.csv', 'LYV_balance_sheet.csv', 'LYV_cash_flow.csv']\n",
      "Saved: LYV_master.csv\n",
      "Processing ticker: BEN\n",
      "Files: ['BEN_cash_flow.csv', 'BEN_income_statement.csv', 'BEN_balance_sheet.csv']\n",
      "Saved: BEN_master.csv\n",
      "Processing ticker: KLAC\n",
      "Files: ['KLAC_income_statement.csv', 'KLAC_balance_sheet.csv', 'KLAC_cash_flow.csv']\n",
      "Saved: KLAC_master.csv\n",
      "Processing ticker: DE\n",
      "Files: ['DE_cash_flow.csv', 'DE_income_statement.csv', 'DE_balance_sheet.csv']\n",
      "Saved: DE_master.csv\n",
      "Processing ticker: CRWD\n",
      "Files: ['CRWD_balance_sheet.csv', 'CRWD_cash_flow.csv', 'CRWD_income_statement.csv']\n",
      "Saved: CRWD_master.csv\n",
      "Processing ticker: EQIX\n",
      "Files: ['EQIX_balance_sheet.csv', 'EQIX_income_statement.csv', 'EQIX_cash_flow.csv']\n",
      "Saved: EQIX_master.csv\n",
      "Processing ticker: NCLH\n",
      "Files: ['NCLH_cash_flow.csv', 'NCLH_income_statement.csv', 'NCLH_balance_sheet.csv']\n",
      "Saved: NCLH_master.csv\n",
      "Processing ticker: CF\n",
      "Files: ['CF_balance_sheet.csv', 'CF_income_statement.csv', 'CF_cash_flow.csv']\n",
      "Saved: CF_master.csv\n",
      "Processing ticker: AMZN\n",
      "Files: ['AMZN_cash_flow.csv', 'AMZN_balance_sheet.csv', 'AMZN_income_statement.csv']\n",
      "Saved: AMZN_master.csv\n",
      "Processing ticker: PLTR\n",
      "Files: ['PLTR_balance_sheet.csv', 'PLTR_cash_flow.csv', 'PLTR_income_statement.csv']\n",
      "Saved: PLTR_master.csv\n",
      "Processing ticker: ATO\n",
      "Files: ['ATO_balance_sheet.csv', 'ATO_income_statement.csv', 'ATO_cash_flow.csv']\n",
      "Saved: ATO_master.csv\n",
      "Processing ticker: SOLV\n",
      "Files: ['SOLV_balance_sheet.csv', 'SOLV_income_statement.csv', 'SOLV_cash_flow.csv']\n",
      "Saved: SOLV_master.csv\n",
      "Processing ticker: WST\n",
      "Files: ['WST_cash_flow.csv', 'WST_income_statement.csv', 'WST_balance_sheet.csv']\n",
      "Saved: WST_master.csv\n",
      "Processing ticker: APA\n",
      "Files: ['APA_balance_sheet.csv', 'APA_income_statement.csv', 'APA_cash_flow.csv']\n",
      "Saved: APA_master.csv\n",
      "Processing ticker: EOG\n",
      "Files: ['EOG_cash_flow.csv', 'EOG_balance_sheet.csv', 'EOG_income_statement.csv']\n",
      "Saved: EOG_master.csv\n",
      "Processing ticker: VRSN\n",
      "Files: ['VRSN_cash_flow.csv', 'VRSN_balance_sheet.csv', 'VRSN_income_statement.csv']\n",
      "Saved: VRSN_master.csv\n",
      "Processing ticker: VRTX\n",
      "Files: ['VRTX_balance_sheet.csv', 'VRTX_cash_flow.csv', 'VRTX_income_statement.csv']\n",
      "Saved: VRTX_master.csv\n",
      "Processing ticker: PEG\n",
      "Files: ['PEG_income_statement.csv', 'PEG_cash_flow.csv', 'PEG_balance_sheet.csv']\n",
      "Saved: PEG_master.csv\n",
      "Processing ticker: LDOS\n",
      "Files: ['LDOS_balance_sheet.csv', 'LDOS_income_statement.csv', 'LDOS_cash_flow.csv']\n",
      "Saved: LDOS_master.csv\n",
      "Processing ticker: SMCI\n",
      "Files: ['SMCI_cash_flow.csv', 'SMCI_income_statement.csv', 'SMCI_balance_sheet.csv']\n",
      "Saved: SMCI_master.csv\n",
      "Processing ticker: KMI\n",
      "Files: ['KMI_balance_sheet.csv', 'KMI_cash_flow.csv', 'KMI_income_statement.csv']\n",
      "Saved: KMI_master.csv\n",
      "Processing ticker: EG\n",
      "Files: ['EG_income_statement.csv', 'EG_balance_sheet.csv', 'EG_cash_flow.csv']\n",
      "Saved: EG_master.csv\n",
      "Processing ticker: MSFT\n",
      "Files: ['MSFT_cash_flow.csv', 'MSFT_income_statement.csv', 'MSFT_balance_sheet.csv']\n",
      "Saved: MSFT_master.csv\n",
      "Processing ticker: ORCL\n",
      "Files: ['ORCL_balance_sheet.csv', 'ORCL_income_statement.csv', 'ORCL_cash_flow.csv']\n",
      "Saved: ORCL_master.csv\n",
      "Processing ticker: RCL\n",
      "Files: ['RCL_cash_flow.csv', 'RCL_balance_sheet.csv', 'RCL_income_statement.csv']\n",
      "Saved: RCL_master.csv\n",
      "Processing ticker: ODFL\n",
      "Files: ['ODFL_cash_flow.csv', 'ODFL_balance_sheet.csv', 'ODFL_income_statement.csv']\n",
      "Saved: ODFL_master.csv\n",
      "Processing ticker: UNP\n",
      "Files: ['UNP_balance_sheet.csv', 'UNP_cash_flow.csv', 'UNP_income_statement.csv']\n",
      "Saved: UNP_master.csv\n",
      "Processing ticker: NSC\n",
      "Files: ['NSC_income_statement.csv', 'NSC_balance_sheet.csv', 'NSC_cash_flow.csv']\n",
      "Saved: NSC_master.csv\n",
      "Processing ticker: CHTR\n",
      "Files: ['CHTR_income_statement.csv', 'CHTR_cash_flow.csv', 'CHTR_balance_sheet.csv']\n",
      "Saved: CHTR_master.csv\n",
      "Processing ticker: HAS\n",
      "Files: ['HAS_cash_flow.csv', 'HAS_income_statement.csv', 'HAS_balance_sheet.csv']\n",
      "Saved: HAS_master.csv\n",
      "Processing ticker: WYNN\n",
      "Files: ['WYNN_cash_flow.csv', 'WYNN_income_statement.csv', 'WYNN_balance_sheet.csv']\n",
      "Saved: WYNN_master.csv\n",
      "Processing ticker: CTRA\n",
      "Files: ['CTRA_income_statement.csv', 'CTRA_balance_sheet.csv', 'CTRA_cash_flow.csv']\n",
      "Saved: CTRA_master.csv\n",
      "Processing ticker: ROP\n",
      "Files: ['ROP_cash_flow.csv', 'ROP_income_statement.csv', 'ROP_balance_sheet.csv']\n",
      "Saved: ROP_master.csv\n",
      "Processing ticker: A\n",
      "Files: ['A_cash_flow.csv', 'A_income_statement.csv', 'A_balance_sheet.csv']\n",
      "Saved: A_master.csv\n",
      "Processing ticker: VST\n",
      "Files: ['VST_income_statement.csv', 'VST_cash_flow.csv', 'VST_balance_sheet.csv']\n",
      "Saved: VST_master.csv\n",
      "Processing ticker: EPAM\n",
      "Files: ['EPAM_income_statement.csv', 'EPAM_cash_flow.csv', 'EPAM_balance_sheet.csv']\n",
      "Saved: EPAM_master.csv\n",
      "Processing ticker: MRNA\n",
      "Files: ['MRNA_income_statement.csv', 'MRNA_balance_sheet.csv', 'MRNA_cash_flow.csv']\n",
      "Saved: MRNA_master.csv\n",
      "Processing ticker: MAA\n",
      "Files: ['MAA_balance_sheet.csv', 'MAA_income_statement.csv', 'MAA_cash_flow.csv']\n",
      "Saved: MAA_master.csv\n",
      "Processing ticker: IPG\n",
      "Files: ['IPG_cash_flow.csv', 'IPG_balance_sheet.csv', 'IPG_income_statement.csv']\n",
      "Saved: IPG_master.csv\n",
      "Processing ticker: OKE\n",
      "Files: ['OKE_income_statement.csv', 'OKE_cash_flow.csv', 'OKE_balance_sheet.csv']\n",
      "Saved: OKE_master.csv\n",
      "Processing ticker: AIZ\n",
      "Files: ['AIZ_cash_flow.csv', 'AIZ_balance_sheet.csv', 'AIZ_income_statement.csv']\n",
      "Saved: AIZ_master.csv\n",
      "Processing ticker: BLDR\n",
      "Files: ['BLDR_income_statement.csv', 'BLDR_balance_sheet.csv', 'BLDR_cash_flow.csv']\n",
      "Saved: BLDR_master.csv\n",
      "Processing ticker: SCHW\n",
      "Files: ['SCHW_income_statement.csv', 'SCHW_cash_flow.csv', 'SCHW_balance_sheet.csv']\n",
      "Saved: SCHW_master.csv\n",
      "Processing ticker: TRMB\n",
      "Files: ['TRMB_income_statement.csv', 'TRMB_balance_sheet.csv', 'TRMB_cash_flow.csv']\n",
      "Saved: TRMB_master.csv\n",
      "Processing ticker: CSGP\n",
      "Files: ['CSGP_balance_sheet.csv', 'CSGP_cash_flow.csv', 'CSGP_income_statement.csv']\n",
      "Saved: CSGP_master.csv\n",
      "Processing ticker: BBY\n",
      "Files: ['BBY_income_statement.csv', 'BBY_balance_sheet.csv', 'BBY_cash_flow.csv']\n",
      "Saved: BBY_master.csv\n",
      "Processing ticker: HON\n",
      "Files: ['HON_income_statement.csv', 'HON_cash_flow.csv', 'HON_balance_sheet.csv']\n",
      "Saved: HON_master.csv\n",
      "Processing ticker: WBD\n",
      "Files: ['WBD_income_statement.csv', 'WBD_cash_flow.csv', 'WBD_balance_sheet.csv']\n",
      "Saved: WBD_master.csv\n",
      "Processing ticker: PH\n",
      "Files: ['PH_balance_sheet.csv', 'PH_income_statement.csv', 'PH_cash_flow.csv']\n",
      "Saved: PH_master.csv\n",
      "Processing ticker: GS\n",
      "Files: ['GS_income_statement.csv', 'GS_balance_sheet.csv', 'GS_cash_flow.csv']\n",
      "Saved: GS_master.csv\n",
      "Processing ticker: ISRG\n",
      "Files: ['ISRG_cash_flow.csv', 'ISRG_balance_sheet.csv', 'ISRG_income_statement.csv']\n",
      "Saved: ISRG_master.csv\n",
      "Processing ticker: JBHT\n",
      "Files: ['JBHT_balance_sheet.csv', 'JBHT_cash_flow.csv', 'JBHT_income_statement.csv']\n",
      "Saved: JBHT_master.csv\n",
      "Processing ticker: VICI\n",
      "Files: ['VICI_income_statement.csv', 'VICI_balance_sheet.csv', 'VICI_cash_flow.csv']\n",
      "Saved: VICI_master.csv\n",
      "Processing ticker: MET\n",
      "Files: ['MET_income_statement.csv', 'MET_balance_sheet.csv', 'MET_cash_flow.csv']\n",
      "Saved: MET_master.csv\n",
      "Processing ticker: TPR\n",
      "Files: ['TPR_income_statement.csv', 'TPR_cash_flow.csv', 'TPR_balance_sheet.csv']\n",
      "Saved: TPR_master.csv\n",
      "Processing ticker: DHI\n",
      "Files: ['DHI_cash_flow.csv', 'DHI_balance_sheet.csv', 'DHI_income_statement.csv']\n",
      "Saved: DHI_master.csv\n",
      "Processing ticker: IR\n",
      "Files: ['IR_balance_sheet.csv', 'IR_income_statement.csv', 'IR_cash_flow.csv']\n",
      "Saved: IR_master.csv\n",
      "Processing ticker: APO\n",
      "Files: ['APO_income_statement.csv', 'APO_cash_flow.csv', 'APO_balance_sheet.csv']\n",
      "Saved: APO_master.csv\n",
      "Processing ticker: GEHC\n",
      "Files: ['GEHC_cash_flow.csv', 'GEHC_balance_sheet.csv', 'GEHC_income_statement.csv']\n",
      "Saved: GEHC_master.csv\n",
      "Processing ticker: PGR\n",
      "Files: ['PGR_cash_flow.csv', 'PGR_income_statement.csv', 'PGR_balance_sheet.csv']\n",
      "Saved: PGR_master.csv\n",
      "Processing ticker: DTE\n",
      "Files: ['DTE_income_statement.csv', 'DTE_cash_flow.csv', 'DTE_balance_sheet.csv']\n",
      "Saved: DTE_master.csv\n",
      "Processing ticker: BRO\n",
      "Files: ['BRO_income_statement.csv', 'BRO_cash_flow.csv', 'BRO_balance_sheet.csv']\n",
      "Saved: BRO_master.csv\n",
      "Processing ticker: LII\n",
      "Files: ['LII_cash_flow.csv', 'LII_balance_sheet.csv', 'LII_income_statement.csv']\n",
      "Saved: LII_master.csv\n",
      "Processing ticker: CMCSA\n",
      "Files: ['CMCSA_balance_sheet.csv', 'CMCSA_cash_flow.csv', 'CMCSA_income_statement.csv']\n",
      "Saved: CMCSA_master.csv\n",
      "Processing ticker: SWK\n",
      "Files: ['SWK_balance_sheet.csv', 'SWK_income_statement.csv', 'SWK_cash_flow.csv']\n",
      "Saved: SWK_master.csv\n",
      "Processing ticker: MRK\n",
      "Files: ['MRK_income_statement.csv', 'MRK_balance_sheet.csv', 'MRK_cash_flow.csv']\n",
      "Saved: MRK_master.csv\n",
      "Processing ticker: MLM\n",
      "Files: ['MLM_income_statement.csv', 'MLM_cash_flow.csv', 'MLM_balance_sheet.csv']\n",
      "Saved: MLM_master.csv\n",
      "Processing ticker: FDS\n",
      "Files: ['FDS_cash_flow.csv', 'FDS_income_statement.csv', 'FDS_balance_sheet.csv']\n",
      "Saved: FDS_master.csv\n",
      "Processing ticker: UBER\n",
      "Files: ['UBER_balance_sheet.csv', 'UBER_income_statement.csv', 'UBER_cash_flow.csv']\n",
      "Saved: UBER_master.csv\n",
      "Processing ticker: PPL\n",
      "Files: ['PPL_income_statement.csv', 'PPL_cash_flow.csv', 'PPL_balance_sheet.csv']\n",
      "Saved: PPL_master.csv\n",
      "Processing ticker: GNRC\n",
      "Files: ['GNRC_income_statement.csv', 'GNRC_balance_sheet.csv', 'GNRC_cash_flow.csv']\n",
      "Saved: GNRC_master.csv\n",
      "Processing ticker: PAYC\n",
      "Files: ['PAYC_income_statement.csv', 'PAYC_cash_flow.csv', 'PAYC_balance_sheet.csv']\n",
      "Saved: PAYC_master.csv\n",
      "Processing ticker: MAR\n",
      "Files: ['MAR_cash_flow.csv', 'MAR_income_statement.csv', 'MAR_balance_sheet.csv']\n",
      "Saved: MAR_master.csv\n",
      "Processing ticker: T\n",
      "Files: ['T_cash_flow.csv', 'T_income_statement.csv', 'T_balance_sheet.csv']\n",
      "Saved: T_master.csv\n",
      "Processing ticker: AFL\n",
      "Files: ['AFL_income_statement.csv', 'AFL_balance_sheet.csv', 'AFL_cash_flow.csv']\n",
      "Saved: AFL_master.csv\n",
      "Processing ticker: ABNB\n",
      "Files: ['ABNB_income_statement.csv', 'ABNB_cash_flow.csv', 'ABNB_balance_sheet.csv']\n",
      "Saved: ABNB_master.csv\n",
      "Processing ticker: ANSS\n",
      "Files: ['ANSS_income_statement.csv', 'ANSS_cash_flow.csv', 'ANSS_balance_sheet.csv']\n",
      "Saved: ANSS_master.csv\n",
      "Processing ticker: CBRE\n",
      "Files: ['CBRE_cash_flow.csv', 'CBRE_balance_sheet.csv', 'CBRE_income_statement.csv']\n",
      "Saved: CBRE_master.csv\n",
      "Processing ticker: UHS\n",
      "Files: ['UHS_cash_flow.csv', 'UHS_balance_sheet.csv', 'UHS_income_statement.csv']\n",
      "Saved: UHS_master.csv\n",
      "Processing ticker: CE\n",
      "Files: ['CE_cash_flow.csv', 'CE_balance_sheet.csv', 'CE_income_statement.csv']\n",
      "Saved: CE_master.csv\n",
      "Processing ticker: WMT\n",
      "Files: ['WMT_balance_sheet.csv', 'WMT_cash_flow.csv', 'WMT_income_statement.csv']\n",
      "Saved: WMT_master.csv\n",
      "Processing ticker: HIG\n",
      "Files: ['HIG_balance_sheet.csv', 'HIG_income_statement.csv', 'HIG_cash_flow.csv']\n",
      "Saved: HIG_master.csv\n",
      "Processing ticker: NTRS\n",
      "Files: ['NTRS_income_statement.csv', 'NTRS_cash_flow.csv', 'NTRS_balance_sheet.csv']\n",
      "Saved: NTRS_master.csv\n",
      "Processing ticker: LKQ\n",
      "Files: ['LKQ_income_statement.csv', 'LKQ_balance_sheet.csv', 'LKQ_cash_flow.csv']\n",
      "Saved: LKQ_master.csv\n",
      "Processing ticker: NWS\n",
      "Files: ['NWS_balance_sheet.csv', 'NWS_income_statement.csv', 'NWS_cash_flow.csv']\n",
      "Saved: NWS_master.csv\n",
      "Processing ticker: BA\n",
      "Files: ['BA_income_statement.csv', 'BA_cash_flow.csv', 'BA_balance_sheet.csv']\n",
      "Saved: BA_master.csv\n",
      "Processing ticker: AES\n",
      "Files: ['AES_cash_flow.csv', 'AES_balance_sheet.csv', 'AES_income_statement.csv']\n",
      "Saved: AES_master.csv\n",
      "Processing ticker: TMO\n",
      "Files: ['TMO_balance_sheet.csv', 'TMO_cash_flow.csv', 'TMO_income_statement.csv']\n",
      "Saved: TMO_master.csv\n",
      "Processing ticker: PARA\n",
      "Files: ['PARA_income_statement.csv', 'PARA_cash_flow.csv', 'PARA_balance_sheet.csv']\n",
      "Saved: PARA_master.csv\n",
      "Processing ticker: BDX\n",
      "Files: ['BDX_cash_flow.csv', 'BDX_income_statement.csv', 'BDX_balance_sheet.csv']\n",
      "Saved: BDX_master.csv\n",
      "Processing ticker: ES\n",
      "Files: ['ES_cash_flow.csv', 'ES_income_statement.csv', 'ES_balance_sheet.csv']\n",
      "Saved: ES_master.csv\n",
      "Processing ticker: LEN\n",
      "Files: ['LEN_income_statement.csv', 'LEN_balance_sheet.csv', 'LEN_cash_flow.csv']\n",
      "Saved: LEN_master.csv\n",
      "Processing ticker: DUK\n",
      "Files: ['DUK_cash_flow.csv', 'DUK_income_statement.csv', 'DUK_balance_sheet.csv']\n",
      "Saved: DUK_master.csv\n",
      "Processing ticker: VTR\n",
      "Files: ['VTR_income_statement.csv', 'VTR_balance_sheet.csv', 'VTR_cash_flow.csv']\n",
      "Saved: VTR_master.csv\n",
      "Processing ticker: SHW\n",
      "Files: ['SHW_balance_sheet.csv', 'SHW_cash_flow.csv', 'SHW_income_statement.csv']\n",
      "Saved: SHW_master.csv\n",
      "Processing ticker: ROST\n",
      "Files: ['ROST_income_statement.csv', 'ROST_balance_sheet.csv', 'ROST_cash_flow.csv']\n",
      "Saved: ROST_master.csv\n",
      "Processing ticker: AJG\n",
      "Files: ['AJG_income_statement.csv', 'AJG_balance_sheet.csv', 'AJG_cash_flow.csv']\n",
      "Saved: AJG_master.csv\n",
      "Processing ticker: SW\n",
      "Files: ['SW_balance_sheet.csv', 'SW_cash_flow.csv', 'SW_income_statement.csv']\n",
      "Saved: SW_master.csv\n",
      "Processing ticker: CFG\n",
      "Files: ['CFG_income_statement.csv', 'CFG_cash_flow.csv', 'CFG_balance_sheet.csv']\n",
      "Saved: CFG_master.csv\n",
      "Processing ticker: MSCI\n",
      "Files: ['MSCI_income_statement.csv', 'MSCI_balance_sheet.csv', 'MSCI_cash_flow.csv']\n",
      "Saved: MSCI_master.csv\n",
      "Processing ticker: WY\n",
      "Files: ['WY_balance_sheet.csv', 'WY_income_statement.csv', 'WY_cash_flow.csv']\n",
      "Saved: WY_master.csv\n",
      "Processing ticker: MS\n",
      "Files: ['MS_cash_flow.csv', 'MS_income_statement.csv', 'MS_balance_sheet.csv']\n",
      "Saved: MS_master.csv\n",
      "Processing ticker: ALB\n",
      "Files: ['ALB_balance_sheet.csv', 'ALB_cash_flow.csv', 'ALB_income_statement.csv']\n",
      "Saved: ALB_master.csv\n",
      "Processing ticker: WRB\n",
      "Files: ['WRB_cash_flow.csv', 'WRB_income_statement.csv', 'WRB_balance_sheet.csv']\n",
      "Saved: WRB_master.csv\n",
      "Processing ticker: SPG\n",
      "Files: ['SPG_cash_flow.csv', 'SPG_income_statement.csv', 'SPG_balance_sheet.csv']\n",
      "Saved: SPG_master.csv\n",
      "Processing ticker: APD\n",
      "Files: ['APD_balance_sheet.csv', 'APD_cash_flow.csv', 'APD_income_statement.csv']\n",
      "Saved: APD_master.csv\n",
      "Processing ticker: GM\n",
      "Files: ['GM_balance_sheet.csv', 'GM_income_statement.csv', 'GM_cash_flow.csv']\n",
      "Saved: GM_master.csv\n",
      "Processing ticker: AMP\n",
      "Files: ['AMP_balance_sheet.csv', 'AMP_cash_flow.csv', 'AMP_income_statement.csv']\n",
      "Saved: AMP_master.csv\n",
      "Processing ticker: PFE\n",
      "Files: ['PFE_income_statement.csv', 'PFE_balance_sheet.csv', 'PFE_cash_flow.csv']\n",
      "Saved: PFE_master.csv\n",
      "Processing ticker: MCK\n",
      "Files: ['MCK_income_statement.csv', 'MCK_balance_sheet.csv', 'MCK_cash_flow.csv']\n",
      "Saved: MCK_master.csv\n",
      "Processing ticker: EFX\n",
      "Files: ['EFX_income_statement.csv', 'EFX_cash_flow.csv', 'EFX_balance_sheet.csv']\n",
      "Saved: EFX_master.csv\n",
      "Processing ticker: FE\n",
      "Files: ['FE_income_statement.csv', 'FE_balance_sheet.csv', 'FE_cash_flow.csv']\n",
      "Saved: FE_master.csv\n",
      "Processing ticker: AAPL\n",
      "Files: ['AAPL_cash_flow.csv', 'AAPL_income_statement.csv', 'AAPL_balance_sheet.csv']\n",
      "Saved: AAPL_master.csv\n",
      "Processing ticker: BAC\n",
      "Files: ['BAC_cash_flow.csv', 'BAC_balance_sheet.csv', 'BAC_income_statement.csv']\n",
      "Saved: BAC_master.csv\n",
      "Processing ticker: FAST\n",
      "Files: ['FAST_balance_sheet.csv', 'FAST_income_statement.csv', 'FAST_cash_flow.csv']\n",
      "Saved: FAST_master.csv\n",
      "Processing ticker: KR\n",
      "Files: ['KR_income_statement.csv', 'KR_balance_sheet.csv', 'KR_cash_flow.csv']\n",
      "Saved: KR_master.csv\n",
      "Processing ticker: CME\n",
      "Files: ['CME_income_statement.csv', 'CME_balance_sheet.csv', 'CME_cash_flow.csv']\n",
      "Saved: CME_master.csv\n",
      "Processing ticker: AVB\n",
      "Files: ['AVB_balance_sheet.csv', 'AVB_income_statement.csv', 'AVB_cash_flow.csv']\n",
      "Saved: AVB_master.csv\n",
      "Processing ticker: EW\n",
      "Files: ['EW_cash_flow.csv', 'EW_income_statement.csv', 'EW_balance_sheet.csv']\n",
      "Saved: EW_master.csv\n",
      "Processing ticker: NEE\n",
      "Files: ['NEE_income_statement.csv', 'NEE_cash_flow.csv', 'NEE_balance_sheet.csv']\n",
      "Saved: NEE_master.csv\n",
      "Processing ticker: PM\n",
      "Files: ['PM_balance_sheet.csv', 'PM_income_statement.csv', 'PM_cash_flow.csv']\n",
      "Saved: PM_master.csv\n",
      "Processing ticker: ADP\n",
      "Files: ['ADP_cash_flow.csv', 'ADP_income_statement.csv', 'ADP_balance_sheet.csv']\n",
      "Saved: ADP_master.csv\n",
      "Processing ticker: DHR\n",
      "Files: ['DHR_income_statement.csv', 'DHR_balance_sheet.csv', 'DHR_cash_flow.csv']\n",
      "Saved: DHR_master.csv\n",
      "Processing ticker: GIS\n",
      "Files: ['GIS_cash_flow.csv', 'GIS_balance_sheet.csv', 'GIS_income_statement.csv']\n",
      "Saved: GIS_master.csv\n",
      "Processing ticker: SBAC\n",
      "Files: ['SBAC_cash_flow.csv', 'SBAC_balance_sheet.csv', 'SBAC_income_statement.csv']\n",
      "Saved: SBAC_master.csv\n",
      "Processing ticker: ZBH\n",
      "Files: ['ZBH_cash_flow.csv', 'ZBH_balance_sheet.csv', 'ZBH_income_statement.csv']\n",
      "Saved: ZBH_master.csv\n",
      "Processing ticker: PSA\n",
      "Files: ['PSA_income_statement.csv', 'PSA_cash_flow.csv', 'PSA_balance_sheet.csv']\n",
      "Saved: PSA_master.csv\n",
      "Processing ticker: NUE\n",
      "Files: ['NUE_balance_sheet.csv', 'NUE_income_statement.csv', 'NUE_cash_flow.csv']\n",
      "Saved: NUE_master.csv\n",
      "Processing ticker: TSLA\n",
      "Files: ['TSLA_income_statement.csv', 'TSLA_balance_sheet.csv', 'TSLA_cash_flow.csv']\n",
      "Saved: TSLA_master.csv\n",
      "Processing ticker: GEV\n",
      "Files: ['GEV_balance_sheet.csv', 'GEV_income_statement.csv', 'GEV_cash_flow.csv']\n",
      "Saved: GEV_master.csv\n",
      "Processing ticker: V\n",
      "Files: ['V_balance_sheet.csv', 'V_income_statement.csv', 'V_cash_flow.csv']\n",
      "Saved: V_master.csv\n",
      "Processing ticker: CAG\n",
      "Files: ['CAG_balance_sheet.csv', 'CAG_cash_flow.csv', 'CAG_income_statement.csv']\n",
      "Saved: CAG_master.csv\n",
      "Processing ticker: DVA\n",
      "Files: ['DVA_cash_flow.csv', 'DVA_balance_sheet.csv', 'DVA_income_statement.csv']\n",
      "Saved: DVA_master.csv\n",
      "Processing ticker: AMCR\n",
      "Files: ['AMCR_balance_sheet.csv', 'AMCR_cash_flow.csv', 'AMCR_income_statement.csv']\n",
      "Saved: AMCR_master.csv\n",
      "Processing ticker: HD\n",
      "Files: ['HD_income_statement.csv', 'HD_balance_sheet.csv', 'HD_cash_flow.csv']\n",
      "Saved: HD_master.csv\n",
      "Processing ticker: SBUX\n",
      "Files: ['SBUX_income_statement.csv', 'SBUX_cash_flow.csv', 'SBUX_balance_sheet.csv']\n",
      "Saved: SBUX_master.csv\n",
      "Processing ticker: GOOGL\n",
      "Files: ['GOOGL_cash_flow.csv', 'GOOGL_income_statement.csv', 'GOOGL_balance_sheet.csv']\n",
      "Saved: GOOGL_master.csv\n",
      "Processing ticker: L\n",
      "Files: ['L_balance_sheet.csv', 'L_cash_flow.csv', 'L_income_statement.csv']\n",
      "Saved: L_master.csv\n",
      "Processing ticker: VMC\n",
      "Files: ['VMC_cash_flow.csv', 'VMC_income_statement.csv', 'VMC_balance_sheet.csv']\n",
      "Saved: VMC_master.csv\n",
      "Processing ticker: PAYX\n",
      "Files: ['PAYX_income_statement.csv', 'PAYX_cash_flow.csv', 'PAYX_balance_sheet.csv']\n",
      "Saved: PAYX_master.csv\n",
      "Processing ticker: COO\n",
      "Files: ['COO_income_statement.csv', 'COO_balance_sheet.csv', 'COO_cash_flow.csv']\n",
      "Saved: COO_master.csv\n",
      "Processing ticker: AMT\n",
      "Files: ['AMT_cash_flow.csv', 'AMT_balance_sheet.csv', 'AMT_income_statement.csv']\n",
      "Saved: AMT_master.csv\n",
      "Processing ticker: TSN\n",
      "Files: ['TSN_cash_flow.csv', 'TSN_income_statement.csv', 'TSN_balance_sheet.csv']\n",
      "Saved: TSN_master.csv\n",
      "Processing ticker: DAY\n",
      "Files: ['DAY_balance_sheet.csv', 'DAY_cash_flow.csv', 'DAY_income_statement.csv']\n",
      "Saved: DAY_master.csv\n",
      "Processing ticker: ORLY\n",
      "Files: ['ORLY_income_statement.csv', 'ORLY_balance_sheet.csv', 'ORLY_cash_flow.csv']\n",
      "Saved: ORLY_master.csv\n",
      "Processing ticker: STX\n",
      "Files: ['STX_cash_flow.csv', 'STX_income_statement.csv', 'STX_balance_sheet.csv']\n",
      "Saved: STX_master.csv\n",
      "Processing ticker: PNR\n",
      "Files: ['PNR_cash_flow.csv', 'PNR_balance_sheet.csv', 'PNR_income_statement.csv']\n",
      "Saved: PNR_master.csv\n",
      "Processing ticker: KIM\n",
      "Files: ['KIM_cash_flow.csv', 'KIM_balance_sheet.csv', 'KIM_income_statement.csv']\n",
      "Saved: KIM_master.csv\n",
      "Processing ticker: URI\n",
      "Files: ['URI_balance_sheet.csv', 'URI_cash_flow.csv', 'URI_income_statement.csv']\n",
      "Saved: URI_master.csv\n",
      "Processing ticker: CMG\n",
      "Files: ['CMG_cash_flow.csv', 'CMG_income_statement.csv', 'CMG_balance_sheet.csv']\n",
      "Saved: CMG_master.csv\n",
      "Processing ticker: EXPD\n",
      "Files: ['EXPD_balance_sheet.csv', 'EXPD_cash_flow.csv', 'EXPD_income_statement.csv']\n",
      "Saved: EXPD_master.csv\n",
      "Processing ticker: MTB\n",
      "Files: ['MTB_cash_flow.csv', 'MTB_income_statement.csv', 'MTB_balance_sheet.csv']\n",
      "Saved: MTB_master.csv\n",
      "Processing ticker: J\n",
      "Files: ['J_income_statement.csv', 'J_balance_sheet.csv', 'J_cash_flow.csv']\n",
      "Saved: J_master.csv\n",
      "Processing ticker: DOC\n",
      "Files: ['DOC_balance_sheet.csv', 'DOC_cash_flow.csv', 'DOC_income_statement.csv']\n",
      "Saved: DOC_master.csv\n",
      "Processing ticker: LVS\n",
      "Files: ['LVS_cash_flow.csv', 'LVS_balance_sheet.csv', 'LVS_income_statement.csv']\n",
      "Saved: LVS_master.csv\n",
      "Processing ticker: IQV\n",
      "Files: ['IQV_cash_flow.csv', 'IQV_balance_sheet.csv', 'IQV_income_statement.csv']\n",
      "Saved: IQV_master.csv\n",
      "Processing ticker: UPS\n",
      "Files: ['UPS_income_statement.csv', 'UPS_cash_flow.csv', 'UPS_balance_sheet.csv']\n",
      "Saved: UPS_master.csv\n",
      "Processing ticker: AEP\n",
      "Files: ['AEP_cash_flow.csv', 'AEP_income_statement.csv', 'AEP_balance_sheet.csv']\n",
      "Saved: AEP_master.csv\n",
      "Processing ticker: RTX\n",
      "Files: ['RTX_income_statement.csv', 'RTX_cash_flow.csv', 'RTX_balance_sheet.csv']\n",
      "Saved: RTX_master.csv\n",
      "Processing ticker: DECK\n",
      "Files: ['DECK_cash_flow.csv', 'DECK_balance_sheet.csv', 'DECK_income_statement.csv']\n",
      "Saved: DECK_master.csv\n",
      "Processing ticker: WELL\n",
      "Files: ['WELL_balance_sheet.csv', 'WELL_income_statement.csv', 'WELL_cash_flow.csv']\n",
      "Saved: WELL_master.csv\n",
      "Processing ticker: NWSA\n",
      "Files: ['NWSA_balance_sheet.csv', 'NWSA_income_statement.csv', 'NWSA_cash_flow.csv']\n",
      "Saved: NWSA_master.csv\n",
      "Processing ticker: DLTR\n",
      "Files: ['DLTR_balance_sheet.csv', 'DLTR_cash_flow.csv', 'DLTR_income_statement.csv']\n",
      "Saved: DLTR_master.csv\n",
      "Processing ticker: DFS\n",
      "Files: ['DFS_income_statement.csv', 'DFS_balance_sheet.csv', 'DFS_cash_flow.csv']\n",
      "Saved: DFS_master.csv\n",
      "Processing ticker: WAB\n",
      "Files: ['WAB_balance_sheet.csv', 'WAB_income_statement.csv', 'WAB_cash_flow.csv']\n",
      "Saved: WAB_master.csv\n",
      "Processing ticker: META\n",
      "Files: ['META_income_statement.csv', 'META_balance_sheet.csv', 'META_cash_flow.csv']\n",
      "Saved: META_master.csv\n",
      "Processing ticker: DXCM\n",
      "Files: ['DXCM_balance_sheet.csv', 'DXCM_income_statement.csv', 'DXCM_cash_flow.csv']\n",
      "Saved: DXCM_master.csv\n",
      "Processing ticker: HPE\n",
      "Files: ['HPE_income_statement.csv', 'HPE_balance_sheet.csv', 'HPE_cash_flow.csv']\n",
      "Saved: HPE_master.csv\n",
      "Processing ticker: WTW\n",
      "Files: ['WTW_cash_flow.csv', 'WTW_balance_sheet.csv', 'WTW_income_statement.csv']\n",
      "Saved: WTW_master.csv\n",
      "Processing ticker: AMGN\n",
      "Files: ['AMGN_income_statement.csv', 'AMGN_balance_sheet.csv', 'AMGN_cash_flow.csv']\n",
      "Saved: AMGN_master.csv\n",
      "Processing ticker: LIN\n",
      "Files: ['LIN_cash_flow.csv', 'LIN_income_statement.csv', 'LIN_balance_sheet.csv']\n",
      "Saved: LIN_master.csv\n",
      "Processing ticker: DRI\n",
      "Files: ['DRI_balance_sheet.csv', 'DRI_income_statement.csv', 'DRI_cash_flow.csv']\n",
      "Saved: DRI_master.csv\n",
      "Processing ticker: LYB\n",
      "Files: ['LYB_income_statement.csv', 'LYB_cash_flow.csv', 'LYB_balance_sheet.csv']\n",
      "Saved: LYB_master.csv\n",
      "Processing ticker: LW\n",
      "Files: ['LW_cash_flow.csv', 'LW_balance_sheet.csv', 'LW_income_statement.csv']\n",
      "Saved: LW_master.csv\n",
      "Processing ticker: EXC\n",
      "Files: ['EXC_balance_sheet.csv', 'EXC_cash_flow.csv', 'EXC_income_statement.csv']\n",
      "Saved: EXC_master.csv\n",
      "Processing ticker: CRM\n",
      "Files: ['CRM_balance_sheet.csv', 'CRM_income_statement.csv', 'CRM_cash_flow.csv']\n",
      "Saved: CRM_master.csv\n",
      "Processing ticker: CTAS\n",
      "Files: ['CTAS_balance_sheet.csv', 'CTAS_cash_flow.csv', 'CTAS_income_statement.csv']\n",
      "Saved: CTAS_master.csv\n",
      "Processing ticker: CEG\n",
      "Files: ['CEG_cash_flow.csv', 'CEG_income_statement.csv', 'CEG_balance_sheet.csv']\n",
      "Saved: CEG_master.csv\n",
      "Processing ticker: PG\n",
      "Files: ['PG_cash_flow.csv', 'PG_income_statement.csv', 'PG_balance_sheet.csv']\n",
      "Saved: PG_master.csv\n",
      "Processing ticker: MSI\n",
      "Files: ['MSI_income_statement.csv', 'MSI_balance_sheet.csv', 'MSI_cash_flow.csv']\n",
      "Saved: MSI_master.csv\n",
      "Processing ticker: NVDA\n",
      "Files: ['NVDA_balance_sheet.csv', 'NVDA_cash_flow.csv', 'NVDA_income_statement.csv']\n",
      "Saved: NVDA_master.csv\n",
      "Processing ticker: TECH\n",
      "Files: ['TECH_cash_flow.csv', 'TECH_balance_sheet.csv', 'TECH_income_statement.csv']\n",
      "Saved: TECH_master.csv\n",
      "Processing ticker: DPZ\n",
      "Files: ['DPZ_income_statement.csv', 'DPZ_balance_sheet.csv', 'DPZ_cash_flow.csv']\n",
      "Saved: DPZ_master.csv\n",
      "Processing ticker: CB\n",
      "Files: ['CB_cash_flow.csv', 'CB_balance_sheet.csv', 'CB_income_statement.csv']\n",
      "Saved: CB_master.csv\n",
      "Processing ticker: INTU\n",
      "Files: ['INTU_cash_flow.csv', 'INTU_income_statement.csv', 'INTU_balance_sheet.csv']\n",
      "Saved: INTU_master.csv\n",
      "Processing ticker: FOX\n",
      "Files: ['FOX_balance_sheet.csv', 'FOX_income_statement.csv', 'FOX_cash_flow.csv']\n",
      "Saved: FOX_master.csv\n",
      "Processing ticker: ITW\n",
      "Files: ['ITW_balance_sheet.csv', 'ITW_cash_flow.csv', 'ITW_income_statement.csv']\n",
      "Saved: ITW_master.csv\n",
      "Processing ticker: ALL\n",
      "Files: ['ALL_income_statement.csv', 'ALL_cash_flow.csv', 'ALL_balance_sheet.csv']\n",
      "Saved: ALL_master.csv\n",
      "Processing ticker: CPT\n",
      "Files: ['CPT_cash_flow.csv', 'CPT_income_statement.csv', 'CPT_balance_sheet.csv']\n",
      "Saved: CPT_master.csv\n",
      "Processing ticker: FTNT\n",
      "Files: ['FTNT_cash_flow.csv', 'FTNT_income_statement.csv', 'FTNT_balance_sheet.csv']\n",
      "Saved: FTNT_master.csv\n",
      "Processing ticker: O\n",
      "Files: ['O_income_statement.csv', 'O_balance_sheet.csv', 'O_cash_flow.csv']\n",
      "Saved: O_master.csv\n",
      "Processing ticker: EA\n",
      "Files: ['EA_balance_sheet.csv', 'EA_cash_flow.csv', 'EA_income_statement.csv']\n",
      "Saved: EA_master.csv\n",
      "Processing ticker: CSX\n",
      "Files: ['CSX_income_statement.csv', 'CSX_balance_sheet.csv', 'CSX_cash_flow.csv']\n",
      "Saved: CSX_master.csv\n",
      "Processing ticker: ACN\n",
      "Files: ['ACN_balance_sheet.csv', 'ACN_income_statement.csv', 'ACN_cash_flow.csv']\n",
      "Saved: ACN_master.csv\n",
      "Processing ticker: RF\n",
      "Files: ['RF_income_statement.csv', 'RF_balance_sheet.csv', 'RF_cash_flow.csv']\n",
      "Saved: RF_master.csv\n",
      "Processing ticker: AZO\n",
      "Files: ['AZO_balance_sheet.csv', 'AZO_income_statement.csv', 'AZO_cash_flow.csv']\n",
      "Saved: AZO_master.csv\n",
      "Processing ticker: MNST\n",
      "Files: ['MNST_balance_sheet.csv', 'MNST_income_statement.csv', 'MNST_cash_flow.csv']\n",
      "Saved: MNST_master.csv\n",
      "Processing ticker: CLX\n",
      "Files: ['CLX_balance_sheet.csv', 'CLX_income_statement.csv', 'CLX_cash_flow.csv']\n",
      "Saved: CLX_master.csv\n",
      "Processing ticker: INCY\n",
      "Files: ['INCY_balance_sheet.csv', 'INCY_cash_flow.csv', 'INCY_income_statement.csv']\n",
      "Saved: INCY_master.csv\n",
      "Processing ticker: AME\n",
      "Files: ['AME_cash_flow.csv', 'AME_income_statement.csv', 'AME_balance_sheet.csv']\n",
      "Saved: AME_master.csv\n",
      "Processing ticker: ENPH\n",
      "Files: ['ENPH_cash_flow.csv', 'ENPH_income_statement.csv', 'ENPH_balance_sheet.csv']\n",
      "Saved: ENPH_master.csv\n",
      "Processing ticker: KKR\n",
      "Files: ['KKR_cash_flow.csv', 'KKR_balance_sheet.csv', 'KKR_income_statement.csv']\n",
      "Saved: KKR_master.csv\n",
      "Processing ticker: ADI\n",
      "Files: ['ADI_income_statement.csv', 'ADI_cash_flow.csv', 'ADI_balance_sheet.csv']\n",
      "Saved: ADI_master.csv\n",
      "Processing ticker: XYL\n",
      "Files: ['XYL_cash_flow.csv', 'XYL_balance_sheet.csv', 'XYL_income_statement.csv']\n",
      "Saved: XYL_master.csv\n",
      "Processing ticker: RSG\n",
      "Files: ['RSG_cash_flow.csv', 'RSG_balance_sheet.csv', 'RSG_income_statement.csv']\n",
      "Saved: RSG_master.csv\n",
      "Processing ticker: EMN\n",
      "Files: ['EMN_income_statement.csv', 'EMN_cash_flow.csv', 'EMN_balance_sheet.csv']\n",
      "Saved: EMN_master.csv\n",
      "Processing ticker: ARE\n",
      "Files: ['ARE_income_statement.csv', 'ARE_cash_flow.csv', 'ARE_balance_sheet.csv']\n",
      "Saved: ARE_master.csv\n",
      "Processing ticker: PFG\n",
      "Files: ['PFG_cash_flow.csv', 'PFG_balance_sheet.csv', 'PFG_income_statement.csv']\n",
      "Saved: PFG_master.csv\n",
      "Processing ticker: NXPI\n",
      "Files: ['NXPI_income_statement.csv', 'NXPI_cash_flow.csv', 'NXPI_balance_sheet.csv']\n",
      "Saved: NXPI_master.csv\n",
      "Processing ticker: FSLR\n",
      "Files: ['FSLR_balance_sheet.csv', 'FSLR_cash_flow.csv', 'FSLR_income_statement.csv']\n",
      "Saved: FSLR_master.csv\n",
      "Processing ticker: JCI\n",
      "Files: ['JCI_cash_flow.csv', 'JCI_balance_sheet.csv', 'JCI_income_statement.csv']\n",
      "Saved: JCI_master.csv\n",
      "Processing ticker: CL\n",
      "Files: ['CL_income_statement.csv', 'CL_cash_flow.csv', 'CL_balance_sheet.csv']\n",
      "Saved: CL_master.csv\n",
      "Processing ticker: ICE\n",
      "Files: ['ICE_cash_flow.csv', 'ICE_income_statement.csv', 'ICE_balance_sheet.csv']\n",
      "Saved: ICE_master.csv\n",
      "Processing ticker: BKR\n",
      "Files: ['BKR_balance_sheet.csv', 'BKR_cash_flow.csv', 'BKR_income_statement.csv']\n",
      "Saved: BKR_master.csv\n",
      "Processing ticker: F\n",
      "Files: ['F_cash_flow.csv', 'F_balance_sheet.csv', 'F_income_statement.csv']\n",
      "Saved: F_master.csv\n",
      "Processing ticker: BALL\n",
      "Files: ['BALL_income_statement.csv', 'BALL_cash_flow.csv', 'BALL_balance_sheet.csv']\n",
      "Saved: BALL_master.csv\n",
      "Processing ticker: HUBB\n",
      "Files: ['HUBB_income_statement.csv', 'HUBB_cash_flow.csv', 'HUBB_balance_sheet.csv']\n",
      "Saved: HUBB_master.csv\n",
      "Processing ticker: PHM\n",
      "Files: ['PHM_balance_sheet.csv', 'PHM_cash_flow.csv', 'PHM_income_statement.csv']\n",
      "Saved: PHM_master.csv\n",
      "Processing ticker: CVX\n",
      "Files: ['CVX_balance_sheet.csv', 'CVX_cash_flow.csv', 'CVX_income_statement.csv']\n",
      "Saved: CVX_master.csv\n",
      "Processing ticker: GPN\n",
      "Files: ['GPN_income_statement.csv', 'GPN_cash_flow.csv', 'GPN_balance_sheet.csv']\n",
      "Saved: GPN_master.csv\n",
      "Processing ticker: AMAT\n",
      "Files: ['AMAT_income_statement.csv', 'AMAT_cash_flow.csv', 'AMAT_balance_sheet.csv']\n",
      "Saved: AMAT_master.csv\n",
      "Processing ticker: CNP\n",
      "Files: ['CNP_balance_sheet.csv', 'CNP_cash_flow.csv', 'CNP_income_statement.csv']\n",
      "Saved: CNP_master.csv\n",
      "Processing ticker: ON\n",
      "Files: ['ON_balance_sheet.csv', 'ON_cash_flow.csv', 'ON_income_statement.csv']\n",
      "Saved: ON_master.csv\n",
      "Processing ticker: PNC\n",
      "Files: ['PNC_cash_flow.csv', 'PNC_balance_sheet.csv', 'PNC_income_statement.csv']\n",
      "Saved: PNC_master.csv\n",
      "Processing ticker: CPRT\n",
      "Files: ['CPRT_cash_flow.csv', 'CPRT_income_statement.csv', 'CPRT_balance_sheet.csv']\n",
      "Saved: CPRT_master.csv\n",
      "Processing ticker: TPL\n",
      "Files: ['TPL_income_statement.csv', 'TPL_cash_flow.csv', 'TPL_balance_sheet.csv']\n",
      "Saved: TPL_master.csv\n",
      "Processing ticker: TER\n",
      "Files: ['TER_balance_sheet.csv', 'TER_income_statement.csv', 'TER_cash_flow.csv']\n",
      "Saved: TER_master.csv\n",
      "Processing ticker: GRMN\n",
      "Files: ['GRMN_income_statement.csv', 'GRMN_balance_sheet.csv', 'GRMN_cash_flow.csv']\n",
      "Saved: GRMN_master.csv\n",
      "Processing ticker: MA\n",
      "Files: ['MA_cash_flow.csv', 'MA_balance_sheet.csv', 'MA_income_statement.csv']\n",
      "Saved: MA_master.csv\n",
      "Processing ticker: RL\n",
      "Files: ['RL_income_statement.csv', 'RL_cash_flow.csv', 'RL_balance_sheet.csv']\n",
      "Saved: RL_master.csv\n",
      "Processing ticker: CI\n",
      "Files: ['CI_income_statement.csv', 'CI_balance_sheet.csv', 'CI_cash_flow.csv']\n",
      "Saved: CI_master.csv\n",
      "Processing ticker: CINF\n",
      "Files: ['CINF_balance_sheet.csv', 'CINF_cash_flow.csv', 'CINF_income_statement.csv']\n",
      "Saved: CINF_master.csv\n",
      "Processing ticker: BAX\n",
      "Files: ['BAX_balance_sheet.csv', 'BAX_cash_flow.csv', 'BAX_income_statement.csv']\n",
      "Saved: BAX_master.csv\n",
      "Processing ticker: BKNG\n",
      "Files: ['BKNG_cash_flow.csv', 'BKNG_balance_sheet.csv', 'BKNG_income_statement.csv']\n",
      "Saved: BKNG_master.csv\n",
      "Processing ticker: DLR\n",
      "Files: ['DLR_cash_flow.csv', 'DLR_income_statement.csv', 'DLR_balance_sheet.csv']\n",
      "Saved: DLR_master.csv\n",
      "Processing ticker: LHX\n",
      "Files: ['LHX_cash_flow.csv', 'LHX_income_statement.csv', 'LHX_balance_sheet.csv']\n",
      "Saved: LHX_master.csv\n",
      "Processing ticker: IVZ\n",
      "Files: ['IVZ_balance_sheet.csv', 'IVZ_income_statement.csv', 'IVZ_cash_flow.csv']\n",
      "Saved: IVZ_master.csv\n",
      "Processing ticker: HBAN\n",
      "Files: ['HBAN_balance_sheet.csv', 'HBAN_cash_flow.csv', 'HBAN_income_statement.csv']\n",
      "Saved: HBAN_master.csv\n",
      "Processing ticker: TEL\n",
      "Files: ['TEL_balance_sheet.csv', 'TEL_income_statement.csv', 'TEL_cash_flow.csv']\n",
      "Saved: TEL_master.csv\n",
      "Processing ticker: ANET\n",
      "Files: ['ANET_balance_sheet.csv', 'ANET_income_statement.csv', 'ANET_cash_flow.csv']\n",
      "Saved: ANET_master.csv\n",
      "Processing ticker: JBL\n",
      "Files: ['JBL_income_statement.csv', 'JBL_balance_sheet.csv', 'JBL_cash_flow.csv']\n",
      "Saved: JBL_master.csv\n",
      "Processing ticker: MHK\n",
      "Files: ['MHK_balance_sheet.csv', 'MHK_cash_flow.csv', 'MHK_income_statement.csv']\n",
      "Saved: MHK_master.csv\n",
      "Processing ticker: ROL\n",
      "Files: ['ROL_income_statement.csv', 'ROL_cash_flow.csv', 'ROL_balance_sheet.csv']\n",
      "Saved: ROL_master.csv\n",
      "Processing ticker: ED\n",
      "Files: ['ED_balance_sheet.csv', 'ED_cash_flow.csv', 'ED_income_statement.csv']\n",
      "Saved: ED_master.csv\n",
      "Processing ticker: ABT\n",
      "Files: ['ABT_cash_flow.csv', 'ABT_income_statement.csv', 'ABT_balance_sheet.csv']\n",
      "Saved: ABT_master.csv\n",
      "Processing ticker: SPGI\n",
      "Files: ['SPGI_balance_sheet.csv', 'SPGI_income_statement.csv', 'SPGI_cash_flow.csv']\n",
      "Saved: SPGI_master.csv\n",
      "Processing ticker: AON\n",
      "Files: ['AON_income_statement.csv', 'AON_balance_sheet.csv', 'AON_cash_flow.csv']\n",
      "Saved: AON_master.csv\n",
      "Processing ticker: CVS\n",
      "Files: ['CVS_cash_flow.csv', 'CVS_balance_sheet.csv', 'CVS_income_statement.csv']\n",
      "Saved: CVS_master.csv\n",
      "Processing ticker: AEE\n",
      "Files: ['AEE_cash_flow.csv', 'AEE_income_statement.csv', 'AEE_balance_sheet.csv']\n",
      "Saved: AEE_master.csv\n",
      "Processing ticker: MPC\n",
      "Files: ['MPC_balance_sheet.csv', 'MPC_income_statement.csv', 'MPC_cash_flow.csv']\n",
      "Saved: MPC_master.csv\n",
      "Processing ticker: CARR\n",
      "Files: ['CARR_income_statement.csv', 'CARR_cash_flow.csv', 'CARR_balance_sheet.csv']\n",
      "Saved: CARR_master.csv\n",
      "Processing ticker: BWA\n",
      "Files: ['BWA_cash_flow.csv', 'BWA_balance_sheet.csv', 'BWA_income_statement.csv']\n",
      "Saved: BWA_master.csv\n",
      "Processing ticker: BXP\n",
      "Files: ['BXP_income_statement.csv', 'BXP_cash_flow.csv', 'BXP_balance_sheet.csv']\n",
      "Saved: BXP_master.csv\n",
      "Processing ticker: UAL\n",
      "Files: ['UAL_income_statement.csv', 'UAL_cash_flow.csv', 'UAL_balance_sheet.csv']\n",
      "Saved: UAL_master.csv\n",
      "Processing ticker: FOXA\n",
      "Files: ['FOXA_income_statement.csv', 'FOXA_balance_sheet.csv', 'FOXA_cash_flow.csv']\n",
      "Saved: FOXA_master.csv\n",
      "Processing ticker: REG\n",
      "Files: ['REG_income_statement.csv', 'REG_balance_sheet.csv', 'REG_cash_flow.csv']\n",
      "Saved: REG_master.csv\n",
      "Processing ticker: CDW\n",
      "Files: ['CDW_income_statement.csv', 'CDW_cash_flow.csv', 'CDW_balance_sheet.csv']\n",
      "Saved: CDW_master.csv\n",
      "Processing ticker: EIX\n",
      "Files: ['EIX_cash_flow.csv', 'EIX_balance_sheet.csv', 'EIX_income_statement.csv']\n",
      "Saved: EIX_master.csv\n",
      "Processing ticker: LLY\n",
      "Files: ['LLY_income_statement.csv', 'LLY_balance_sheet.csv', 'LLY_cash_flow.csv']\n",
      "Saved: LLY_master.csv\n",
      "Processing ticker: ECL\n",
      "Files: ['ECL_balance_sheet.csv', 'ECL_cash_flow.csv', 'ECL_income_statement.csv']\n",
      "Saved: ECL_master.csv\n",
      "Processing ticker: WM\n",
      "Files: ['WM_cash_flow.csv', 'WM_balance_sheet.csv', 'WM_income_statement.csv']\n",
      "Saved: WM_master.csv\n",
      "Processing ticker: LUV\n",
      "Files: ['LUV_income_statement.csv', 'LUV_cash_flow.csv', 'LUV_balance_sheet.csv']\n",
      "Saved: LUV_master.csv\n",
      "Processing ticker: PODD\n",
      "Files: ['PODD_cash_flow.csv', 'PODD_balance_sheet.csv', 'PODD_income_statement.csv']\n",
      "Saved: PODD_master.csv\n",
      "Processing ticker: NRG\n",
      "Files: ['NRG_cash_flow.csv', 'NRG_income_statement.csv', 'NRG_balance_sheet.csv']\n",
      "Saved: NRG_master.csv\n",
      "Processing ticker: RJF\n",
      "Files: ['RJF_balance_sheet.csv', 'RJF_cash_flow.csv', 'RJF_income_statement.csv']\n",
      "Saved: RJF_master.csv\n",
      "Processing ticker: AIG\n",
      "Files: ['AIG_balance_sheet.csv', 'AIG_income_statement.csv', 'AIG_cash_flow.csv']\n",
      "Saved: AIG_master.csv\n",
      "Processing ticker: WEC\n",
      "Files: ['WEC_income_statement.csv', 'WEC_cash_flow.csv', 'WEC_balance_sheet.csv']\n",
      "Saved: WEC_master.csv\n",
      "Processing ticker: SNA\n",
      "Files: ['SNA_cash_flow.csv', 'SNA_income_statement.csv', 'SNA_balance_sheet.csv']\n",
      "Saved: SNA_master.csv\n",
      "Processing ticker: MCO\n",
      "Files: ['MCO_income_statement.csv', 'MCO_balance_sheet.csv', 'MCO_cash_flow.csv']\n",
      "Saved: MCO_master.csv\n",
      "Processing ticker: GWW\n",
      "Files: ['GWW_income_statement.csv', 'GWW_balance_sheet.csv', 'GWW_cash_flow.csv']\n",
      "Saved: GWW_master.csv\n",
      "Processing ticker: FANG\n",
      "Files: ['FANG_balance_sheet.csv', 'FANG_income_statement.csv', 'FANG_cash_flow.csv']\n",
      "Saved: FANG_master.csv\n",
      "Processing ticker: MO\n",
      "Files: ['MO_cash_flow.csv', 'MO_income_statement.csv', 'MO_balance_sheet.csv']\n",
      "Saved: MO_master.csv\n",
      "Processing ticker: WDC\n",
      "Files: ['WDC_balance_sheet.csv', 'WDC_cash_flow.csv', 'WDC_income_statement.csv']\n",
      "Saved: WDC_master.csv\n",
      "Processing ticker: QCOM\n",
      "Files: ['QCOM_income_statement.csv', 'QCOM_cash_flow.csv', 'QCOM_balance_sheet.csv']\n",
      "Saved: QCOM_master.csv\n",
      "Processing ticker: EL\n",
      "Files: ['EL_income_statement.csv', 'EL_cash_flow.csv', 'EL_balance_sheet.csv']\n",
      "Saved: EL_master.csv\n",
      "Processing ticker: KEYS\n",
      "Files: ['KEYS_balance_sheet.csv', 'KEYS_cash_flow.csv', 'KEYS_income_statement.csv']\n",
      "Saved: KEYS_master.csv\n",
      "Processing ticker: IFF\n",
      "Files: ['IFF_income_statement.csv', 'IFF_cash_flow.csv', 'IFF_balance_sheet.csv']\n",
      "Saved: IFF_master.csv\n",
      "Processing ticker: ETR\n",
      "Files: ['ETR_balance_sheet.csv', 'ETR_income_statement.csv', 'ETR_cash_flow.csv']\n",
      "Saved: ETR_master.csv\n",
      "Processing ticker: TYL\n",
      "Files: ['TYL_balance_sheet.csv', 'TYL_cash_flow.csv', 'TYL_income_statement.csv']\n",
      "Saved: TYL_master.csv\n",
      "Processing ticker: COR\n",
      "Files: ['COR_cash_flow.csv', 'COR_balance_sheet.csv', 'COR_income_statement.csv']\n",
      "Saved: COR_master.csv\n",
      "Processing ticker: CZR\n",
      "Files: ['CZR_balance_sheet.csv', 'CZR_cash_flow.csv', 'CZR_income_statement.csv']\n",
      "Saved: CZR_master.csv\n",
      "Processing ticker: GE\n",
      "Files: ['GE_cash_flow.csv', 'GE_income_statement.csv', 'GE_balance_sheet.csv']\n",
      "Saved: GE_master.csv\n",
      "Processing ticker: LH\n",
      "Files: ['LH_cash_flow.csv', 'LH_balance_sheet.csv', 'LH_income_statement.csv']\n",
      "Saved: LH_master.csv\n",
      "Processing ticker: APTV\n",
      "Files: ['APTV_income_statement.csv', 'APTV_cash_flow.csv', 'APTV_balance_sheet.csv']\n",
      "Saved: APTV_master.csv\n",
      "Processing ticker: PANW\n",
      "Files: ['PANW_income_statement.csv', 'PANW_balance_sheet.csv', 'PANW_cash_flow.csv']\n",
      "Saved: PANW_master.csv\n",
      "Processing ticker: LULU\n",
      "Files: ['LULU_balance_sheet.csv', 'LULU_cash_flow.csv', 'LULU_income_statement.csv']\n",
      "Saved: LULU_master.csv\n",
      "Processing ticker: HRL\n",
      "Files: ['HRL_balance_sheet.csv', 'HRL_cash_flow.csv', 'HRL_income_statement.csv']\n",
      "Saved: HRL_master.csv\n",
      "Processing ticker: COP\n",
      "Files: ['COP_income_statement.csv', 'COP_cash_flow.csv', 'COP_balance_sheet.csv']\n",
      "Saved: COP_master.csv\n",
      "Processing ticker: IP\n",
      "Files: ['IP_balance_sheet.csv', 'IP_cash_flow.csv', 'IP_income_statement.csv']\n",
      "Saved: IP_master.csv\n",
      "Processing ticker: EQT\n",
      "Files: ['EQT_cash_flow.csv', 'EQT_balance_sheet.csv', 'EQT_income_statement.csv']\n",
      "Saved: EQT_master.csv\n",
      "Processing ticker: JKHY\n",
      "Files: ['JKHY_income_statement.csv', 'JKHY_cash_flow.csv', 'JKHY_balance_sheet.csv']\n",
      "Saved: JKHY_master.csv\n",
      "Processing ticker: PRU\n",
      "Files: ['PRU_balance_sheet.csv', 'PRU_income_statement.csv', 'PRU_cash_flow.csv']\n",
      "Saved: PRU_master.csv\n",
      "Processing ticker: MMC\n",
      "Files: ['MMC_cash_flow.csv', 'MMC_balance_sheet.csv', 'MMC_income_statement.csv']\n",
      "Saved: MMC_master.csv\n",
      "Processing ticker: NEM\n",
      "Files: ['NEM_balance_sheet.csv', 'NEM_cash_flow.csv', 'NEM_income_statement.csv']\n",
      "Saved: NEM_master.csv\n",
      "Processing ticker: PPG\n",
      "Files: ['PPG_income_statement.csv', 'PPG_balance_sheet.csv', 'PPG_cash_flow.csv']\n",
      "Saved: PPG_master.csv\n",
      "Processing ticker: BSX\n",
      "Files: ['BSX_income_statement.csv', 'BSX_balance_sheet.csv', 'BSX_cash_flow.csv']\n",
      "Saved: BSX_master.csv\n",
      "Processing ticker: AVGO\n",
      "Files: ['AVGO_cash_flow.csv', 'AVGO_income_statement.csv', 'AVGO_balance_sheet.csv']\n",
      "Saved: AVGO_master.csv\n",
      "Processing ticker: PWR\n",
      "Files: ['PWR_balance_sheet.csv', 'PWR_cash_flow.csv', 'PWR_income_statement.csv']\n",
      "Saved: PWR_master.csv\n",
      "Processing ticker: CMI\n",
      "Files: ['CMI_balance_sheet.csv', 'CMI_cash_flow.csv', 'CMI_income_statement.csv']\n",
      "Saved: CMI_master.csv\n",
      "Processing ticker: SWKS\n",
      "Files: ['SWKS_income_statement.csv', 'SWKS_cash_flow.csv', 'SWKS_balance_sheet.csv']\n",
      "Saved: SWKS_master.csv\n",
      "Processing ticker: TSCO\n",
      "Files: ['TSCO_balance_sheet.csv', 'TSCO_income_statement.csv', 'TSCO_cash_flow.csv']\n",
      "Saved: TSCO_master.csv\n",
      "Processing ticker: CNC\n",
      "Files: ['CNC_income_statement.csv', 'CNC_cash_flow.csv', 'CNC_balance_sheet.csv']\n",
      "Saved: CNC_master.csv\n",
      "Processing ticker: NDSN\n",
      "Files: ['NDSN_cash_flow.csv', 'NDSN_balance_sheet.csv', 'NDSN_income_statement.csv']\n",
      "Saved: NDSN_master.csv\n",
      "Processing ticker: TGT\n",
      "Files: ['TGT_cash_flow.csv', 'TGT_income_statement.csv', 'TGT_balance_sheet.csv']\n",
      "Saved: TGT_master.csv\n",
      "Processing ticker: GILD\n",
      "Files: ['GILD_income_statement.csv', 'GILD_cash_flow.csv', 'GILD_balance_sheet.csv']\n",
      "Saved: GILD_master.csv\n",
      "Processing ticker: UNH\n",
      "Files: ['UNH_cash_flow.csv', 'UNH_balance_sheet.csv', 'UNH_income_statement.csv']\n",
      "Saved: UNH_master.csv\n",
      "Processing ticker: ALGN\n",
      "Files: ['ALGN_income_statement.csv', 'ALGN_cash_flow.csv', 'ALGN_balance_sheet.csv']\n",
      "Saved: ALGN_master.csv\n",
      "Processing ticker: SO\n",
      "Files: ['SO_income_statement.csv', 'SO_balance_sheet.csv', 'SO_cash_flow.csv']\n",
      "Saved: SO_master.csv\n",
      "Processing ticker: LMT\n",
      "Files: ['LMT_balance_sheet.csv', 'LMT_income_statement.csv', 'LMT_cash_flow.csv']\n",
      "Saved: LMT_master.csv\n",
      "Processing ticker: HES\n",
      "Files: ['HES_cash_flow.csv', 'HES_balance_sheet.csv', 'HES_income_statement.csv']\n",
      "Saved: HES_master.csv\n",
      "Processing ticker: HUM\n",
      "Files: ['HUM_income_statement.csv', 'HUM_cash_flow.csv', 'HUM_balance_sheet.csv']\n",
      "Saved: HUM_master.csv\n",
      "Processing ticker: PCG\n",
      "Files: ['PCG_cash_flow.csv', 'PCG_income_statement.csv', 'PCG_balance_sheet.csv']\n",
      "Saved: PCG_master.csv\n",
      "Processing ticker: HCA\n",
      "Files: ['HCA_income_statement.csv', 'HCA_cash_flow.csv', 'HCA_balance_sheet.csv']\n",
      "Saved: HCA_master.csv\n",
      "Processing ticker: ELV\n",
      "Files: ['ELV_cash_flow.csv', 'ELV_income_statement.csv', 'ELV_balance_sheet.csv']\n",
      "Saved: ELV_master.csv\n",
      "Processing ticker: CTVA\n",
      "Files: ['CTVA_income_statement.csv', 'CTVA_balance_sheet.csv', 'CTVA_cash_flow.csv']\n",
      "Saved: CTVA_master.csv\n",
      "Processing ticker: MGM\n",
      "Files: ['MGM_cash_flow.csv', 'MGM_balance_sheet.csv', 'MGM_income_statement.csv']\n",
      "Saved: MGM_master.csv\n",
      "Processing ticker: RVTY\n",
      "Files: ['RVTY_balance_sheet.csv', 'RVTY_cash_flow.csv', 'RVTY_income_statement.csv']\n",
      "Saved: RVTY_master.csv\n",
      "Processing ticker: JNJ\n",
      "Files: ['JNJ_balance_sheet.csv', 'JNJ_cash_flow.csv', 'JNJ_income_statement.csv']\n",
      "Saved: JNJ_master.csv\n",
      "Processing ticker: XOM\n",
      "Files: ['XOM_cash_flow.csv', 'XOM_income_statement.csv', 'XOM_balance_sheet.csv']\n",
      "Saved: XOM_master.csv\n",
      "Processing ticker: HLT\n",
      "Files: ['HLT_cash_flow.csv', 'HLT_balance_sheet.csv', 'HLT_income_statement.csv']\n",
      "Saved: HLT_master.csv\n",
      "Processing ticker: PKG\n",
      "Files: ['PKG_cash_flow.csv', 'PKG_income_statement.csv', 'PKG_balance_sheet.csv']\n",
      "Saved: PKG_master.csv\n",
      "Processing ticker: FTV\n",
      "Files: ['FTV_cash_flow.csv', 'FTV_balance_sheet.csv', 'FTV_income_statement.csv']\n",
      "Saved: FTV_master.csv\n",
      "Processing ticker: IBM\n",
      "Files: ['IBM_income_statement.csv', 'IBM_cash_flow.csv', 'IBM_balance_sheet.csv']\n",
      "Saved: IBM_master.csv\n",
      "Processing ticker: PYPL\n",
      "Files: ['PYPL_income_statement.csv', 'PYPL_balance_sheet.csv', 'PYPL_cash_flow.csv']\n",
      "Saved: PYPL_master.csv\n",
      "Processing ticker: PEP\n",
      "Files: ['PEP_balance_sheet.csv', 'PEP_cash_flow.csv', 'PEP_income_statement.csv']\n",
      "Saved: PEP_master.csv\n",
      "Processing ticker: CSCO\n",
      "Files: ['CSCO_income_statement.csv', 'CSCO_cash_flow.csv', 'CSCO_balance_sheet.csv']\n",
      "Saved: CSCO_master.csv\n",
      "Processing ticker: TDY\n",
      "Files: ['TDY_cash_flow.csv', 'TDY_balance_sheet.csv', 'TDY_income_statement.csv']\n",
      "Saved: TDY_master.csv\n",
      "Processing ticker: OXY\n",
      "Files: ['OXY_balance_sheet.csv', 'OXY_income_statement.csv', 'OXY_cash_flow.csv']\n",
      "Saved: OXY_master.csv\n",
      "Processing ticker: STLD\n",
      "Files: ['STLD_income_statement.csv', 'STLD_balance_sheet.csv', 'STLD_cash_flow.csv']\n",
      "Saved: STLD_master.csv\n",
      "Processing ticker: TTWO\n",
      "Files: ['TTWO_balance_sheet.csv', 'TTWO_income_statement.csv', 'TTWO_cash_flow.csv']\n",
      "Saved: TTWO_master.csv\n",
      "Processing ticker: PTC\n",
      "Files: ['PTC_income_statement.csv', 'PTC_cash_flow.csv', 'PTC_balance_sheet.csv']\n",
      "Saved: PTC_master.csv\n",
      "Processing ticker: VLO\n",
      "Files: ['VLO_income_statement.csv', 'VLO_cash_flow.csv', 'VLO_balance_sheet.csv']\n",
      "Saved: VLO_master.csv\n",
      "Processing ticker: TROW\n",
      "Files: ['TROW_income_statement.csv', 'TROW_balance_sheet.csv', 'TROW_cash_flow.csv']\n",
      "Saved: TROW_master.csv\n",
      "Processing ticker: VRSK\n",
      "Files: ['VRSK_balance_sheet.csv', 'VRSK_income_statement.csv', 'VRSK_cash_flow.csv']\n",
      "Saved: VRSK_master.csv\n",
      "Processing ticker: KO\n",
      "Files: ['KO_cash_flow.csv', 'KO_balance_sheet.csv', 'KO_income_statement.csv']\n",
      "Saved: KO_master.csv\n",
      "Processing ticker: PSX\n",
      "Files: ['PSX_balance_sheet.csv', 'PSX_income_statement.csv', 'PSX_cash_flow.csv']\n",
      "Saved: PSX_master.csv\n",
      "Processing ticker: KVUE\n",
      "Files: ['KVUE_balance_sheet.csv', 'KVUE_income_statement.csv', 'KVUE_cash_flow.csv']\n",
      "Saved: KVUE_master.csv\n",
      "Processing ticker: ADBE\n",
      "Files: ['ADBE_balance_sheet.csv', 'ADBE_cash_flow.csv', 'ADBE_income_statement.csv']\n",
      "Saved: ADBE_master.csv\n",
      "Processing ticker: SNPS\n",
      "Files: ['SNPS_balance_sheet.csv', 'SNPS_cash_flow.csv', 'SNPS_income_statement.csv']\n",
      "Saved: SNPS_master.csv\n",
      "Processing ticker: TXN\n",
      "Files: ['TXN_cash_flow.csv', 'TXN_income_statement.csv', 'TXN_balance_sheet.csv']\n",
      "Saved: TXN_master.csv\n",
      "Processing ticker: GEN\n",
      "Files: ['GEN_balance_sheet.csv', 'GEN_income_statement.csv', 'GEN_cash_flow.csv']\n",
      "Saved: GEN_master.csv\n",
      "Processing ticker: ROK\n",
      "Files: ['ROK_cash_flow.csv', 'ROK_income_statement.csv', 'ROK_balance_sheet.csv']\n",
      "Saved: ROK_master.csv\n",
      "Processing ticker: KMX\n",
      "Files: ['KMX_cash_flow.csv', 'KMX_balance_sheet.csv', 'KMX_income_statement.csv']\n",
      "Saved: KMX_master.csv\n",
      "Processing ticker: DD\n",
      "Files: ['DD_income_statement.csv', 'DD_balance_sheet.csv', 'DD_cash_flow.csv']\n",
      "Saved: DD_master.csv\n",
      "Processing ticker: KHC\n",
      "Files: ['KHC_income_statement.csv', 'KHC_cash_flow.csv', 'KHC_balance_sheet.csv']\n",
      "Saved: KHC_master.csv\n",
      "Processing ticker: TMUS\n",
      "Files: ['TMUS_income_statement.csv', 'TMUS_balance_sheet.csv', 'TMUS_cash_flow.csv']\n",
      "Saved: TMUS_master.csv\n",
      "Processing ticker: EMR\n",
      "Files: ['EMR_cash_flow.csv', 'EMR_balance_sheet.csv', 'EMR_income_statement.csv']\n",
      "Saved: EMR_master.csv\n",
      "Processing ticker: PLD\n",
      "Files: ['PLD_balance_sheet.csv', 'PLD_income_statement.csv', 'PLD_cash_flow.csv']\n",
      "Saved: PLD_master.csv\n",
      "Processing ticker: TDG\n",
      "Files: ['TDG_balance_sheet.csv', 'TDG_income_statement.csv', 'TDG_cash_flow.csv']\n",
      "Saved: TDG_master.csv\n",
      "Processing ticker: NOC\n",
      "Files: ['NOC_balance_sheet.csv', 'NOC_cash_flow.csv', 'NOC_income_statement.csv']\n",
      "Saved: NOC_master.csv\n",
      "Processing ticker: HAL\n",
      "Files: ['HAL_cash_flow.csv', 'HAL_income_statement.csv', 'HAL_balance_sheet.csv']\n",
      "Saved: HAL_master.csv\n",
      "Processing ticker: LRCX\n",
      "Files: ['LRCX_balance_sheet.csv', 'LRCX_cash_flow.csv', 'LRCX_income_statement.csv']\n",
      "Saved: LRCX_master.csv\n",
      "Processing ticker: CCI\n",
      "Files: ['CCI_balance_sheet.csv', 'CCI_cash_flow.csv', 'CCI_income_statement.csv']\n",
      "Saved: CCI_master.csv\n",
      "Processing ticker: AOS\n",
      "Files: ['AOS_cash_flow.csv', 'AOS_balance_sheet.csv', 'AOS_income_statement.csv']\n",
      "Saved: AOS_master.csv\n",
      "Processing ticker: CMS\n",
      "Files: ['CMS_balance_sheet.csv', 'CMS_income_statement.csv', 'CMS_cash_flow.csv']\n",
      "Saved: CMS_master.csv\n",
      "Processing ticker: ADM\n",
      "Files: ['ADM_income_statement.csv', 'ADM_cash_flow.csv', 'ADM_balance_sheet.csv']\n",
      "Saved: ADM_master.csv\n",
      "Processing ticker: MKTX\n",
      "Files: ['MKTX_balance_sheet.csv', 'MKTX_income_statement.csv', 'MKTX_cash_flow.csv']\n",
      "Saved: MKTX_master.csv\n",
      "Processing ticker: D\n",
      "Files: ['D_income_statement.csv', 'D_cash_flow.csv', 'D_balance_sheet.csv']\n",
      "Saved: D_master.csv\n",
      "Processing ticker: LNT\n",
      "Files: ['LNT_balance_sheet.csv', 'LNT_cash_flow.csv', 'LNT_income_statement.csv']\n",
      "Saved: LNT_master.csv\n",
      "Processing ticker: ACGL\n",
      "Files: ['ACGL_cash_flow.csv', 'ACGL_income_statement.csv', 'ACGL_balance_sheet.csv']\n",
      "Saved: ACGL_master.csv\n",
      "Processing ticker: FFIV\n",
      "Files: ['FFIV_balance_sheet.csv', 'FFIV_income_statement.csv', 'FFIV_cash_flow.csv']\n",
      "Saved: FFIV_master.csv\n",
      "Processing ticker: INVH\n",
      "Files: ['INVH_balance_sheet.csv', 'INVH_income_statement.csv', 'INVH_cash_flow.csv']\n",
      "Saved: INVH_master.csv\n",
      "Processing ticker: K\n",
      "Files: ['K_cash_flow.csv', 'K_income_statement.csv', 'K_balance_sheet.csv']\n",
      "Saved: K_master.csv\n",
      "Processing ticker: GLW\n",
      "Files: ['GLW_cash_flow.csv', 'GLW_income_statement.csv', 'GLW_balance_sheet.csv']\n",
      "Saved: GLW_master.csv\n",
      "Processing ticker: CTSH\n",
      "Files: ['CTSH_income_statement.csv', 'CTSH_balance_sheet.csv', 'CTSH_cash_flow.csv']\n",
      "Saved: CTSH_master.csv\n",
      "Processing ticker: TJX\n",
      "Files: ['TJX_balance_sheet.csv', 'TJX_cash_flow.csv', 'TJX_income_statement.csv']\n",
      "Saved: TJX_master.csv\n",
      "Processing ticker: GPC\n",
      "Files: ['GPC_balance_sheet.csv', 'GPC_cash_flow.csv', 'GPC_income_statement.csv']\n",
      "Saved: GPC_master.csv\n",
      "Processing ticker: VLTO\n",
      "Files: ['VLTO_cash_flow.csv', 'VLTO_balance_sheet.csv', 'VLTO_income_statement.csv']\n",
      "Saved: VLTO_master.csv\n",
      "Processing ticker: CHD\n",
      "Files: ['CHD_cash_flow.csv', 'CHD_income_statement.csv', 'CHD_balance_sheet.csv']\n",
      "Saved: CHD_master.csv\n",
      "Processing ticker: ERIE\n",
      "Files: ['ERIE_balance_sheet.csv', 'ERIE_cash_flow.csv', 'ERIE_income_statement.csv']\n",
      "Saved: ERIE_master.csv\n",
      "Processing ticker: AXP\n",
      "Files: ['AXP_income_statement.csv', 'AXP_balance_sheet.csv', 'AXP_cash_flow.csv']\n",
      "Saved: AXP_master.csv\n",
      "Processing ticker: TAP\n",
      "Files: ['TAP_cash_flow.csv', 'TAP_income_statement.csv', 'TAP_balance_sheet.csv']\n",
      "Saved: TAP_master.csv\n",
      "Processing ticker: MTD\n",
      "Files: ['MTD_income_statement.csv', 'MTD_balance_sheet.csv', 'MTD_cash_flow.csv']\n",
      "Saved: MTD_master.csv\n",
      "Processing ticker: CCL\n",
      "Files: ['CCL_balance_sheet.csv', 'CCL_cash_flow.csv', 'CCL_income_statement.csv']\n",
      "Saved: CCL_master.csv\n",
      "Processing ticker: ABBV\n",
      "Files: ['ABBV_income_statement.csv', 'ABBV_balance_sheet.csv', 'ABBV_cash_flow.csv']\n",
      "Saved: ABBV_master.csv\n",
      "Processing ticker: BR\n",
      "Files: ['BR_balance_sheet.csv', 'BR_income_statement.csv', 'BR_cash_flow.csv']\n",
      "Saved: BR_master.csv\n",
      "Processing ticker: MKC\n",
      "Files: ['MKC_cash_flow.csv', 'MKC_income_statement.csv', 'MKC_balance_sheet.csv']\n",
      "Saved: MKC_master.csv\n",
      "Processing ticker: DVN\n",
      "Files: ['DVN_income_statement.csv', 'DVN_cash_flow.csv', 'DVN_balance_sheet.csv']\n",
      "Saved: DVN_master.csv\n",
      "Processing ticker: USB\n",
      "Files: ['USB_balance_sheet.csv', 'USB_income_statement.csv', 'USB_cash_flow.csv']\n",
      "Saved: USB_master.csv\n",
      "Processing ticker: FIS\n",
      "Files: ['FIS_cash_flow.csv', 'FIS_income_statement.csv', 'FIS_balance_sheet.csv']\n",
      "Saved: FIS_master.csv\n",
      "Processing ticker: CHRW\n",
      "Files: ['CHRW_income_statement.csv', 'CHRW_balance_sheet.csv', 'CHRW_cash_flow.csv']\n",
      "Saved: CHRW_master.csv\n",
      "Processing ticker: IT\n",
      "Files: ['IT_balance_sheet.csv', 'IT_cash_flow.csv', 'IT_income_statement.csv']\n",
      "Saved: IT_master.csv\n",
      "Processing ticker: GOOG\n",
      "Files: ['GOOG_income_statement.csv', 'GOOG_balance_sheet.csv', 'GOOG_cash_flow.csv']\n",
      "Saved: GOOG_master.csv\n",
      "Processing ticker: CAT\n",
      "Files: ['CAT_income_statement.csv', 'CAT_cash_flow.csv', 'CAT_balance_sheet.csv']\n",
      "Saved: CAT_master.csv\n",
      "Processing ticker: NOW\n",
      "Files: ['NOW_cash_flow.csv', 'NOW_balance_sheet.csv', 'NOW_income_statement.csv']\n",
      "Saved: NOW_master.csv\n",
      "Processing ticker: DOV\n",
      "Files: ['DOV_cash_flow.csv', 'DOV_balance_sheet.csv', 'DOV_income_statement.csv']\n",
      "Saved: DOV_master.csv\n",
      "Processing ticker: PNW\n",
      "Files: ['PNW_balance_sheet.csv', 'PNW_cash_flow.csv', 'PNW_income_statement.csv']\n",
      "Saved: PNW_master.csv\n",
      "Processing ticker: OTIS\n",
      "Files: ['OTIS_balance_sheet.csv', 'OTIS_cash_flow.csv', 'OTIS_income_statement.csv']\n",
      "Saved: OTIS_master.csv\n",
      "Processing ticker: HII\n",
      "Files: ['HII_cash_flow.csv', 'HII_balance_sheet.csv', 'HII_income_statement.csv']\n",
      "Saved: HII_master.csv\n",
      "Processing ticker: MPWR\n",
      "Files: ['MPWR_balance_sheet.csv', 'MPWR_income_statement.csv', 'MPWR_cash_flow.csv']\n",
      "Saved: MPWR_master.csv\n",
      "Processing ticker: KEY\n",
      "Files: ['KEY_cash_flow.csv', 'KEY_income_statement.csv', 'KEY_balance_sheet.csv']\n",
      "Saved: KEY_master.csv\n",
      "Processing ticker: OMC\n",
      "Files: ['OMC_income_statement.csv', 'OMC_cash_flow.csv', 'OMC_balance_sheet.csv']\n",
      "Saved: OMC_master.csv\n",
      "Processing ticker: TFC\n",
      "Files: ['TFC_balance_sheet.csv', 'TFC_cash_flow.csv', 'TFC_income_statement.csv']\n",
      "Saved: TFC_master.csv\n",
      "Processing ticker: BX\n",
      "Files: ['BX_income_statement.csv', 'BX_cash_flow.csv', 'BX_balance_sheet.csv']\n",
      "Saved: BX_master.csv\n",
      "Processing ticker: TT\n",
      "Files: ['TT_income_statement.csv', 'TT_cash_flow.csv', 'TT_balance_sheet.csv']\n",
      "Saved: TT_master.csv\n",
      "Processing ticker: RMD\n",
      "Files: ['RMD_cash_flow.csv', 'RMD_balance_sheet.csv', 'RMD_income_statement.csv']\n",
      "Saved: RMD_master.csv\n",
      "Processing ticker: NI\n",
      "Files: ['NI_balance_sheet.csv', 'NI_cash_flow.csv', 'NI_income_statement.csv']\n",
      "Saved: NI_master.csv\n",
      "Processing ticker: AKAM\n",
      "Files: ['AKAM_cash_flow.csv', 'AKAM_income_statement.csv', 'AKAM_balance_sheet.csv']\n",
      "Saved: AKAM_master.csv\n",
      "Processing ticker: STE\n",
      "Files: ['STE_balance_sheet.csv', 'STE_income_statement.csv', 'STE_cash_flow.csv']\n",
      "Saved: STE_master.csv\n",
      "Processing ticker: VZ\n",
      "Files: ['VZ_balance_sheet.csv', 'VZ_cash_flow.csv', 'VZ_income_statement.csv']\n",
      "Saved: VZ_master.csv\n",
      "Processing ticker: DOW\n",
      "Files: ['DOW_cash_flow.csv', 'DOW_balance_sheet.csv', 'DOW_income_statement.csv']\n",
      "Saved: DOW_master.csv\n",
      "Processing ticker: MDLZ\n",
      "Files: ['MDLZ_balance_sheet.csv', 'MDLZ_cash_flow.csv', 'MDLZ_income_statement.csv']\n",
      "Saved: MDLZ_master.csv\n",
      "Processing ticker: CPAY\n",
      "Files: ['CPAY_balance_sheet.csv', 'CPAY_cash_flow.csv', 'CPAY_income_statement.csv']\n",
      "Saved: CPAY_master.csv\n",
      "Processing ticker: MCHP\n",
      "Files: ['MCHP_balance_sheet.csv', 'MCHP_income_statement.csv', 'MCHP_cash_flow.csv']\n",
      "Saved: MCHP_master.csv\n",
      "Processing ticker: MOS\n",
      "Files: ['MOS_income_statement.csv', 'MOS_cash_flow.csv', 'MOS_balance_sheet.csv']\n",
      "Saved: MOS_master.csv\n",
      "Processing ticker: GDDY\n",
      "Files: ['GDDY_income_statement.csv', 'GDDY_cash_flow.csv', 'GDDY_balance_sheet.csv']\n",
      "Saved: GDDY_master.csv\n",
      "Processing ticker: WDAY\n",
      "Files: ['WDAY_balance_sheet.csv', 'WDAY_cash_flow.csv', 'WDAY_income_statement.csv']\n",
      "Saved: WDAY_master.csv\n",
      "Processing ticker: FCX\n",
      "Files: ['FCX_cash_flow.csv', 'FCX_balance_sheet.csv', 'FCX_income_statement.csv']\n",
      "Saved: FCX_master.csv\n",
      "Processing ticker: CDNS\n",
      "Files: ['CDNS_income_statement.csv', 'CDNS_cash_flow.csv', 'CDNS_balance_sheet.csv']\n",
      "Saved: CDNS_master.csv\n",
      "Processing ticker: JNPR\n",
      "Files: ['JNPR_cash_flow.csv', 'JNPR_balance_sheet.csv', 'JNPR_income_statement.csv']\n",
      "Saved: JNPR_master.csv\n",
      "Processing ticker: ADSK\n",
      "Files: ['ADSK_cash_flow.csv', 'ADSK_balance_sheet.csv', 'ADSK_income_statement.csv']\n",
      "Saved: ADSK_master.csv\n",
      "Processing ticker: TFX\n",
      "Files: ['TFX_balance_sheet.csv', 'TFX_cash_flow.csv', 'TFX_income_statement.csv']\n",
      "Saved: TFX_master.csv\n",
      "Processing ticker: CAH\n",
      "Files: ['CAH_balance_sheet.csv', 'CAH_income_statement.csv', 'CAH_cash_flow.csv']\n",
      "Saved: CAH_master.csv\n",
      "Processing ticker: DAL\n",
      "Files: ['DAL_balance_sheet.csv', 'DAL_income_statement.csv', 'DAL_cash_flow.csv']\n",
      "Saved: DAL_master.csv\n",
      "Processing ticker: MDT\n",
      "Files: ['MDT_income_statement.csv', 'MDT_cash_flow.csv', 'MDT_balance_sheet.csv']\n",
      "Saved: MDT_master.csv\n",
      "Processing ticker: DG\n",
      "Files: ['DG_income_statement.csv', 'DG_balance_sheet.csv', 'DG_cash_flow.csv']\n",
      "Saved: DG_master.csv\n",
      "Processing ticker: HOLX\n",
      "Files: ['HOLX_balance_sheet.csv', 'HOLX_income_statement.csv', 'HOLX_cash_flow.csv']\n",
      "Saved: HOLX_master.csv\n",
      "Processing ticker: STZ\n",
      "Files: ['STZ_balance_sheet.csv', 'STZ_income_statement.csv', 'STZ_cash_flow.csv']\n",
      "Saved: STZ_master.csv\n",
      "Processing ticker: SYY\n",
      "Files: ['SYY_cash_flow.csv', 'SYY_balance_sheet.csv', 'SYY_income_statement.csv']\n",
      "Saved: SYY_master.csv\n",
      "Processing ticker: EXR\n",
      "Files: ['EXR_balance_sheet.csv', 'EXR_cash_flow.csv', 'EXR_income_statement.csv']\n",
      "Saved: EXR_master.csv\n",
      "Processing ticker: IEX\n",
      "Files: ['IEX_cash_flow.csv', 'IEX_income_statement.csv', 'IEX_balance_sheet.csv']\n",
      "Saved: IEX_master.csv\n",
      "Processing ticker: HSIC\n",
      "Files: ['HSIC_income_statement.csv', 'HSIC_cash_flow.csv', 'HSIC_balance_sheet.csv']\n",
      "Saved: HSIC_master.csv\n",
      "Processing ticker: GD\n",
      "Files: ['GD_cash_flow.csv', 'GD_income_statement.csv', 'GD_balance_sheet.csv']\n",
      "Saved: GD_master.csv\n",
      "Processing ticker: AXON\n",
      "Files: ['AXON_balance_sheet.csv', 'AXON_cash_flow.csv', 'AXON_income_statement.csv']\n",
      "Saved: AXON_master.csv\n",
      "Processing ticker: POOL\n",
      "Files: ['POOL_cash_flow.csv', 'POOL_income_statement.csv', 'POOL_balance_sheet.csv']\n",
      "Saved: POOL_master.csv\n",
      "Processing ticker: C\n",
      "Files: ['C_balance_sheet.csv', 'C_income_statement.csv', 'C_cash_flow.csv']\n",
      "Saved: C_master.csv\n",
      "Processing ticker: MOH\n",
      "Files: ['MOH_income_statement.csv', 'MOH_cash_flow.csv', 'MOH_balance_sheet.csv']\n",
      "Saved: MOH_master.csv\n",
      "Processing ticker: ZBRA\n",
      "Files: ['ZBRA_cash_flow.csv', 'ZBRA_income_statement.csv', 'ZBRA_balance_sheet.csv']\n",
      "Saved: ZBRA_master.csv\n",
      "Processing ticker: IDXX\n",
      "Files: ['IDXX_income_statement.csv', 'IDXX_balance_sheet.csv', 'IDXX_cash_flow.csv']\n",
      "Saved: IDXX_master.csv\n",
      "Processing ticker: JPM\n",
      "Files: ['JPM_balance_sheet.csv', 'JPM_income_statement.csv', 'JPM_cash_flow.csv']\n",
      "Saved: JPM_master.csv\n",
      "Processing ticker: APH\n",
      "Files: ['APH_income_statement.csv', 'APH_cash_flow.csv', 'APH_balance_sheet.csv']\n",
      "Saved: APH_master.csv\n",
      "Processing ticker: UDR\n",
      "Files: ['UDR_cash_flow.csv', 'UDR_income_statement.csv', 'UDR_balance_sheet.csv']\n",
      "Saved: UDR_master.csv\n",
      "Processing ticker: KDP\n",
      "Files: ['KDP_income_statement.csv', 'KDP_cash_flow.csv', 'KDP_balance_sheet.csv']\n",
      "Saved: KDP_master.csv\n",
      "Processing ticker: YUM\n",
      "Files: ['YUM_income_statement.csv', 'YUM_cash_flow.csv', 'YUM_balance_sheet.csv']\n",
      "Saved: YUM_master.csv\n",
      "Processing ticker: HST\n",
      "Files: ['HST_income_statement.csv', 'HST_balance_sheet.csv', 'HST_cash_flow.csv']\n",
      "Saved: HST_master.csv\n",
      "Processing ticker: SYF\n",
      "Files: ['SYF_income_statement.csv', 'SYF_cash_flow.csv', 'SYF_balance_sheet.csv']\n",
      "Saved: SYF_master.csv\n",
      "Processing ticker: SRE\n",
      "Files: ['SRE_cash_flow.csv', 'SRE_income_statement.csv', 'SRE_balance_sheet.csv']\n",
      "Saved: SRE_master.csv\n",
      "Processing ticker: DIS\n",
      "Files: ['DIS_cash_flow.csv', 'DIS_income_statement.csv', 'DIS_balance_sheet.csv']\n",
      "Saved: DIS_master.csv\n",
      "Processing ticker: SJM\n",
      "Files: ['SJM_cash_flow.csv', 'SJM_income_statement.csv', 'SJM_balance_sheet.csv']\n",
      "Saved: SJM_master.csv\n",
      "Processing ticker: LOW\n",
      "Files: ['LOW_cash_flow.csv', 'LOW_income_statement.csv', 'LOW_balance_sheet.csv']\n",
      "Saved: LOW_master.csv\n",
      "Processing ticker: FMC\n",
      "Files: ['FMC_income_statement.csv', 'FMC_cash_flow.csv', 'FMC_balance_sheet.csv']\n",
      "Saved: FMC_master.csv\n",
      "Processing ticker: PCAR\n",
      "Files: ['PCAR_balance_sheet.csv', 'PCAR_cash_flow.csv', 'PCAR_income_statement.csv']\n",
      "Saved: PCAR_master.csv\n",
      "Processing ticker: KMB\n",
      "Files: ['KMB_balance_sheet.csv', 'KMB_cash_flow.csv', 'KMB_income_statement.csv']\n",
      "Saved: KMB_master.csv\n",
      "Processing ticker: BLK\n",
      "Files: ['BLK_income_statement.csv', 'BLK_cash_flow.csv', 'BLK_balance_sheet.csv']\n",
      "Saved: BLK_master.csv\n",
      "Processing ticker: WAT\n",
      "Files: ['WAT_income_statement.csv', 'WAT_cash_flow.csv', 'WAT_balance_sheet.csv']\n",
      "Saved: WAT_master.csv\n",
      "Processing ticker: BG\n",
      "Files: ['BG_balance_sheet.csv', 'BG_income_statement.csv', 'BG_cash_flow.csv']\n",
      "Saved: BG_master.csv\n",
      "Processing ticker: FI\n",
      "Files: ['FI_balance_sheet.csv', 'FI_cash_flow.csv', 'FI_income_statement.csv']\n",
      "Saved: FI_master.csv\n",
      "Processing ticker: MU\n",
      "Files: ['MU_income_statement.csv', 'MU_cash_flow.csv', 'MU_balance_sheet.csv']\n",
      "Saved: MU_master.csv\n",
      "Processing ticker: ULTA\n",
      "Files: ['ULTA_balance_sheet.csv', 'ULTA_cash_flow.csv', 'ULTA_income_statement.csv']\n",
      "Saved: ULTA_master.csv\n",
      "Processing ticker: BMY\n",
      "Files: ['BMY_cash_flow.csv', 'BMY_balance_sheet.csv', 'BMY_income_statement.csv']\n",
      "Saved: BMY_master.csv\n",
      "Processing ticker: NTAP\n",
      "Files: ['NTAP_income_statement.csv', 'NTAP_balance_sheet.csv', 'NTAP_cash_flow.csv']\n",
      "Saved: NTAP_master.csv\n",
      "Processing ticker: CBOE\n",
      "Files: ['CBOE_cash_flow.csv', 'CBOE_income_statement.csv', 'CBOE_balance_sheet.csv']\n",
      "Saved: CBOE_master.csv\n",
      "Processing ticker: TRGP\n",
      "Files: ['TRGP_balance_sheet.csv', 'TRGP_cash_flow.csv', 'TRGP_income_statement.csv']\n",
      "Saved: TRGP_master.csv\n",
      "Processing ticker: VTRS\n",
      "Files: ['VTRS_cash_flow.csv', 'VTRS_income_statement.csv', 'VTRS_balance_sheet.csv']\n",
      "Saved: VTRS_master.csv\n",
      "Processing ticker: TXT\n",
      "Files: ['TXT_balance_sheet.csv', 'TXT_cash_flow.csv', 'TXT_income_statement.csv']\n",
      "Saved: TXT_master.csv\n",
      "Processing ticker: MAS\n",
      "Files: ['MAS_balance_sheet.csv', 'MAS_income_statement.csv', 'MAS_cash_flow.csv']\n",
      "Saved: MAS_master.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Dictionary to group files by ticker\n",
    "ticker_files = defaultdict(list)\n",
    "folder_path = \"./data/financial_statement\"\n",
    "\n",
    "# Get all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Group files by ticker (part before first underscore), exclude master files\n",
    "for file in csv_files:\n",
    "    if '_' in file and not file.endswith('_master.csv'):\n",
    "        ticker = file.split('_')[0]\n",
    "        ticker_files[ticker].append(file)\n",
    "\n",
    "# Process each ticker group\n",
    "for ticker, files in ticker_files.items():\n",
    "    print(f\"Processing ticker: {ticker}\")\n",
    "    print(f\"Files: {files}\")\n",
    "    \n",
    "    # Read and merge all files for this ticker\n",
    "    merged_df = None\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if merged_df is None:\n",
    "            merged_df = df\n",
    "        else:\n",
    "            # Merge on 'frame' column\n",
    "            merged_df = pd.merge(merged_df, df, on='frame', how='outer')\n",
    "    \n",
    "    # Remove metadata columns\n",
    "    metadata_cols = [col for col in merged_df.columns if any(col.startswith(meta) for meta in ['filed', 'company_name', 'end', 'unit', 'form', 'cik'])]\n",
    "    merged_df = merged_df.drop(columns=metadata_cols)\n",
    "    \n",
    "    # Save merged dataframe\n",
    "    output_file = os.path.join(folder_path, f\"{ticker}_master.csv\")\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved: {ticker}_master.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mapping.json (KPIs, MOATs and Risk mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the new values to replace all existing values\n",
    "new_swot_values = [\"Strengths\", \"Weaknesses\", \"Opportunities\", \"Threats\"]\n",
    "new_porter_values = [\n",
    "    \"High Threat of New Entrants\",\n",
    "    \"Low Threat of New Entrants\",\n",
    "    \"High Bargaining Power of Buyers\",\n",
    "    \"Low Bargaining Power of Buyers\",\n",
    "    \"High Bargaining Power of Suppliers\",\n",
    "    \"Low Bargaining Power of Suppliers\",\n",
    "    \"High Threat of Substitute Products or Services\",\n",
    "    \"Low Threat of Substitute Products or Services\",\n",
    "    \"High Intensity of Rivalry\",\n",
    "    \"Low Intensity of Rivalry\"\n",
    "]\n",
    "\n",
    "# Read the JSON file\n",
    "with open('mapping.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Update all SWOT and Porter values\n",
    "for category, details in data.items():\n",
    "\n",
    "    # Here you need to replace the values from 'risks' and 'moats' and 'kpis'\n",
    "    if 'kpis' in details:\n",
    "        for moat in details['kpis']:\n",
    "            mapping = moat.get('mapping', {})\n",
    "            \n",
    "            # Replace SWOT values\n",
    "            if 'swot' in mapping:\n",
    "                mapping['swot'] = new_swot_values\n",
    "            if 'SWOT' in mapping:\n",
    "                mapping['SWOT'] = new_swot_values\n",
    "            \n",
    "            # Replace Porter values\n",
    "            if 'porters' in mapping:\n",
    "                mapping['porters'] = new_porter_values\n",
    "            if 'Porter' in mapping:\n",
    "                mapping['Porter'] = new_porter_values\n",
    "\n",
    "# Overwrite the original file\n",
    "with open('mapping.json', 'w') as file:\n",
    "    json.dump(data, file, indent=2)\n",
    "\n",
    "print(\"JSON file has been updated with new SWOT and Porter values\")\n",
    "\n",
    "# Verify the changes\n",
    "print(\"\\nVerifying changes:\")\n",
    "for category, details in data.items():\n",
    "    if 'risks' in details:\n",
    "        for moat in details['risks']:\n",
    "            mapping = moat.get('mapping', {})\n",
    "            swot = mapping.get('swot') or mapping.get('SWOT')\n",
    "            porter = mapping.get('porters') or mapping.get('Porter')\n",
    "            if swot or porter:\n",
    "                print(f\"Category: {category}\")\n",
    "                print(f\"SWOT: {swot}\")\n",
    "                print(f\"Porter: {porter}\")\n",
    "                print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>section</th>\n",
       "      <th>content</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "      <th>question_number</th>\n",
       "      <th>question_formatted</th>\n",
       "      <th>question_prompt</th>\n",
       "      <th>gemini_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>Item 1. Business</td>\n",
       "      <td>Business 2 Business Overview Accenture is a le...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "      <td>9.0</td>\n",
       "      <td>What is Accenture's approach to intellectual p...</td>\n",
       "      <td>As financial analysts, we are extracting finan...</td>\n",
       "      <td>```json\\n{\\n \"question\": \"What is Accenture's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>Item 1. Business</td>\n",
       "      <td>Business 2 Business Overview Accenture is a le...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Does Accenture disclose any key performance in...</td>\n",
       "      <td>As financial analysts, we are extracting finan...</td>\n",
       "      <td>```json\\n{\\n \"question\": \"Does Accenture discl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>Item 1A. Risk Factors</td>\n",
       "      <td>Risk Factors 18 Risk Factors In addition to th...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>What specific risks does Accenture identify re...</td>\n",
       "      <td>As financial analysts, we are extracting finan...</td>\n",
       "      <td>```json\\n{\\n \"question\": \"What specific risks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>Item 1A. Risk Factors</td>\n",
       "      <td>Risk Factors 18 Risk Factors In addition to th...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "      <td>2.0</td>\n",
       "      <td>What risks does Accenture highlight regarding ...</td>\n",
       "      <td>As financial analysts, we are extracting finan...</td>\n",
       "      <td>```json\\n{\\n \"question\": \"What risks does Acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>Item 1A. Risk Factors</td>\n",
       "      <td>Risk Factors 18 Risk Factors In addition to th...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Does Accenture discuss risks associated with c...</td>\n",
       "      <td>As financial analysts, we are extracting finan...</td>\n",
       "      <td>```json\\n{\\n \"question\": \"Does Accenture discu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>Item 1A. Risk Factors</td>\n",
       "      <td>Risk Factors 18 Risk Factors In addition to th...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "      <td>4.0</td>\n",
       "      <td>What cybersecurity, data privacy, or intellect...</td>\n",
       "      <td>As financial analysts, we are extracting finan...</td>\n",
       "      <td>```json\\n{\\n \"question\": \"What cybersecurity, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>Item 1A. Risk Factors</td>\n",
       "      <td>Risk Factors 18 Risk Factors In addition to th...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "      <td>5.0</td>\n",
       "      <td>What risks does Accenture identify related to ...</td>\n",
       "      <td>As financial analysts, we are extracting finan...</td>\n",
       "      <td>```json\\n{\\n \"question\": \"What risks does Acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>Item 1A. Risk Factors</td>\n",
       "      <td>Risk Factors 18 Risk Factors In addition to th...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "      <td>6.0</td>\n",
       "      <td>What risks does Accenture face from intense co...</td>\n",
       "      <td>As financial analysts, we are extracting finan...</td>\n",
       "      <td>```json\\n{\\n \"question\": \"What risks does Acce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker filing_date                section  \\\n",
       "0    ACN  2024-08-31       Item 1. Business   \n",
       "1    ACN  2024-08-31       Item 1. Business   \n",
       "2    ACN  2024-08-31  Item 1A. Risk Factors   \n",
       "3    ACN  2024-08-31  Item 1A. Risk Factors   \n",
       "4    ACN  2024-08-31  Item 1A. Risk Factors   \n",
       "5    ACN  2024-08-31  Item 1A. Risk Factors   \n",
       "6    ACN  2024-08-31  Item 1A. Risk Factors   \n",
       "7    ACN  2024-08-31  Item 1A. Risk Factors   \n",
       "\n",
       "                                             content   Security  \\\n",
       "0  Business 2 Business Overview Accenture is a le...  Accenture   \n",
       "1  Business 2 Business Overview Accenture is a le...  Accenture   \n",
       "2  Risk Factors 18 Risk Factors In addition to th...  Accenture   \n",
       "3  Risk Factors 18 Risk Factors In addition to th...  Accenture   \n",
       "4  Risk Factors 18 Risk Factors In addition to th...  Accenture   \n",
       "5  Risk Factors 18 Risk Factors In addition to th...  Accenture   \n",
       "6  Risk Factors 18 Risk Factors In addition to th...  Accenture   \n",
       "7  Risk Factors 18 Risk Factors In addition to th...  Accenture   \n",
       "\n",
       "              GICS Sector               GICS Sub-Industry  \\\n",
       "0  Information Technology  IT Consulting & Other Services   \n",
       "1  Information Technology  IT Consulting & Other Services   \n",
       "2  Information Technology  IT Consulting & Other Services   \n",
       "3  Information Technology  IT Consulting & Other Services   \n",
       "4  Information Technology  IT Consulting & Other Services   \n",
       "5  Information Technology  IT Consulting & Other Services   \n",
       "6  Information Technology  IT Consulting & Other Services   \n",
       "7  Information Technology  IT Consulting & Other Services   \n",
       "\n",
       "  Headquarters Location  Date added      CIK  Founded  question_number  \\\n",
       "0       Dublin, Ireland  2011-07-06  1467373     1989              9.0   \n",
       "1       Dublin, Ireland  2011-07-06  1467373     1989             10.0   \n",
       "2       Dublin, Ireland  2011-07-06  1467373     1989              1.0   \n",
       "3       Dublin, Ireland  2011-07-06  1467373     1989              2.0   \n",
       "4       Dublin, Ireland  2011-07-06  1467373     1989              3.0   \n",
       "5       Dublin, Ireland  2011-07-06  1467373     1989              4.0   \n",
       "6       Dublin, Ireland  2011-07-06  1467373     1989              5.0   \n",
       "7       Dublin, Ireland  2011-07-06  1467373     1989              6.0   \n",
       "\n",
       "                                  question_formatted  \\\n",
       "0  What is Accenture's approach to intellectual p...   \n",
       "1  Does Accenture disclose any key performance in...   \n",
       "2  What specific risks does Accenture identify re...   \n",
       "3  What risks does Accenture highlight regarding ...   \n",
       "4  Does Accenture discuss risks associated with c...   \n",
       "5  What cybersecurity, data privacy, or intellect...   \n",
       "6  What risks does Accenture identify related to ...   \n",
       "7  What risks does Accenture face from intense co...   \n",
       "\n",
       "                                     question_prompt  \\\n",
       "0  As financial analysts, we are extracting finan...   \n",
       "1  As financial analysts, we are extracting finan...   \n",
       "2  As financial analysts, we are extracting finan...   \n",
       "3  As financial analysts, we are extracting finan...   \n",
       "4  As financial analysts, we are extracting finan...   \n",
       "5  As financial analysts, we are extracting finan...   \n",
       "6  As financial analysts, we are extracting finan...   \n",
       "7  As financial analysts, we are extracting finan...   \n",
       "\n",
       "                                     gemini_response  \n",
       "0  ```json\\n{\\n \"question\": \"What is Accenture's ...  \n",
       "1  ```json\\n{\\n \"question\": \"Does Accenture discl...  \n",
       "2  ```json\\n{\\n \"question\": \"What specific risks ...  \n",
       "3  ```json\\n{\\n \"question\": \"What risks does Acce...  \n",
       "4  ```json\\n{\\n \"question\": \"Does Accenture discu...  \n",
       "5  ```json\\n{\\n \"question\": \"What cybersecurity, ...  \n",
       "6  ```json\\n{\\n \"question\": \"What risks does Acce...  \n",
       "7  ```json\\n{\\n \"question\": \"What risks does Acce...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "f = pd.read_csv('/Users/maseehfaizan/Desktop/Maseeh/Projects/Hybrid_Pricer/data/ticker_csvs/ACN_df_with_gemini_responses.csv')\n",
    "f.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
