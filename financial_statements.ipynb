{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a5f2e98",
   "metadata": {},
   "source": [
    "# Import the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68964475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d18027",
   "metadata": {},
   "source": [
    "## To start our analysis and to comply with compute restrictions I will first analyse the data for a total of 5 companies out of 500\n",
    "\n",
    "I will first start by studying 5 companies in the same industry so to have a more industry specific insights. Given the companies in that industry I will know the patterns that emerge in that specific industry and from that point on, when I have completed that industry I can generalize it to other companies in the same industry at first and than into other industries\n",
    "\n",
    "### Advantages:\n",
    "1. **Domain-Specific patterns**\n",
    "2. Comparable analysis\n",
    "3. Controlled complexity\n",
    "4. Faster iteration\n",
    "5. Clear baseline\n",
    "\n",
    "### Information Techonology Industry\n",
    "1. **Microsoft** \n",
    "2. **ServiceNow**\n",
    "3. **AMD**\n",
    "4. **Salesforce**\n",
    "5. **Palantir**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9326702c",
   "metadata": {},
   "source": [
    "# DCF model\n",
    "\n",
    "To start I will be conducting the dcf analysis for the yearly data only. Once the Calendar Year Accounts (CY) I will move forward and include the quarterly data aswell. \n",
    "\n",
    "### Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52076f33",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m yearly = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33m./data/financial_statement/MSFT_master.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# First let's create a new dataframe for the DCF\u001b[39;00m\n\u001b[32m      3\u001b[39m dcf = pd.DataFrame()\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "yearly = pd.read_csv('./data/financial_statement/MSFT_master.csv')\n",
    "# First let's create a new dataframe for the DCF\n",
    "dcf = pd.DataFrame()\n",
    "dcf['frame'] = yearly['frame']\n",
    "dcf['Revenue'] = yearly['Income Statement - Revenue - Total Revenue']\n",
    "\n",
    "# Add revenue growth rate to your DCF model\n",
    "dcf['Revenue_Growth_Rate'] = yearly['Revenue - Total Revenue'].pct_change()\n",
    "# Replace NaN in the first row with 0 or remove it as needed\n",
    "dcf['Revenue_Growth_Rate'] = dcf['Revenue_Growth_Rate'].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824b6845",
   "metadata": {},
   "source": [
    "### COGS\n",
    "If I have a column called Cost - Total Cost of Revenue I want to create a new column that populates the COGS column with Total Cost of Revenue column. If the column is not available I want to sum Cost of Product Revenue and Cost of Service Revenue. Before making the addition I want to make sure that these accounts are available\n",
    "\n",
    "This way the code is more generalizable given the different columns names that I can encounter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb59b864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No cost of revenue columns found\n"
     ]
    }
   ],
   "source": [
    "# Create COGS column from available data\n",
    "if 'Cost - Total Cost of Revenue' in yearly.columns:\n",
    "    # Direct assignment if column exists\n",
    "    dcf['COGS'] = yearly['Cost - Total Cost of Revenue']\n",
    "else:\n",
    "    # Check if component columns exist and sum them\n",
    "    product_cost_exists = 'Cost of Product Revenue' in yearly.columns\n",
    "    service_cost_exists = 'Cost of Service Revenue' in yearly.columns\n",
    "    \n",
    "    if product_cost_exists and service_cost_exists:\n",
    "        dcf['COGS'] = yearly['Cost of Product Revenue'] + yearly['Cost of Service Revenue']\n",
    "    elif product_cost_exists:\n",
    "        dcf['COGS'] = yearly['Cost of Product Revenue']\n",
    "    elif service_cost_exists:\n",
    "        dcf['COGS'] = yearly['Cost of Service Revenue']\n",
    "    else:\n",
    "        # No cost columns available\n",
    "        dcf['COGS'] = None\n",
    "        print(\"Warning: No cost of revenue columns found\")\n",
    "\n",
    "dcf['COGS pct of Revenue'] = dcf['COGS']/dcf['Revenue']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a8127",
   "metadata": {},
   "source": [
    "### Gross Profit Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da9b89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Gross - Gross Profit' in yearly.columns:\n",
    "    dcf['Gross Margin'] = yearly['Gross - Gross Profit']\n",
    "else: \n",
    "    dcf['Gross Margin'] = dcf['Revenue'] - dcf['COGS']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec51c04c",
   "metadata": {},
   "source": [
    "### Operating Expenses\n",
    "\n",
    "I have few columns that start with Operating Expenses - Specific Name. \n",
    "For all the columns that start with Operating Expenses I want to bring them to my DCF dataframe and next to all those account I want a new column that computes Operating Expense / Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f94be634",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_ex = [col for col in yearly.columns if col.startswith('Operating Expenses')]\n",
    "\n",
    "for col in op_ex:\n",
    "    name = col.replace('Operating Expenses -','').strip()\n",
    "    if name == 'Research and Development' or 'Sales and Marketing' or 'General and Administrative':\n",
    "        dcf[col] = yearly[col]\n",
    "        ratio_name = f'{name}/Revenue'\n",
    "        dcf[ratio_name] = yearly[col]/dcf['Revenue']\n",
    "    else:\n",
    "        pass\n",
    "dcf['Total Operating Expense'] = dcf[op_ex].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd65542",
   "metadata": {},
   "source": [
    "### EBIT (Operating Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9698aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Operating - Operating Income' in yearly.columns:\n",
    "    dcf['EBIT'] = yearly['Operating - Operating Income']\n",
    "else:\n",
    "    dcf['EBIT'] = dcf['Gross Margin'] - dcf['Total Operating Expense']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c4b2bd",
   "metadata": {},
   "source": [
    "### Tax Expense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2bddeec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Tax - Income Tax Expense/Benefit' in yearly.columns:\n",
    "    dcf['Tax'] = yearly['Tax - Income Tax Expense/Benefit']\n",
    "else: \n",
    "    # The corporate tax rate in the US is around 21% as of 2024\n",
    "    dcf['Tax'] = yearly['EBIT']*0.21\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3840f77c",
   "metadata": {},
   "source": [
    "### Depretiation and Amortization\n",
    "Usually found in the CashFlow Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a063af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Operating - Depreciation and Amortization' in yearly.columns:\n",
    "    dcf['D&A'] = yearly['Operating - Depreciation and Amortization']\n",
    "    dcf['pct_growth_revenue'] = dcf['D&A']/dcf['Revenue']\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f36d4",
   "metadata": {},
   "source": [
    "### Net Working Capital (NWC)\n",
    "For NWC I need Accounts Receivable, Inventory, Accounts Payable, Accrued Expenses and Deffered Liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3da6bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Assets - Accounts Receivable, Net (Current)','Assets - Inventory','Liabilities - Accounts Payable']\n",
    "dcf['NWC'] = 0\n",
    "for col in cols:\n",
    "    if col in yearly.columns:\n",
    "        name = col.split('-')[1].strip()\n",
    "        dcf[name] = yearly[col]\n",
    "    \n",
    "        if col.split('-')[0].strip()=='Liabilities':\n",
    "            dcf['NWC'] = dcf['NWC'] - dcf[name]\n",
    "            dcf[f'{name}/COGS'] = dcf[name]/dcf['COGS']\n",
    "\n",
    "        else:\n",
    "            dcf[f'{name}/Revenue'] = dcf[name]/dcf['Revenue']\n",
    "            dcf['NWC'] = dcf['NWC'] + dcf[name]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65b52a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute delta NWC\n",
    "dcf['Delta NWC'] = dcf['NWC'].diff()\n",
    "\n",
    "# Replace NaN in the first row with 0 or handle it as needed\n",
    "dcf['Delta NWC'] = dcf['Delta NWC'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a7bb197",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Investing - Capital Expenditures' in yearly.columns:\n",
    "    dcf['CAPEX'] = yearly['Investing - Capital Expenditures']\n",
    "    dcf['CAPEX/Revenue'] = dcf['CAPEX']/dcf['Revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed25b834",
   "metadata": {},
   "source": [
    "### FCF\n",
    "$$ FCF = EBIT - Tax + D\\&A - DeltaNWC - CAPEX$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cf61527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sp = pd.read_csv('./data/sp500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a096fb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Industrials', 'Health Care', 'Information Technology',\n",
       "       'Utilities', 'Financials', 'Materials', 'Consumer Discretionary',\n",
       "       'Real Estate', 'Communication Services', 'Consumer Staples',\n",
       "       'Energy'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp['GICS Sector'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33aecd",
   "metadata": {},
   "source": [
    "# API call for where different financial model is important\n",
    "\n",
    "Here I am categorizing different Industry and different analysis metrics. \n",
    "- In Information Technology the norme is to compute the **DCF** Model\n",
    "- In **Financials** We need to compute the *Dividend Discount Model* **DDM**\n",
    "- In **Real Estate** we need Net Asset Values **NAV**\n",
    "\n",
    "This is how we will categorize and price these different companies in different sector because this is how a fundamental analyst would have done so \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc9af8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dcf = ['Information Technology','Communication Services','Consumer Discretionary','Consumer Staples','Health Care','Industrials','Materials']\n",
    "ddm = ['Utilities','Financials']\n",
    "nav = ['Real Estate','Energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "471333c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = sp[sp['GICS Sector']=='Information Technology']\n",
    "cs = sp[sp['GICS Sector']=='Communication Services']\n",
    "cd = sp[sp['GICS Sector']=='Consumer Discretionary']\n",
    "css = sp[sp['GICS Sector']=='Consumer Staples']\n",
    "hc = sp[sp['GICS Sector']=='Health Care']\n",
    "ind = sp[sp['GICS Sector']=='Industrials']\n",
    "mat = sp[sp['GICS Sector']=='Materials']\n",
    "df = pd.concat([it, cs, cd,css,hc,ind,mat], ignore_index=True)\n",
    "# After your existing code\n",
    "df_one_per_subindustry = df.groupby('GICS Sub-Industry').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11180570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advertising</td>\n",
       "      <td>254</td>\n",
       "      <td>IPG</td>\n",
       "      <td>Interpublic Group of Companies (The)</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>New York City, New York</td>\n",
       "      <td>1992-10-01</td>\n",
       "      <td>51644</td>\n",
       "      <td>1961 (1930)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aerospace &amp; Defense</td>\n",
       "      <td>54</td>\n",
       "      <td>AXON</td>\n",
       "      <td>Axon Enterprise</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Scottsdale, Arizona</td>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>1069183</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agricultural &amp; Farm Machinery</td>\n",
       "      <td>141</td>\n",
       "      <td>DE</td>\n",
       "      <td>Deere &amp; Company</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Moline, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>315189</td>\n",
       "      <td>1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agricultural Products &amp; Services</td>\n",
       "      <td>43</td>\n",
       "      <td>ADM</td>\n",
       "      <td>Archer Daniels Midland</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>7084</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Freight &amp; Logistics</td>\n",
       "      <td>79</td>\n",
       "      <td>CHRW</td>\n",
       "      <td>C.H. Robinson</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Eden Prairie, Minnesota</td>\n",
       "      <td>2007-03-02</td>\n",
       "      <td>1043277</td>\n",
       "      <td>1905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Technology Distributors</td>\n",
       "      <td>92</td>\n",
       "      <td>CDW</td>\n",
       "      <td>CDW</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Vernon Hills, Illinois</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>1402057</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Technology Hardware, Storage &amp; Peripherals</td>\n",
       "      <td>39</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Cupertino, California</td>\n",
       "      <td>1982-11-30</td>\n",
       "      <td>320193</td>\n",
       "      <td>1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Tobacco</td>\n",
       "      <td>21</td>\n",
       "      <td>MO</td>\n",
       "      <td>Altria</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>Richmond, Virginia</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>764180</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Trading Companies &amp; Distributors</td>\n",
       "      <td>190</td>\n",
       "      <td>FAST</td>\n",
       "      <td>Fastenal</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Winona, Minnesota</td>\n",
       "      <td>2008-09-15</td>\n",
       "      <td>815556</td>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Wireless Telecommunication Services</td>\n",
       "      <td>432</td>\n",
       "      <td>TMUS</td>\n",
       "      <td>T-Mobile US</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>Bellevue, Washington</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>1283699</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             GICS Sub-Industry  Unnamed: 0 Symbol  \\\n",
       "0                                  Advertising         254    IPG   \n",
       "1                          Aerospace & Defense          54   AXON   \n",
       "2                Agricultural & Farm Machinery         141     DE   \n",
       "3             Agricultural Products & Services          43    ADM   \n",
       "4                      Air Freight & Logistics          79   CHRW   \n",
       "..                                         ...         ...    ...   \n",
       "86                     Technology Distributors          92    CDW   \n",
       "87  Technology Hardware, Storage & Peripherals          39   AAPL   \n",
       "88                                     Tobacco          21     MO   \n",
       "89            Trading Companies & Distributors         190   FAST   \n",
       "90         Wireless Telecommunication Services         432   TMUS   \n",
       "\n",
       "                                Security             GICS Sector  \\\n",
       "0   Interpublic Group of Companies (The)  Communication Services   \n",
       "1                        Axon Enterprise             Industrials   \n",
       "2                        Deere & Company             Industrials   \n",
       "3                 Archer Daniels Midland        Consumer Staples   \n",
       "4                          C.H. Robinson             Industrials   \n",
       "..                                   ...                     ...   \n",
       "86                                   CDW  Information Technology   \n",
       "87                            Apple Inc.  Information Technology   \n",
       "88                                Altria        Consumer Staples   \n",
       "89                              Fastenal             Industrials   \n",
       "90                           T-Mobile US  Communication Services   \n",
       "\n",
       "      Headquarters Location  Date added      CIK      Founded  \n",
       "0   New York City, New York  1992-10-01    51644  1961 (1930)  \n",
       "1       Scottsdale, Arizona  2023-05-04  1069183         1993  \n",
       "2          Moline, Illinois  1957-03-04   315189         1837  \n",
       "3         Chicago, Illinois  1957-03-04     7084         1902  \n",
       "4   Eden Prairie, Minnesota  2007-03-02  1043277         1905  \n",
       "..                      ...         ...      ...          ...  \n",
       "86   Vernon Hills, Illinois  2019-09-23  1402057         1984  \n",
       "87    Cupertino, California  1982-11-30   320193         1977  \n",
       "88       Richmond, Virginia  1957-03-04   764180         1985  \n",
       "89        Winona, Minnesota  2008-09-15   815556         1967  \n",
       "90     Bellevue, Washington  2019-07-15  1283699         1994  \n",
       "\n",
       "[91 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_per_subindustry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8bd6b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing IPG (Attempt 1/3)\n",
      "Successfully processed IPG\n",
      "Processing AXON (Attempt 1/3)\n",
      "Successfully processed AXON\n",
      "Processing DE (Attempt 1/3)\n",
      "Successfully processed DE\n",
      "Processing ADM (Attempt 1/3)\n",
      "Successfully processed ADM\n",
      "Processing CHRW (Attempt 1/3)\n",
      "Successfully processed CHRW\n",
      "Processing ROST (Attempt 1/3)\n",
      "Successfully processed ROST\n",
      "Processing LULU (Attempt 1/3)\n",
      "Successfully processed LULU\n",
      "Processing ADBE (Attempt 1/3)\n",
      "Successfully processed ADBE\n",
      "Processing F (Attempt 1/3)\n",
      "Successfully processed F\n",
      "Processing APTV (Attempt 1/3)\n",
      "Successfully processed APTV\n",
      "Processing AZO (Attempt 1/3)\n",
      "Successfully processed AZO\n",
      "Processing ABBV (Attempt 1/3)\n",
      "Successfully processed ABBV\n",
      "Processing TAP (Attempt 1/3)\n",
      "Successfully processed TAP\n",
      "Processing FOXA (Attempt 1/3)\n",
      "Successfully processed FOXA\n",
      "Processing AMZN (Attempt 1/3)\n",
      "Successfully processed AMZN\n",
      "Processing AOS (Attempt 1/3)\n",
      "Successfully processed AOS\n",
      "Processing CHTR (Attempt 1/3)\n",
      "Successfully processed CHTR\n",
      "Processing JBHT (Attempt 1/3)\n",
      "Successfully processed JBHT\n",
      "Processing CZR (Attempt 1/3)\n",
      "Successfully processed CZR\n",
      "Processing DOW (Attempt 1/3)\n",
      "Successfully processed DOW\n",
      "Processing ANET (Attempt 1/3)\n",
      "Successfully processed ANET\n",
      "Processing BBY (Attempt 1/3)\n",
      "Successfully processed BBY\n",
      "Processing J (Attempt 1/3)\n",
      "Successfully processed J\n",
      "Processing CAT (Attempt 1/3)\n",
      "Successfully processed CAT\n",
      "Processing MLM (Attempt 1/3)\n",
      "Successfully processed MLM\n",
      "Processing GRMN (Attempt 1/3)\n",
      "Successfully processed GRMN\n",
      "Processing COST (Attempt 1/3)\n",
      "Successfully processed COST\n",
      "Processing FCX (Attempt 1/3)\n",
      "Successfully processed FCX\n",
      "Processing BR (Attempt 1/3)\n",
      "Successfully processed BR\n",
      "Processing BF.B (Attempt 1/3)\n",
      "File not found for BF.B. Skipping...\n",
      "Processing GPC (Attempt 1/3)\n",
      "Successfully processed GPC\n",
      "Processing CTAS (Attempt 1/3)\n",
      "Successfully processed CTAS\n",
      "Processing WBA (Attempt 1/3)\n",
      "Successfully processed WBA\n",
      "Processing AME (Attempt 1/3)\n",
      "Successfully processed AME\n",
      "Processing APH (Attempt 1/3)\n",
      "Successfully processed APH\n",
      "Processing KEYS (Attempt 1/3)\n",
      "Successfully processed KEYS\n",
      "Processing JBL (Attempt 1/3)\n",
      "Successfully processed JBL\n",
      "Processing RSG (Attempt 1/3)\n",
      "Successfully processed RSG\n",
      "Processing CF (Attempt 1/3)\n",
      "Successfully processed CF\n",
      "Processing SYY (Attempt 1/3)\n",
      "Successfully processed SYY\n",
      "Processing KR (Attempt 1/3)\n",
      "Successfully processed KR\n",
      "Processing DECK (Attempt 1/3)\n",
      "Successfully processed DECK\n",
      "Processing NEM (Attempt 1/3)\n",
      "Successfully processed NEM\n",
      "Processing CAH (Attempt 1/3)\n",
      "Successfully processed CAH\n",
      "Processing ABT (Attempt 1/3)\n",
      "Successfully processed ABT\n",
      "Processing HCA (Attempt 1/3)\n",
      "Successfully processed HCA\n",
      "Processing CI (Attempt 1/3)\n",
      "Successfully processed CI\n",
      "Processing ALGN (Attempt 1/3)\n",
      "Successfully processed ALGN\n",
      "Processing SOLV (Attempt 1/3)\n",
      "Successfully processed SOLV\n",
      "Processing GEV (Attempt 1/3)\n",
      "Successfully processed GEV\n",
      "Processing MHK (Attempt 1/3)\n",
      "Successfully processed MHK\n",
      "Processing HD (Attempt 1/3)\n",
      "Successfully processed HD\n",
      "Processing DHI (Attempt 1/3)\n",
      "Successfully processed DHI\n",
      "Processing ABNB (Attempt 1/3)\n",
      "Successfully processed ABNB\n",
      "Processing CHD (Attempt 1/3)\n",
      "Successfully processed CHD\n",
      "Processing ADP (Attempt 1/3)\n",
      "Successfully processed ADP\n",
      "Processing ACN (Attempt 1/3)\n",
      "Successfully processed ACN\n",
      "Processing MMM (Attempt 1/3)\n",
      "Successfully processed MMM\n",
      "Processing APD (Attempt 1/3)\n",
      "Successfully processed APD\n",
      "Processing DOV (Attempt 1/3)\n",
      "Successfully processed DOV\n",
      "Processing T (Attempt 1/3)\n",
      "Successfully processed T\n",
      "Processing EA (Attempt 1/3)\n",
      "Successfully processed EA\n",
      "Processing GOOGL (Attempt 1/3)\n",
      "Successfully processed GOOGL\n",
      "Processing AKAM (Attempt 1/3)\n",
      "Successfully processed AKAM\n",
      "Processing HAS (Attempt 1/3)\n",
      "Successfully processed HAS\n",
      "Processing A (Attempt 1/3)\n",
      "Successfully processed A\n",
      "Processing CNC (Attempt 1/3)\n",
      "Successfully processed CNC\n",
      "Processing BALL (Attempt 1/3)\n",
      "Successfully processed BALL\n",
      "Processing LYV (Attempt 1/3)\n",
      "Successfully processed LYV\n",
      "Processing TSCO (Attempt 1/3)\n",
      "Successfully processed TSCO\n",
      "Processing CPB (Attempt 1/3)\n",
      "Successfully processed CPB\n",
      "Processing AMCR (Attempt 1/3)\n",
      "Successfully processed AMCR\n",
      "Processing DAL (Attempt 1/3)\n",
      "Successfully processed DAL\n",
      "Processing UBER (Attempt 1/3)\n",
      "Successfully processed UBER\n",
      "Processing EL (Attempt 1/3)\n",
      "Successfully processed EL\n",
      "Processing BMY (Attempt 1/3)\n",
      "Successfully processed BMY\n",
      "Processing NWSA (Attempt 1/3)\n",
      "Successfully processed NWSA\n",
      "Processing CSX (Attempt 1/3)\n",
      "Successfully processed CSX\n",
      "Processing EFX (Attempt 1/3)\n",
      "Successfully processed EFX\n",
      "Processing CMG (Attempt 1/3)\n",
      "Successfully processed CMG\n",
      "Processing AMAT (Attempt 1/3)\n",
      "Successfully processed AMAT\n",
      "Processing AMD (Attempt 1/3)\n",
      "Successfully processed AMD\n",
      "Processing KO (Attempt 1/3)\n",
      "Successfully processed KO\n",
      "Processing ALB (Attempt 1/3)\n",
      "Successfully processed ALB\n",
      "Processing NUE (Attempt 1/3)\n",
      "Successfully processed NUE\n",
      "Processing CRWD (Attempt 1/3)\n",
      "Successfully processed CRWD\n",
      "Processing CDW (Attempt 1/3)\n",
      "Successfully processed CDW\n",
      "Processing AAPL (Attempt 1/3)\n",
      "Successfully processed AAPL\n",
      "Processing MO (Attempt 1/3)\n",
      "Successfully processed MO\n",
      "Processing FAST (Attempt 1/3)\n",
      "Successfully processed FAST\n",
      "Processing TMUS (Attempt 1/3)\n",
      "Successfully processed TMUS\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Everytime I will manually change the Sector name to the one I want to analyze and safe the data.\n",
    "sp_analysis = df_one_per_subindustry.copy()\n",
    "\n",
    "# Initialize counter and accounts storage\n",
    "ix = 0\n",
    "sp_analysis['accounts'] = None\n",
    "sp_analysis['question_prompt'] = None\n",
    "\n",
    "# Process each company\n",
    "for idx, row in sp_analysis.iterrows():\n",
    "    symbol = row['Symbol']\n",
    "    sub_industry = row['GICS Sub-Industry']\n",
    "    \n",
    "    # Retry configuration\n",
    "    max_retries = 3\n",
    "    retry_count = 0\n",
    "    success = False\n",
    "    \n",
    "    while retry_count < max_retries and not success:\n",
    "        try:\n",
    "            print(f'Processing {symbol} (Attempt {retry_count + 1}/{max_retries})')\n",
    "            \n",
    "            # Read the financial statement\n",
    "            df = pd.read_csv(f'./data/financial_statement/{symbol}_master.csv')\n",
    "            accounts = df.columns.to_list()\n",
    "            \n",
    "            # Store accounts in the dataframe\n",
    "            sp_analysis.at[idx, 'accounts'] = accounts\n",
    "            \n",
    "            # Create the prompt\n",
    "            accounts_str = ', '.join(accounts)\n",
    "            prompt = (\n",
    "                \"Hey Gemini I want a concise answer. \\n\" +\n",
    "                \" The Goal is to create a standard DCF model using the mappings you will provide. Take into account the account names for the specific industry and create a mapping code like shown in the example bellow \"+\n",
    "                \"Make sure the answer is given in JSON format \"+\n",
    "                \"\\n ------ \\n\" +\n",
    "                f\"Here are account names for companies that are in {sub_industry} sub-industry. \\n\" +\n",
    "                accounts_str + \"I want these accounts to be mapped like this: \\n\" +\n",
    "                \"\"\"I want you to use these accounts and create a mapping like this\n",
    "                Make sure to always write Sub-Industry name in Pascal format: .... for example {\n",
    "                \"**ApplicationSoftware**\": {\n",
    "                \"revenue\": [\n",
    "                \"IncomeStatement - Revenues - TotalRevenue\"\n",
    "                ],\n",
    "                \"cogs\": [\n",
    "                \"IncomeStatement - Expenses - CostOfRevenue\"\n",
    "                ],\n",
    "                \"operating_expenses\": [\n",
    "                \"IncomeStatement - Expenses - SalesAndMarketing\",\n",
    "                \"IncomeStatement - Expenses - GeneralAndAdministrative\"\n",
    "                ],\n",
    "                \"d_and_a\": [\n",
    "                \"CashFlow - OperatingActivities - DepreciationAndAmortization\"\n",
    "                ],\n",
    "                \"capex\": [\n",
    "                \"CashFlow - InvestingActivities - CapitalExpenditures\"\n",
    "                ],\n",
    "                \"stock_based_compensation\": [\n",
    "                \"CashFlow - OperatingActivities - ShareBasedCompensation\"\n",
    "                ],\n",
    "                \"nwc_operating_assets\": [\n",
    "                \"Assets - AccountsReceivable\",\n",
    "                \"Assets - ContractAssets\",\n",
    "                \"Assets - CapitalizedContractCosts\",\n",
    "                \"Assets - PrepaidExpenses\"\n",
    "                ],\n",
    "                \"nwc_operating_liabilities\": [\n",
    "                \"Liabilities - AccountsPayable\",\n",
    "                \"Liabilities - AccruedLiabilities\",\n",
    "                \"Liabilities - DeferredRevenue\"\n",
    "                ]\n",
    "                }\n",
    "                }\n",
    "                Make sure the answer is just the mapping no introduction sentence no ending sentence just the mapping code\"\"\"+ \"\"\"Don't add any other comments i.e ( // Note: DepreciationAndAmortization, ShareBasedCompensation, and RestructuringCharges are typically excluded\n",
    "                // from core operating expenses for normalized free cash flow calculation.)\"\"\"\n",
    "                            )\n",
    "            \n",
    "            sp_analysis.at[idx, 'question_prompt'] = str(prompt)\n",
    "            \n",
    "            # Mark as successful\n",
    "            success = True\n",
    "            print(f'Successfully processed {symbol}')\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f'File not found for {symbol}. Skipping...')\n",
    "            # Don't retry for file not found errors\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f'Error processing {symbol}: {e}')\n",
    "            \n",
    "            if retry_count < max_retries:\n",
    "                print(f'Waiting 60 seconds before retry...')\n",
    "                time.sleep(60)  # Wait 1 minute before retrying\n",
    "            else:\n",
    "                print(f'Max retries reached for {symbol}. Moving to next company.')\n",
    "                # Optionally store error information\n",
    "                sp_analysis.at[idx, 'error'] = str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b69ed59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing IPG (Attempt 1/3)\n",
      "Successfully processed IPG\n",
      "Available target accounts: 12/13\n",
      "Processing AXON (Attempt 1/3)\n",
      "Successfully processed AXON\n",
      "Available target accounts: 13/13\n",
      "Processing DE (Attempt 1/3)\n",
      "Successfully processed DE\n",
      "Available target accounts: 13/13\n",
      "Processing ADM (Attempt 1/3)\n",
      "Successfully processed ADM\n",
      "Available target accounts: 5/13\n",
      "Processing CHRW (Attempt 1/3)\n",
      "Successfully processed CHRW\n",
      "Available target accounts: 12/13\n",
      "Processing ROST (Attempt 1/3)\n",
      "Successfully processed ROST\n",
      "Available target accounts: 6/13\n",
      "Processing LULU (Attempt 1/3)\n",
      "Successfully processed LULU\n",
      "Available target accounts: 7/13\n",
      "Processing ADBE (Attempt 1/3)\n",
      "Successfully processed ADBE\n",
      "Available target accounts: 13/13\n",
      "Processing F (Attempt 1/3)\n",
      "Successfully processed F\n",
      "Available target accounts: 5/13\n",
      "Processing APTV (Attempt 1/3)\n",
      "Successfully processed APTV\n",
      "Available target accounts: 5/13\n",
      "Processing AZO (Attempt 1/3)\n",
      "Successfully processed AZO\n",
      "Available target accounts: 6/13\n",
      "Processing ABBV (Attempt 1/3)\n",
      "Successfully processed ABBV\n",
      "Available target accounts: 4/13\n",
      "Processing TAP (Attempt 1/3)\n",
      "Successfully processed TAP\n",
      "Available target accounts: 5/13\n",
      "Processing FOXA (Attempt 1/3)\n",
      "Successfully processed FOXA\n",
      "Available target accounts: 10/13\n",
      "Processing AMZN (Attempt 1/3)\n",
      "Successfully processed AMZN\n",
      "Available target accounts: 4/13\n",
      "Processing AOS (Attempt 1/3)\n",
      "Successfully processed AOS\n",
      "Available target accounts: 13/13\n",
      "Processing CHTR (Attempt 1/3)\n",
      "Successfully processed CHTR\n",
      "Available target accounts: 11/13\n",
      "Processing JBHT (Attempt 1/3)\n",
      "Successfully processed JBHT\n",
      "Available target accounts: 11/13\n",
      "Processing CZR (Attempt 1/3)\n",
      "Successfully processed CZR\n",
      "Available target accounts: 5/13\n",
      "Processing DOW (Attempt 1/3)\n",
      "Successfully processed DOW\n",
      "Available target accounts: 7/13\n",
      "Processing ANET (Attempt 1/3)\n",
      "Successfully processed ANET\n",
      "Available target accounts: 1/13\n",
      "Processing BBY (Attempt 1/3)\n",
      "Successfully processed BBY\n",
      "Available target accounts: 4/13\n",
      "Processing J (Attempt 1/3)\n",
      "Successfully processed J\n",
      "Available target accounts: 12/13\n",
      "Processing CAT (Attempt 1/3)\n",
      "Successfully processed CAT\n",
      "Available target accounts: 1/13\n",
      "Processing MLM (Attempt 1/3)\n",
      "Successfully processed MLM\n",
      "Available target accounts: 7/13\n",
      "Processing GRMN (Attempt 1/3)\n",
      "Successfully processed GRMN\n",
      "Available target accounts: 6/13\n",
      "Processing COST (Attempt 1/3)\n",
      "Successfully processed COST\n",
      "Available target accounts: 3/13\n",
      "Processing FCX (Attempt 1/3)\n",
      "Successfully processed FCX\n",
      "Available target accounts: 7/13\n",
      "Processing BR (Attempt 1/3)\n",
      "Successfully processed BR\n",
      "Available target accounts: 13/13\n",
      "Processing BF.B (Attempt 1/3)\n",
      "File not found for BF.B. Skipping...\n",
      "Processing GPC (Attempt 1/3)\n",
      "Successfully processed GPC\n",
      "Available target accounts: 4/13\n",
      "Processing CTAS (Attempt 1/3)\n",
      "Successfully processed CTAS\n",
      "Available target accounts: 12/13\n",
      "Processing WBA (Attempt 1/3)\n",
      "Successfully processed WBA\n",
      "Available target accounts: 3/13\n",
      "Processing AME (Attempt 1/3)\n",
      "Successfully processed AME\n",
      "Available target accounts: 12/13\n",
      "Processing APH (Attempt 1/3)\n",
      "Successfully processed APH\n",
      "Available target accounts: 7/13\n",
      "Processing KEYS (Attempt 1/3)\n",
      "Successfully processed KEYS\n",
      "Available target accounts: 5/13\n",
      "Processing JBL (Attempt 1/3)\n",
      "Successfully processed JBL\n",
      "Available target accounts: 7/13\n",
      "Processing RSG (Attempt 1/3)\n",
      "Successfully processed RSG\n",
      "Available target accounts: 10/13\n",
      "Processing CF (Attempt 1/3)\n",
      "Successfully processed CF\n",
      "Available target accounts: 6/13\n",
      "Processing SYY (Attempt 1/3)\n",
      "Successfully processed SYY\n",
      "Available target accounts: 2/13\n",
      "Processing KR (Attempt 1/3)\n",
      "Successfully processed KR\n",
      "Available target accounts: 3/13\n",
      "Processing DECK (Attempt 1/3)\n",
      "Successfully processed DECK\n",
      "Available target accounts: 6/13\n",
      "Processing NEM (Attempt 1/3)\n",
      "Successfully processed NEM\n",
      "Available target accounts: 7/13\n",
      "Processing CAH (Attempt 1/3)\n",
      "Successfully processed CAH\n",
      "Available target accounts: 5/13\n",
      "Processing ABT (Attempt 1/3)\n",
      "Successfully processed ABT\n",
      "Available target accounts: 4/13\n",
      "Processing HCA (Attempt 1/3)\n",
      "Successfully processed HCA\n",
      "Available target accounts: 4/13\n",
      "Processing CI (Attempt 1/3)\n",
      "Successfully processed CI\n",
      "Available target accounts: 4/13\n",
      "Processing ALGN (Attempt 1/3)\n",
      "Successfully processed ALGN\n",
      "Available target accounts: 1/13\n",
      "Processing SOLV (Attempt 1/3)\n",
      "Successfully processed SOLV\n",
      "Available target accounts: 5/13\n",
      "Processing GEV (Attempt 1/3)\n",
      "Successfully processed GEV\n",
      "Available target accounts: 10/13\n",
      "Processing MHK (Attempt 1/3)\n",
      "Successfully processed MHK\n",
      "Available target accounts: 7/13\n",
      "Processing HD (Attempt 1/3)\n",
      "Successfully processed HD\n",
      "Available target accounts: 7/13\n",
      "Processing DHI (Attempt 1/3)\n",
      "Successfully processed DHI\n",
      "Available target accounts: 7/13\n",
      "Processing ABNB (Attempt 1/3)\n",
      "Successfully processed ABNB\n",
      "Available target accounts: 5/13\n",
      "Processing CHD (Attempt 1/3)\n",
      "Successfully processed CHD\n",
      "Available target accounts: 3/13\n",
      "Processing ADP (Attempt 1/3)\n",
      "Successfully processed ADP\n",
      "Available target accounts: 10/13\n",
      "Processing ACN (Attempt 1/3)\n",
      "Successfully processed ACN\n",
      "Available target accounts: 11/13\n",
      "Processing MMM (Attempt 1/3)\n",
      "Successfully processed MMM\n",
      "Available target accounts: 7/13\n",
      "Processing APD (Attempt 1/3)\n",
      "Successfully processed APD\n",
      "Available target accounts: 7/13\n",
      "Processing DOV (Attempt 1/3)\n",
      "Successfully processed DOV\n",
      "Available target accounts: 7/13\n",
      "Processing T (Attempt 1/3)\n",
      "Successfully processed T\n",
      "Available target accounts: 11/13\n",
      "Processing EA (Attempt 1/3)\n",
      "Successfully processed EA\n",
      "Available target accounts: 13/13\n",
      "Processing GOOGL (Attempt 1/3)\n",
      "Successfully processed GOOGL\n",
      "Available target accounts: 12/13\n",
      "Processing AKAM (Attempt 1/3)\n",
      "Successfully processed AKAM\n",
      "Available target accounts: 12/13\n",
      "Processing HAS (Attempt 1/3)\n",
      "Successfully processed HAS\n",
      "Available target accounts: 7/13\n",
      "Processing A (Attempt 1/3)\n",
      "Successfully processed A\n",
      "Available target accounts: 4/13\n",
      "Processing CNC (Attempt 1/3)\n",
      "Successfully processed CNC\n",
      "Available target accounts: 4/13\n",
      "Processing BALL (Attempt 1/3)\n",
      "Successfully processed BALL\n",
      "Available target accounts: 6/13\n",
      "Processing LYV (Attempt 1/3)\n",
      "Successfully processed LYV\n",
      "Available target accounts: 11/13\n",
      "Processing TSCO (Attempt 1/3)\n",
      "Successfully processed TSCO\n",
      "Available target accounts: 7/13\n",
      "Processing CPB (Attempt 1/3)\n",
      "Successfully processed CPB\n",
      "Available target accounts: 3/13\n",
      "Processing AMCR (Attempt 1/3)\n",
      "Successfully processed AMCR\n",
      "Available target accounts: 6/13\n",
      "Processing DAL (Attempt 1/3)\n",
      "Successfully processed DAL\n",
      "Available target accounts: 3/13\n",
      "Processing UBER (Attempt 1/3)\n",
      "Successfully processed UBER\n",
      "Available target accounts: 4/13\n",
      "Processing EL (Attempt 1/3)\n",
      "Successfully processed EL\n",
      "Available target accounts: 2/13\n",
      "Processing BMY (Attempt 1/3)\n",
      "Successfully processed BMY\n",
      "Available target accounts: 5/13\n",
      "Processing NWSA (Attempt 1/3)\n",
      "Successfully processed NWSA\n",
      "Available target accounts: 11/13\n",
      "Processing CSX (Attempt 1/3)\n",
      "Successfully processed CSX\n",
      "Available target accounts: 4/13\n",
      "Processing EFX (Attempt 1/3)\n",
      "Successfully processed EFX\n",
      "Available target accounts: 5/13\n",
      "Processing CMG (Attempt 1/3)\n",
      "Successfully processed CMG\n",
      "Available target accounts: 7/13\n",
      "Processing AMAT (Attempt 1/3)\n",
      "Successfully processed AMAT\n",
      "Available target accounts: 13/13\n",
      "Processing AMD (Attempt 1/3)\n",
      "Successfully processed AMD\n",
      "Available target accounts: 12/13\n",
      "Processing KO (Attempt 1/3)\n",
      "Successfully processed KO\n",
      "Available target accounts: 2/13\n",
      "Processing ALB (Attempt 1/3)\n",
      "Successfully processed ALB\n",
      "Available target accounts: 5/13\n",
      "Processing NUE (Attempt 1/3)\n",
      "Successfully processed NUE\n",
      "Available target accounts: 6/13\n",
      "Processing CRWD (Attempt 1/3)\n",
      "Successfully processed CRWD\n",
      "Available target accounts: 12/13\n",
      "Processing CDW (Attempt 1/3)\n",
      "Successfully processed CDW\n",
      "Available target accounts: 12/13\n",
      "Processing AAPL (Attempt 1/3)\n",
      "Successfully processed AAPL\n",
      "Available target accounts: 13/13\n",
      "Processing MO (Attempt 1/3)\n",
      "Successfully processed MO\n",
      "Available target accounts: 3/13\n",
      "Processing FAST (Attempt 1/3)\n",
      "Successfully processed FAST\n",
      "Available target accounts: 4/13\n",
      "Processing TMUS (Attempt 1/3)\n",
      "Successfully processed TMUS\n",
      "Available target accounts: 5/13\n",
      "\n",
      "==================================================\n",
      "SUMMARY OF ACCOUNT AVAILABILITY\n",
      "==================================================\n",
      "\n",
      "Total companies processed: 91\n",
      "\n",
      "Account availability across companies:\n",
      "  frame: 90/91 (98.9%)\n",
      "  total_assets: 87/91 (95.6%)\n",
      "  total_liabilities: 60/91 (65.9%)\n",
      "  total_equity: 56/91 (61.5%)\n",
      "  total_revenue: 37/91 (40.7%)\n",
      "  gross_profit: 22/91 (24.2%)\n",
      "  operating_income: 24/91 (26.4%)\n",
      "  net_income: 28/91 (30.8%)\n",
      "  comprehensive_income: 25/91 (27.5%)\n",
      "  basic_eps: 43/91 (47.3%)\n",
      "  diluted_eps: 43/91 (47.3%)\n",
      "  shares_basic: 59/91 (64.8%)\n",
      "  shares_diluted: 59/91 (64.8%)\n",
      "\n",
      "Results saved to: financial_mapping_analysis_1749477525.csv\n",
      "Sample mapping saved to: sample_mapping_1749477525.json\n",
      "\n",
      "Processing complete! Review the prompts and use them with your AI to generate the final JSON mappings.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Target accounts we're looking for\n",
    "target_accounts = {\n",
    "    'frame': 'frame',\n",
    "    'total_assets': 'Assets - TotalAssets',\n",
    "    'total_liabilities': 'Liabilities - TotalLiabilities', \n",
    "    'total_equity': 'Equity - TotalStockholdersEquity',\n",
    "    'total_revenue': 'IncomeStatement - Revenues - TotalRevenue',\n",
    "    'gross_profit': 'IncomeStatement - OtherIncomeExpense - GrossProfit',\n",
    "    'operating_income': 'IncomeStatement - OtherIncomeExpense - OperatingIncome',\n",
    "    'net_income': 'IncomeStatement - NetIncome - NetIncome',\n",
    "    'comprehensive_income': 'IncomeStatement - NetIncome - ComprehensiveIncome',\n",
    "    'basic_eps': 'IncomeStatement - EarningsPerShare - BasicEps',\n",
    "    'diluted_eps': 'IncomeStatement - EarningsPerShare - DilutedEps',\n",
    "    'shares_basic': 'IncomeStatement - EarningsPerShare - WeightedAverageSharesBasic',\n",
    "    'shares_diluted': 'IncomeStatement - EarningsPerShare - WeightedAverageSharesDiluted'\n",
    "}\n",
    "\n",
    "# Everytime I will manually change the Sector name to the one I want to analyze and save the data.\n",
    "sp_analysis = df_one_per_subindustry.copy()\n",
    "\n",
    "# Initialize counter and accounts storage\n",
    "ix = 0\n",
    "sp_analysis['accounts'] = None\n",
    "sp_analysis['question_prompt'] = None\n",
    "sp_analysis['available_target_accounts'] = None\n",
    "\n",
    "# Process each company\n",
    "for idx, row in sp_analysis.iterrows():\n",
    "    symbol = row['Symbol']\n",
    "    sub_industry = row['GICS Sub-Industry']\n",
    "    \n",
    "    # Retry configuration\n",
    "    max_retries = 3\n",
    "    retry_count = 0\n",
    "    success = False\n",
    "    \n",
    "    while retry_count < max_retries and not success:\n",
    "        try:\n",
    "            print(f'Processing {symbol} (Attempt {retry_count + 1}/{max_retries})')\n",
    "            \n",
    "            # Read the financial statement\n",
    "            df = pd.read_csv(f'./data/financial_statement/{symbol}_master.csv')\n",
    "            accounts = df.columns.to_list()\n",
    "            \n",
    "            # Store accounts in the dataframe\n",
    "            sp_analysis.at[idx, 'accounts'] = accounts\n",
    "            \n",
    "            # Find which target accounts are available (exact matches)\n",
    "            available_targets = {}\n",
    "            for key, target_col in target_accounts.items():\n",
    "                if target_col in accounts:\n",
    "                    available_targets[key] = target_col\n",
    "            \n",
    "            # Store available target accounts\n",
    "            sp_analysis.at[idx, 'available_target_accounts'] = available_targets\n",
    "            \n",
    "            # Create the prompt for mapping\n",
    "            accounts_str = ', '.join(accounts)\n",
    "            \n",
    "            # Convert sub_industry to PascalCase\n",
    "            pascal_sub_industry = ''.join(word.capitalize() for word in sub_industry.replace('-', ' ').replace('&', 'And').split())\n",
    "            \n",
    "            prompt = (\n",
    "                \"Analyze the financial statement columns and create a JSON mapping for these specific accounts. \"\n",
    "                \"Return ONLY the JSON mapping with no additional text or explanations.\\n\\n\"\n",
    "                f\"Industry: {sub_industry}\\n\"\n",
    "                f\"Available columns: {accounts_str}\\n\\n\"\n",
    "                \"Find exact matches or closest equivalents for these target accounts:\\n\"\n",
    "                \"1. frame - Time period identifier\\n\"\n",
    "                \"2. Assets - TotalAssets - Total assets from balance sheet\\n\"\n",
    "                \"3. Liabilities - TotalLiabilities - Total liabilities from balance sheet\\n\"\n",
    "                \"4. Equity - TotalStockholdersEquity - Total stockholders equity\\n\"\n",
    "                \"5. IncomeStatement - Revenues - TotalRevenue - Total revenue/sales\\n\"\n",
    "                \"6. IncomeStatement - OtherIncomeExpense - GrossProfit - Gross profit\\n\"\n",
    "                \"7. IncomeStatement - OtherIncomeExpense - OperatingIncome - Operating income\\n\"\n",
    "                \"8. IncomeStatement - NetIncome - NetIncome - Net income\\n\"\n",
    "                \"9. IncomeStatement - NetIncome - ComprehensiveIncome - Comprehensive income\\n\"\n",
    "                \"10. IncomeStatement - EarningsPerShare - BasicEps - Basic earnings per share\\n\"\n",
    "                \"11. IncomeStatement - EarningsPerShare - DilutedEps - Diluted earnings per share\\n\"\n",
    "                \"12. IncomeStatement - EarningsPerShare - WeightedAverageSharesBasic - Weighted avg shares basic\\n\"\n",
    "                \"13. IncomeStatement - EarningsPerShare - WeightedAverageSharesDiluted - Weighted avg shares diluted\\n\\n\"\n",
    "                f'Return the mapping in this exact JSON format:\\n'\n",
    "                '{\\n'\n",
    "                f'  \"{pascal_sub_industry}\": {{\\n'\n",
    "                '    \"frame\": [\"exact_column_name\"],\\n'\n",
    "                '    \"total_assets\": [\"exact_column_name\"],\\n'\n",
    "                '    \"total_liabilities\": [\"exact_column_name\"],\\n'\n",
    "                '    \"total_equity\": [\"exact_column_name\"],\\n'\n",
    "                '    \"total_revenue\": [\"exact_column_name\"],\\n'\n",
    "                '    \"gross_profit\": [\"exact_column_name\"],\\n'\n",
    "                '    \"operating_income\": [\"exact_column_name\"],\\n'\n",
    "                '    \"net_income\": [\"exact_column_name\"],\\n'\n",
    "                '    \"comprehensive_income\": [\"exact_column_name\"],\\n'\n",
    "                '    \"basic_eps\": [\"exact_column_name\"],\\n'\n",
    "                '    \"diluted_eps\": [\"exact_column_name\"],\\n'\n",
    "                '    \"shares_basic\": [\"exact_column_name\"],\\n'\n",
    "                '    \"shares_diluted\": [\"exact_column_name\"]\\n'\n",
    "                '  }\\n'\n",
    "                '}\\n\\n'\n",
    "                \"Rules: Use exact column names from the list above. If a column doesn't exist, use empty array []. No comments or extra text.\"\n",
    "            )\n",
    "            \n",
    "            sp_analysis.at[idx, 'question_prompt'] = str(prompt)\n",
    "            \n",
    "            # Mark as successful\n",
    "            success = True\n",
    "            print(f'Successfully processed {symbol}')\n",
    "            print(f'Available target accounts: {len(available_targets)}/{len(target_accounts)}')\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f'File not found for {symbol}. Skipping...')\n",
    "            # Don't retry for file not found errors\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f'Error processing {symbol}: {e}')\n",
    "            \n",
    "            if retry_count < max_retries:\n",
    "                print(f'Waiting 60 seconds before retry...')\n",
    "                time.sleep(60)  # Wait 1 minute before retrying\n",
    "            else:\n",
    "                print(f'Max retries reached for {symbol}. Moving to next company.')\n",
    "                # Optionally store error information\n",
    "                sp_analysis.at[idx, 'error'] = str(e)\n",
    "\n",
    "# Create a summary of what accounts are commonly available\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY OF ACCOUNT AVAILABILITY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Analyze which target accounts are most commonly available\n",
    "account_availability = {}\n",
    "for key in target_accounts.keys():\n",
    "    account_availability[key] = 0\n",
    "\n",
    "for idx, row in sp_analysis.iterrows():\n",
    "    if row['available_target_accounts'] is not None:\n",
    "        for key in row['available_target_accounts'].keys():\n",
    "            account_availability[key] += 1\n",
    "\n",
    "total_companies = len(sp_analysis)\n",
    "print(f\"\\nTotal companies processed: {total_companies}\")\n",
    "print(\"\\nAccount availability across companies:\")\n",
    "for account, count in account_availability.items():\n",
    "    percentage = (count / total_companies) * 100\n",
    "    print(f\"  {account}: {count}/{total_companies} ({percentage:.1f}%)\")\n",
    "\n",
    "# Save results\n",
    "output_file = f'financial_mapping_analysis_{int(time.time())}.csv'\n",
    "sp_analysis.to_csv(output_file, index=False)\n",
    "print(f\"\\nResults saved to: {output_file}\")\n",
    "\n",
    "# Create a sample JSON structure for manual review\n",
    "sample_mapping = {}\n",
    "for idx, row in sp_analysis.iterrows():\n",
    "    if row['available_target_accounts'] is not None and len(row['available_target_accounts']) > 0:\n",
    "        symbol = row['Symbol']\n",
    "        sub_industry = row['GICS Sub-Industry']\n",
    "        pascal_sub_industry = ''.join(word.capitalize() for word in sub_industry.replace('-', ' ').replace('&', 'And').split())\n",
    "        \n",
    "        sample_mapping[symbol] = {\n",
    "            \"sub_industry\": sub_industry,\n",
    "            \"pascal_sub_industry\": pascal_sub_industry,\n",
    "            \"available_accounts\": row['available_target_accounts']\n",
    "        }\n",
    "\n",
    "# Save sample mapping for reference\n",
    "sample_file = f'sample_mapping_{int(time.time())}.json'\n",
    "with open(sample_file, 'w') as f:\n",
    "    json.dump(sample_mapping, f, indent=2)\n",
    "print(f\"Sample mapping saved to: {sample_file}\")\n",
    "\n",
    "print(f\"\\nProcessing complete! Review the prompts and use them with your AI to generate the final JSON mappings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc262d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import os\n",
    "\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "# Configure the API key\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Initialize the model with low temperature\n",
    "model = genai.GenerativeModel(\n",
    "    'gemini-2.5-flash-preview-05-20',\n",
    "    generation_config={\n",
    "        'temperature': 0.01, # Low temperature for more deterministic responses for reproducibility\n",
    "        'top_p': 0.95, # Top-p sampling for diversity\n",
    "        'response_mime_type': 'application/json'  # Force JSON output\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "285a6e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting financial mapping processing with Gemini...\n",
      "This may take several minutes depending on the number of companies...\n",
      "\n",
      "============================================================\n",
      "Processing 1/91: IPG - Advertising\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for IPG\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 2/91: AXON - Aerospace & Defense\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for AXON\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 3/91: DE - Agricultural & Farm Machinery\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for DE\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 4/91: ADM - Agricultural Products & Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for ADM\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 5/91: CHRW - Air Freight & Logistics\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CHRW\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 6/91: ROST - Apparel Retail\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for ROST\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 7/91: LULU - Apparel, Accessories & Luxury Goods\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for LULU\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 8/91: ADBE - Application Software\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for ADBE\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 9/91: F - Automobile Manufacturers\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for F\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 10/91: APTV - Automotive Parts & Equipment\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for APTV\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 11/91: AZO - Automotive Retail\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for AZO\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 12/91: ABBV - Biotechnology\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for ABBV\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 13/91: TAP - Brewers\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for TAP\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 14/91: FOXA - Broadcasting\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for FOXA\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 15/91: AMZN - Broadline Retail\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for AMZN\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 16/91: AOS - Building Products\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for AOS\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 17/91: CHTR - Cable & Satellite\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CHTR\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 18/91: JBHT - Cargo Ground Transportation\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for JBHT\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 19/91: CZR - Casinos & Gaming\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CZR\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 20/91: DOW - Commodity Chemicals\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for DOW\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 21/91: ANET - Communications Equipment\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for ANET\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 22/91: BBY - Computer & Electronics Retail\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for BBY\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 23/91: J - Construction & Engineering\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for J\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 24/91: CAT - Construction Machinery & Heavy Transportation Equipment\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CAT\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 25/91: MLM - Construction Materials\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for MLM\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 26/91: GRMN - Consumer Electronics\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for GRMN\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 27/91: COST - Consumer Staples Merchandise Retail\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for COST\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 28/91: FCX - Copper\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for FCX\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 29/91: BR - Data Processing & Outsourced Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for BR\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 30/91: BF.B - Distillers & Vintners\n",
      "âœ— Error processing BF.B: contents must not be empty\n",
      "\n",
      "============================================================\n",
      "Processing 31/91: GPC - Distributors\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for GPC\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 32/91: CTAS - Diversified Support Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CTAS\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 33/91: WBA - Drug Retail\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for WBA\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 34/91: AME - Electrical Components & Equipment\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for AME\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 35/91: APH - Electronic Components\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for APH\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 36/91: KEYS - Electronic Equipment & Instruments\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for KEYS\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 37/91: JBL - Electronic Manufacturing Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for JBL\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 38/91: RSG - Environmental & Facilities Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for RSG\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 39/91: CF - Fertilizers & Agricultural Chemicals\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CF\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 40/91: SYY - Food Distributors\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for SYY\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 41/91: KR - Food Retail\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for KR\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 42/91: DECK - Footwear\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for DECK\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 43/91: NEM - Gold\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for NEM\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 44/91: CAH - Health Care Distributors\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CAH\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 45/91: ABT - Health Care Equipment\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for ABT\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 46/91: HCA - Health Care Facilities\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for HCA\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 47/91: CI - Health Care Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CI\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 48/91: ALGN - Health Care Supplies\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for ALGN\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 49/91: SOLV - Health Care Technology\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for SOLV\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 50/91: GEV - Heavy Electrical Equipment\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for GEV\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 51/91: MHK - Home Furnishings\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for MHK\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 52/91: HD - Home Improvement Retail\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for HD\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 53/91: DHI - Homebuilding\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for DHI\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 54/91: ABNB - Hotels, Resorts & Cruise Lines\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for ABNB\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 55/91: CHD - Household Products\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CHD\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 56/91: ADP - Human Resource & Employment Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for ADP\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 57/91: ACN - IT Consulting & Other Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for ACN\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 58/91: MMM - Industrial Conglomerates\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for MMM\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 59/91: APD - Industrial Gases\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for APD\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 60/91: DOV - Industrial Machinery & Supplies & Components\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for DOV\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 61/91: T - Integrated Telecommunication Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for T\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 62/91: EA - Interactive Home Entertainment\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for EA\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 63/91: GOOGL - Interactive Media & Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for GOOGL\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 64/91: AKAM - Internet Services & Infrastructure\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for AKAM\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 65/91: HAS - Leisure Products\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for HAS\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 66/91: A - Life Sciences Tools & Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for A\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 67/91: CNC - Managed Health Care\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CNC\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 68/91: BALL - Metal, Glass & Plastic Containers\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for BALL\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 69/91: LYV - Movies & Entertainment\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for LYV\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 70/91: TSCO - Other Specialty Retail\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for TSCO\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 71/91: CPB - Packaged Foods & Meats\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CPB\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 72/91: AMCR - Paper & Plastic Packaging Products & Materials\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for AMCR\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 73/91: DAL - Passenger Airlines\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for DAL\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 74/91: UBER - Passenger Ground Transportation\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for UBER\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 75/91: EL - Personal Care Products\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for EL\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 76/91: BMY - Pharmaceuticals\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for BMY\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 77/91: NWSA - Publishing\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for NWSA\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 78/91: CSX - Rail Transportation\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CSX\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 79/91: EFX - Research & Consulting Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for EFX\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 80/91: CMG - Restaurants\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CMG\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 81/91: AMAT - Semiconductor Materials & Equipment\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for AMAT\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 82/91: AMD - Semiconductors\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for AMD\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 83/91: KO - Soft Drinks & Non-alcoholic Beverages\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for KO\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 84/91: ALB - Specialty Chemicals\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for ALB\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 85/91: NUE - Steel\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for NUE\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 86/91: CRWD - Systems Software\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CRWD\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 87/91: CDW - Technology Distributors\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for CDW\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 88/91: AAPL - Technology Hardware, Storage & Peripherals\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for AAPL\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 89/91: MO - Tobacco\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for MO\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 90/91: FAST - Trading Companies & Distributors\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for FAST\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing 91/91: TMUS - Wireless Telecommunication Services\n",
      "Response received from Gemini\n",
      "âœ“ Successfully parsed JSON mapping for TMUS\n",
      "============================================================\n",
      "\n",
      "\n",
      "âœ“ Financial mappings JSON file created: financial_account_mappings.json\n",
      "âœ“ Summary file created: financial_account_mappings_summary.json\n",
      "\n",
      "============================================================\n",
      "PROCESSING COMPLETE - VALIDATION REPORT\n",
      "============================================================\n",
      "Total industries processed: 90\n",
      "Complete mappings (80%+ coverage): 83\n",
      "Partial mappings (30-79% coverage): 4\n",
      "Failed mappings (<30% coverage): 4\n",
      "\n",
      "âœ“ Processed dataframe saved to: financial_mapping_results.csv\n",
      "âœ“ Validation report saved to: mapping_validation_report.json\n",
      "\n",
      "============================================================\n",
      "FILES CREATED:\n",
      "1. financial_account_mappings.json - Main mapping file\n",
      "2. financial_account_mappings_summary.json - Processing summary\n",
      "3. financial_mapping_results.csv - Dataframe with responses\n",
      "4. mapping_validation_report.json - Validation analysis\n",
      "============================================================\n",
      "\n",
      "Processing complete! Review the JSON files for your financial account mappings.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def parse_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    Extract JSON content from Gemini's response, handling markdown code blocks\n",
    "    \"\"\"\n",
    "    # Try to find JSON content within ```json ... ``` blocks\n",
    "    json_pattern = r'```json\\s*(.*?)\\s*```'\n",
    "    matches = re.findall(json_pattern, response_text, re.DOTALL)\n",
    "    \n",
    "    if matches:\n",
    "        # Take the first match\n",
    "        json_str = matches[0].strip()\n",
    "    else:\n",
    "        # If no markdown blocks, try to find JSON content within { }\n",
    "        brace_pattern = r'\\{.*\\}'\n",
    "        brace_matches = re.findall(brace_pattern, response_text, re.DOTALL)\n",
    "        if brace_matches:\n",
    "            json_str = brace_matches[0].strip()\n",
    "        else:\n",
    "            # Assume the entire response is JSON\n",
    "            json_str = response_text.strip()\n",
    "    \n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        print(f\"JSON string attempted: {json_str[:300]}...\")  # Show first 300 chars\n",
    "        return None\n",
    "\n",
    "def process_financial_mapping_with_gemini(df, output_file='financial_mappings.json'):\n",
    "    \"\"\"\n",
    "    Process each row's financial mapping prompt and save Gemini's response as proper JSON\n",
    "    \"\"\"\n",
    "    # Dictionary to store all financial mappings\n",
    "    all_mappings = {}\n",
    "    response_texts = []  # For dataframe column\n",
    "    parsed_mappings = []  # For dataframe column\n",
    "    \n",
    "    total_rows = len(df)\n",
    "    \n",
    "    # Process each row\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            symbol = row['Symbol']\n",
    "            prompt = row['question_prompt']\n",
    "            sub_industry = row['GICS Sub-Industry']\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Processing {index + 1}/{total_rows}: {symbol} - {sub_industry}\")\n",
    "            \n",
    "            # Send prompt to Gemini\n",
    "            response = model.generate_content(prompt)\n",
    "            response_text = response.text\n",
    "            \n",
    "            print('Response received from Gemini')\n",
    "            \n",
    "            # Parse JSON from response\n",
    "            parsed_json = parse_json_from_response(response_text)\n",
    "            \n",
    "            if parsed_json:\n",
    "                # If the parsed JSON has a single key (industry name),\n",
    "                # merge it into our main dictionary\n",
    "                if isinstance(parsed_json, dict) and len(parsed_json) == 1:\n",
    "                    all_mappings.update(parsed_json)\n",
    "                    # Get the key name for storage\n",
    "                    industry_key = list(parsed_json.keys())[0]\n",
    "                    parsed_mappings.append(parsed_json[industry_key])\n",
    "                else:\n",
    "                    # Otherwise, use the symbol as the key\n",
    "                    all_mappings[symbol] = parsed_json\n",
    "                    parsed_mappings.append(parsed_json)\n",
    "                \n",
    "                print(f\"âœ“ Successfully parsed JSON mapping for {symbol}\")\n",
    "                response_texts.append(json.dumps(parsed_json, indent=2))\n",
    "            else:\n",
    "                print(f\"âœ— Failed to parse JSON for {symbol}\")\n",
    "                error_info = {\n",
    "                    \"error\": \"Failed to parse JSON\", \n",
    "                    \"raw_response\": response_text[:500],\n",
    "                    \"symbol\": symbol,\n",
    "                    \"sub_industry\": sub_industry\n",
    "                }\n",
    "                all_mappings[f\"{symbol}_ERROR\"] = error_info\n",
    "                response_texts.append(response_text)\n",
    "                parsed_mappings.append(error_info)\n",
    "            \n",
    "            print(f\"{'='*60}\\n\")\n",
    "            \n",
    "            # Rate limiting - wait between requests\n",
    "            time.sleep(2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error: {str(e)}\"\n",
    "            print(f\"âœ— Error processing {symbol}: {str(e)}\")\n",
    "            \n",
    "            # Store error in the mappings\n",
    "            error_info = {\n",
    "                \"error\": str(e),\n",
    "                \"symbol\": symbol,\n",
    "                \"sub_industry\": sub_industry,\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            all_mappings[f\"{symbol}_ERROR\"] = error_info\n",
    "            response_texts.append(error_msg)\n",
    "            parsed_mappings.append(error_info)\n",
    "            \n",
    "            # Longer wait on error\n",
    "            time.sleep(10)\n",
    "    \n",
    "    # Write the combined JSON to file\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_mappings, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nâœ“ Financial mappings JSON file created: {output_file}\")\n",
    "        \n",
    "        # Also create a summary file\n",
    "        summary_file = output_file.replace('.json', '_summary.json')\n",
    "        summary = {\n",
    "            \"total_companies\": total_rows,\n",
    "            \"successful_mappings\": len([k for k in all_mappings.keys() if not k.endswith('_ERROR')]),\n",
    "            \"failed_mappings\": len([k for k in all_mappings.keys() if k.endswith('_ERROR')]),\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"industries_processed\": list(set(df['GICS Sub-Industry'].tolist()))\n",
    "        }\n",
    "        \n",
    "        with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"âœ“ Summary file created: {summary_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— Error writing JSON file: {e}\")\n",
    "        # Fallback: write as pretty-printed string\n",
    "        fallback_file = output_file.replace('.json', '_fallback.txt')\n",
    "        with open(fallback_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(json.dumps(all_mappings, indent=2, ensure_ascii=False))\n",
    "        print(f\"âœ“ Fallback file created: {fallback_file}\")\n",
    "    \n",
    "    # Add responses to dataframe\n",
    "    df_copy = df.copy()\n",
    "    df_copy['gemini_response'] = response_texts\n",
    "    df_copy['parsed_mapping'] = parsed_mappings\n",
    "    \n",
    "    return df_copy, all_mappings\n",
    "\n",
    "def validate_financial_mappings(mappings_dict):\n",
    "    \"\"\"\n",
    "    Validate the financial mappings and provide a report\n",
    "    \"\"\"\n",
    "    validation_report = {\n",
    "        \"total_industries\": 0,\n",
    "        \"complete_mappings\": 0,\n",
    "        \"partial_mappings\": 0,\n",
    "        \"failed_mappings\": 0,\n",
    "        \"account_coverage\": {},\n",
    "        \"missing_accounts\": {}\n",
    "    }\n",
    "    \n",
    "    # Target accounts we're looking for\n",
    "    target_accounts = [\n",
    "        'frame', 'total_assets', 'total_liabilities', 'total_equity',\n",
    "        'total_revenue', 'gross_profit', 'operating_income', 'net_income',\n",
    "        'comprehensive_income', 'basic_eps', 'diluted_eps', 'shares_basic', 'shares_diluted'\n",
    "    ]\n",
    "    \n",
    "    for industry_key, mapping in mappings_dict.items():\n",
    "        if industry_key.endswith('_ERROR'):\n",
    "            validation_report[\"failed_mappings\"] += 1\n",
    "            continue\n",
    "            \n",
    "        validation_report[\"total_industries\"] += 1\n",
    "        \n",
    "        if isinstance(mapping, dict) and 'error' not in mapping:\n",
    "            # Count how many target accounts are mapped\n",
    "            mapped_accounts = []\n",
    "            missing_accounts = []\n",
    "            \n",
    "            for account in target_accounts:\n",
    "                if account in mapping and mapping[account] and len(mapping[account]) > 0:\n",
    "                    mapped_accounts.append(account)\n",
    "                else:\n",
    "                    missing_accounts.append(account)\n",
    "            \n",
    "            # Classify mapping completeness\n",
    "            coverage_ratio = len(mapped_accounts) / len(target_accounts)\n",
    "            if coverage_ratio >= 0.8:  # 80% or more\n",
    "                validation_report[\"complete_mappings\"] += 1\n",
    "            elif coverage_ratio >= 0.3:  # 30% or more\n",
    "                validation_report[\"partial_mappings\"] += 1\n",
    "            else:\n",
    "                validation_report[\"failed_mappings\"] += 1\n",
    "            \n",
    "            validation_report[\"account_coverage\"][industry_key] = {\n",
    "                \"mapped\": mapped_accounts,\n",
    "                \"missing\": missing_accounts,\n",
    "                \"coverage_ratio\": coverage_ratio\n",
    "            }\n",
    "    \n",
    "    return validation_report\n",
    "\n",
    "# Process the financial mapping data\n",
    "print(\"Starting financial mapping processing with Gemini...\")\n",
    "print(\"This may take several minutes depending on the number of companies...\")\n",
    "\n",
    "# Process the dataframe\n",
    "df_processed, financial_mappings = process_financial_mapping_with_gemini(\n",
    "    sp_analysis, \n",
    "    'financial_account_mappings.json'\n",
    ")\n",
    "\n",
    "# Validate the mappings\n",
    "validation_report = validate_financial_mappings(financial_mappings)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PROCESSING COMPLETE - VALIDATION REPORT\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total industries processed: {validation_report['total_industries']}\")\n",
    "print(f\"Complete mappings (80%+ coverage): {validation_report['complete_mappings']}\")\n",
    "print(f\"Partial mappings (30-79% coverage): {validation_report['partial_mappings']}\")\n",
    "print(f\"Failed mappings (<30% coverage): {validation_report['failed_mappings']}\")\n",
    "\n",
    "# Save the processed dataframe\n",
    "df_processed.to_csv('financial_mapping_results.csv', index=False)\n",
    "print(f\"\\nâœ“ Processed dataframe saved to: financial_mapping_results.csv\")\n",
    "\n",
    "# Save validation report\n",
    "with open('mapping_validation_report.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(validation_report, f, indent=2, ensure_ascii=False)\n",
    "print(f\"âœ“ Validation report saved to: mapping_validation_report.json\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FILES CREATED:\")\n",
    "print(\"1. financial_account_mappings.json - Main mapping file\")\n",
    "print(\"2. financial_account_mappings_summary.json - Processing summary\")\n",
    "print(\"3. financial_mapping_results.csv - Dataframe with responses\")\n",
    "print(\"4. mapping_validation_report.json - Validation analysis\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(\"\\nProcessing complete! Review the JSON files for your financial account mappings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f45cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "def process_dataframe_with_gemini(df, file_name, prompt_column='question_prompt', max_retries=3):\n",
    "    responses = []\n",
    "    gemini_responses = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        print(f\"Processing row {index + 1}/{len(df)}: {row['section']}\")\n",
    "        \n",
    "        retry_count = 0\n",
    "        success = False\n",
    "        \n",
    "        while retry_count < max_retries and not success:\n",
    "            try:\n",
    "                prompt = row[prompt_column]\n",
    "                \n",
    "                if row['content'] == '':\n",
    "                    response_text = \"\"\n",
    "                else:\n",
    "                    response = model.generate_content(prompt)\n",
    "                    response_text = response.text\n",
    "                \n",
    "                responses.append(response_text)\n",
    "                gemini_responses.append(response_text)\n",
    "                success = True\n",
    "                time.sleep(0.01)\n",
    "                \n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                print(f\"Error on attempt {retry_count}: {str(e)}\")\n",
    "                \n",
    "                if retry_count < max_retries:\n",
    "                    wait_time = 65 if \"rate limit\" in str(e).lower() else 5\n",
    "                    print(f\"Waiting {wait_time} seconds before retry...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    error_text = f\"Error after {retry_count} attempts: {str(e)}\"\n",
    "                    responses.append(error_text)\n",
    "                    gemini_responses.append(error_text)\n",
    "    \n",
    "    df['gemini_response'] = responses\n",
    "    \n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        json.dump(gemini_responses, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f6c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "                \"Analyze the financial statement columns and create a JSON mapping for these specific accounts. \"\n",
    "                \"Return ONLY the JSON mapping with no additional text or explanations.\\n\\n\"\n",
    "                f\"Industry: {sub_industry}\\n\"\n",
    "                f\"Available columns: {accounts_str}\\n\\n\"\n",
    "                \"Find exact matches or closest equivalents for these target accounts:\\n\"\n",
    "                \"1. frame - Time period identifier\\n\"\n",
    "                \"2. Assets - TotalAssets - Total assets from balance sheet\\n\"\n",
    "                \"3. Liabilities - TotalLiabilities - Total liabilities from balance sheet\\n\"\n",
    "                \"4. Equity - TotalStockholdersEquity - Total stockholders equity\\n\"\n",
    "                \"5. IncomeStatement - Revenues - TotalRevenue - Total revenue/sales\\n\"\n",
    "                \"6. IncomeStatement - OtherIncomeExpense - GrossProfit - Gross profit\\n\"\n",
    "                \"7. IncomeStatement - OtherIncomeExpense - OperatingIncome - Operating income\\n\"\n",
    "                \"8. IncomeStatement - NetIncome - NetIncome - Net income\\n\"\n",
    "                \"9. IncomeStatement - NetIncome - ComprehensiveIncome - Comprehensive income\\n\"\n",
    "                \"10. IncomeStatement - EarningsPerShare - BasicEps - Basic earnings per share\\n\"\n",
    "                \"11. IncomeStatement - EarningsPerShare - DilutedEps - Diluted earnings per share\\n\"\n",
    "                \"12. IncomeStatement - EarningsPerShare - WeightedAverageSharesBasic - Weighted avg shares basic\\n\"\n",
    "                \"13. IncomeStatement - EarningsPerShare - WeightedAverageSharesDiluted - Weighted avg shares diluted\\n\\n\"\n",
    "                f'Return the mapping in this exact JSON format:\\n'\n",
    "                '{\\n'\n",
    "                f'  \"{pascal_sub_industry}\": {{\\n'\n",
    "                '    \"frame\": [\"exact_column_name\"],\\n'\n",
    "                '    \"total_assets\": [\"exact_column_name\"],\\n'\n",
    "                '    \"total_liabilities\": [\"exact_column_name\"],\\n'\n",
    "                '    \"total_equity\": [\"exact_column_name\"],\\n'\n",
    "                '    \"total_revenue\": [\"exact_column_name\"],\\n'\n",
    "                '    \"gross_profit\": [\"exact_column_name\"],\\n'\n",
    "                '    \"operating_income\": [\"exact_column_name\"],\\n'\n",
    "                '    \"net_income\": [\"exact_column_name\"],\\n'\n",
    "                '    \"comprehensive_income\": [\"exact_column_name\"],\\n'\n",
    "                '    \"basic_eps\": [\"exact_column_name\"],\\n'\n",
    "                '    \"diluted_eps\": [\"exact_column_name\"],\\n'\n",
    "                '    \"shares_basic\": [\"exact_column_name\"],\\n'\n",
    "                '    \"shares_diluted\": [\"exact_column_name\"]\\n'\n",
    "                '  }\\n'\n",
    "                '}\\n\\n'\n",
    "                \"Rules: Use exact column names from the list above. If a column doesn't exist, use empty array []. No comments or extra text.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53011c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CIK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>9.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>152.076923</td>\n",
       "      <td>8.067989e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>130.805473</td>\n",
       "      <td>6.055792e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.800000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43.500000</td>\n",
       "      <td>7.002450e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>107.000000</td>\n",
       "      <td>8.667870e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>229.000000</td>\n",
       "      <td>1.304052e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>481.000000</td>\n",
       "      <td>1.996810e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           CIK\n",
       "count   91.000000  9.100000e+01\n",
       "mean   152.076923  8.067989e+05\n",
       "std    130.805473  6.055792e+05\n",
       "min      0.000000  1.800000e+03\n",
       "25%     43.500000  7.002450e+04\n",
       "50%    107.000000  8.667870e+05\n",
       "75%    229.000000  1.304052e+06\n",
       "max    481.000000  1.996810e+06"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_analysis.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38b20cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing Advertising\n",
      "Response received\n",
      "Successfully parsed JSON for Advertising\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Aerospace & Defense\n",
      "Response received\n",
      "Successfully parsed JSON for Aerospace & Defense\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Agricultural & Farm Machinery\n",
      "Response received\n",
      "Successfully parsed JSON for Agricultural & Farm Machinery\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Agricultural Products & Services\n",
      "Response received\n",
      "Successfully parsed JSON for Agricultural Products & Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Air Freight & Logistics\n",
      "Response received\n",
      "Successfully parsed JSON for Air Freight & Logistics\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Apparel Retail\n",
      "Response received\n",
      "Successfully parsed JSON for Apparel Retail\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Apparel, Accessories & Luxury Goods\n",
      "Response received\n",
      "Successfully parsed JSON for Apparel, Accessories & Luxury Goods\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Application Software\n",
      "Response received\n",
      "Successfully parsed JSON for Application Software\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Automobile Manufacturers\n",
      "Response received\n",
      "Successfully parsed JSON for Automobile Manufacturers\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Automotive Parts & Equipment\n",
      "Response received\n",
      "Successfully parsed JSON for Automotive Parts & Equipment\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Automotive Retail\n",
      "Response received\n",
      "Successfully parsed JSON for Automotive Retail\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Biotechnology\n",
      "Response received\n",
      "Successfully parsed JSON for Biotechnology\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Brewers\n",
      "Response received\n",
      "Successfully parsed JSON for Brewers\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Broadcasting\n",
      "Response received\n",
      "Successfully parsed JSON for Broadcasting\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Broadline Retail\n",
      "Response received\n",
      "Successfully parsed JSON for Broadline Retail\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Building Products\n",
      "Response received\n",
      "Successfully parsed JSON for Building Products\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Cable & Satellite\n",
      "Response received\n",
      "Successfully parsed JSON for Cable & Satellite\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Cargo Ground Transportation\n",
      "Response received\n",
      "Successfully parsed JSON for Cargo Ground Transportation\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Casinos & Gaming\n",
      "Response received\n",
      "Successfully parsed JSON for Casinos & Gaming\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Commodity Chemicals\n",
      "Response received\n",
      "Successfully parsed JSON for Commodity Chemicals\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Communications Equipment\n",
      "Response received\n",
      "Successfully parsed JSON for Communications Equipment\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Computer & Electronics Retail\n",
      "Response received\n",
      "Successfully parsed JSON for Computer & Electronics Retail\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Construction & Engineering\n",
      "Response received\n",
      "Successfully parsed JSON for Construction & Engineering\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Construction Machinery & Heavy Transportation Equipment\n",
      "Response received\n",
      "Successfully parsed JSON for Construction Machinery & Heavy Transportation Equipment\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Construction Materials\n",
      "Response received\n",
      "Successfully parsed JSON for Construction Materials\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Consumer Electronics\n",
      "Response received\n",
      "Successfully parsed JSON for Consumer Electronics\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Consumer Staples Merchandise Retail\n",
      "Response received\n",
      "Successfully parsed JSON for Consumer Staples Merchandise Retail\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Copper\n",
      "Response received\n",
      "Successfully parsed JSON for Copper\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Data Processing & Outsourced Services\n",
      "Response received\n",
      "Successfully parsed JSON for Data Processing & Outsourced Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Distillers & Vintners\n",
      "Error processing row Distillers & Vintners: contents must not be empty\n",
      "\n",
      "==================================================\n",
      "Processing Distributors\n",
      "Response received\n",
      "Successfully parsed JSON for Distributors\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Diversified Support Services\n",
      "Response received\n",
      "Successfully parsed JSON for Diversified Support Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Drug Retail\n",
      "Response received\n",
      "Successfully parsed JSON for Drug Retail\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Electrical Components & Equipment\n",
      "Response received\n",
      "Successfully parsed JSON for Electrical Components & Equipment\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Electronic Components\n",
      "Response received\n",
      "Successfully parsed JSON for Electronic Components\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Electronic Equipment & Instruments\n",
      "Response received\n",
      "Successfully parsed JSON for Electronic Equipment & Instruments\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Electronic Manufacturing Services\n",
      "Response received\n",
      "Successfully parsed JSON for Electronic Manufacturing Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Environmental & Facilities Services\n",
      "Response received\n",
      "Successfully parsed JSON for Environmental & Facilities Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Fertilizers & Agricultural Chemicals\n",
      "Response received\n",
      "Successfully parsed JSON for Fertilizers & Agricultural Chemicals\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Food Distributors\n",
      "Response received\n",
      "Successfully parsed JSON for Food Distributors\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Food Retail\n",
      "Response received\n",
      "Successfully parsed JSON for Food Retail\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Footwear\n",
      "Response received\n",
      "Successfully parsed JSON for Footwear\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Gold\n",
      "Response received\n",
      "Successfully parsed JSON for Gold\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Health Care Distributors\n",
      "Response received\n",
      "Successfully parsed JSON for Health Care Distributors\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Health Care Equipment\n",
      "Response received\n",
      "Successfully parsed JSON for Health Care Equipment\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Health Care Facilities\n",
      "Response received\n",
      "Successfully parsed JSON for Health Care Facilities\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Health Care Services\n",
      "Response received\n",
      "Successfully parsed JSON for Health Care Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Health Care Supplies\n",
      "Response received\n",
      "Successfully parsed JSON for Health Care Supplies\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Health Care Technology\n",
      "Response received\n",
      "Successfully parsed JSON for Health Care Technology\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Heavy Electrical Equipment\n",
      "Response received\n",
      "Successfully parsed JSON for Heavy Electrical Equipment\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Home Furnishings\n",
      "Response received\n",
      "Successfully parsed JSON for Home Furnishings\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Home Improvement Retail\n",
      "Response received\n",
      "Successfully parsed JSON for Home Improvement Retail\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Homebuilding\n",
      "Response received\n",
      "Successfully parsed JSON for Homebuilding\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Hotels, Resorts & Cruise Lines\n",
      "Response received\n",
      "Successfully parsed JSON for Hotels, Resorts & Cruise Lines\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Household Products\n",
      "Response received\n",
      "Successfully parsed JSON for Household Products\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Human Resource & Employment Services\n",
      "Response received\n",
      "Successfully parsed JSON for Human Resource & Employment Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing IT Consulting & Other Services\n",
      "Response received\n",
      "Successfully parsed JSON for IT Consulting & Other Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Industrial Conglomerates\n",
      "Response received\n",
      "Successfully parsed JSON for Industrial Conglomerates\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Industrial Gases\n",
      "Response received\n",
      "Successfully parsed JSON for Industrial Gases\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Industrial Machinery & Supplies & Components\n",
      "Response received\n",
      "Successfully parsed JSON for Industrial Machinery & Supplies & Components\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Integrated Telecommunication Services\n",
      "Response received\n",
      "Successfully parsed JSON for Integrated Telecommunication Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Interactive Home Entertainment\n",
      "Response received\n",
      "Successfully parsed JSON for Interactive Home Entertainment\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Interactive Media & Services\n",
      "Response received\n",
      "Successfully parsed JSON for Interactive Media & Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Internet Services & Infrastructure\n",
      "Response received\n",
      "Successfully parsed JSON for Internet Services & Infrastructure\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Leisure Products\n",
      "Response received\n",
      "Successfully parsed JSON for Leisure Products\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Life Sciences Tools & Services\n",
      "Response received\n",
      "Successfully parsed JSON for Life Sciences Tools & Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Managed Health Care\n",
      "Response received\n",
      "Successfully parsed JSON for Managed Health Care\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Metal, Glass & Plastic Containers\n",
      "Response received\n",
      "Successfully parsed JSON for Metal, Glass & Plastic Containers\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Movies & Entertainment\n",
      "Response received\n",
      "Successfully parsed JSON for Movies & Entertainment\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Other Specialty Retail\n",
      "Response received\n",
      "Successfully parsed JSON for Other Specialty Retail\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Packaged Foods & Meats\n",
      "Response received\n",
      "Successfully parsed JSON for Packaged Foods & Meats\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Paper & Plastic Packaging Products & Materials\n",
      "Response received\n",
      "Successfully parsed JSON for Paper & Plastic Packaging Products & Materials\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Passenger Airlines\n",
      "Response received\n",
      "Successfully parsed JSON for Passenger Airlines\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Passenger Ground Transportation\n",
      "Response received\n",
      "Successfully parsed JSON for Passenger Ground Transportation\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Personal Care Products\n",
      "Response received\n",
      "Successfully parsed JSON for Personal Care Products\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Pharmaceuticals\n",
      "Response received\n",
      "Successfully parsed JSON for Pharmaceuticals\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Publishing\n",
      "Response received\n",
      "Successfully parsed JSON for Publishing\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Rail Transportation\n",
      "Response received\n",
      "Successfully parsed JSON for Rail Transportation\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Research & Consulting Services\n",
      "Response received\n",
      "Successfully parsed JSON for Research & Consulting Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Restaurants\n",
      "Response received\n",
      "Successfully parsed JSON for Restaurants\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Semiconductor Materials & Equipment\n",
      "Response received\n",
      "Successfully parsed JSON for Semiconductor Materials & Equipment\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Semiconductors\n",
      "Response received\n",
      "Successfully parsed JSON for Semiconductors\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Soft Drinks & Non-alcoholic Beverages\n",
      "Response received\n",
      "Successfully parsed JSON for Soft Drinks & Non-alcoholic Beverages\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Specialty Chemicals\n",
      "Response received\n",
      "Successfully parsed JSON for Specialty Chemicals\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Steel\n",
      "Response received\n",
      "Successfully parsed JSON for Steel\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Systems Software\n",
      "Response received\n",
      "Successfully parsed JSON for Systems Software\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Technology Distributors\n",
      "Response received\n",
      "Successfully parsed JSON for Technology Distributors\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Technology Hardware, Storage & Peripherals\n",
      "Response received\n",
      "Successfully parsed JSON for Technology Hardware, Storage & Peripherals\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Tobacco\n",
      "Response received\n",
      "Successfully parsed JSON for Tobacco\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Trading Companies & Distributors\n",
      "Response received\n",
      "Successfully parsed JSON for Trading Companies & Distributors\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing Wireless Telecommunication Services\n",
      "Response received\n",
      "Successfully parsed JSON for Wireless Telecommunication Services\n",
      "==================================================\n",
      "\n",
      "\n",
      "âœ“ Valid JSON file created: dcf.json\n",
      "Processing complete. Check 'dcf.json' for properly formatted JSON.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20')\n",
    "\n",
    "def parse_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    Extract JSON content from Gemini's response, handling markdown code blocks\n",
    "    \"\"\"\n",
    "    # Try to find JSON content within ```json ... ``` blocks\n",
    "    json_pattern = r'```json\\s*(.*?)\\s*```'\n",
    "    matches = re.findall(json_pattern, response_text, re.DOTALL)\n",
    "    \n",
    "    if matches:\n",
    "        # Take the first match\n",
    "        json_str = matches[0].strip()\n",
    "    else:\n",
    "        # If no markdown blocks, assume the entire response is JSON\n",
    "        json_str = response_text.strip()\n",
    "    \n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        print(f\"JSON string attempted: {json_str[:200]}...\")  # Show first 200 chars\n",
    "        return None\n",
    "\n",
    "def process_dataframe_with_gemini(df, output_file='gemini_responses.json'):\n",
    "    \"\"\"\n",
    "    Process each row's prompt and save Gemini's response as proper JSON\n",
    "    \"\"\"\n",
    "    # Dictionary to store all responses\n",
    "    all_responses = {}\n",
    "    response_texts = []  # For dataframe column\n",
    "    \n",
    "    # Process each row\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            prompt = row['question_prompt']\n",
    "            sub_industry = row['GICS Sub-Industry']\n",
    "            \n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Processing {sub_industry}\")\n",
    "            \n",
    "            # Send prompt to Gemini\n",
    "            response = model.generate_content(prompt)\n",
    "            response_text = response.text\n",
    "            \n",
    "            print('Response received')\n",
    "            \n",
    "            # Parse JSON from response\n",
    "            parsed_json = parse_json_from_response(response_text)\n",
    "            \n",
    "            if parsed_json:\n",
    "                # If the parsed JSON has a single key (like the examples show),\n",
    "                # merge it into our main dictionary\n",
    "                if isinstance(parsed_json, dict) and len(parsed_json) == 1:\n",
    "                    all_responses.update(parsed_json)\n",
    "                else:\n",
    "                    # Otherwise, use the sub-industry as the key\n",
    "                    all_responses[sub_industry] = parsed_json\n",
    "                \n",
    "                print(f\"Successfully parsed JSON for {sub_industry}\")\n",
    "                response_texts.append(json.dumps(parsed_json))\n",
    "            else:\n",
    "                print(f\"Failed to parse JSON for {sub_industry}\")\n",
    "                all_responses[sub_industry] = {\"error\": \"Failed to parse JSON\", \"raw_response\": response_text[:500]}\n",
    "                response_texts.append(response_text)\n",
    "            \n",
    "            print(f\"{'='*50}\\n\")\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error: {str(e)}\"\n",
    "            print(f\"Error processing row {row['GICS Sub-Industry']}: {str(e)}\")\n",
    "            \n",
    "            # Store error in the responses\n",
    "            all_responses[row['GICS Sub-Industry']] = {\"error\": str(e)}\n",
    "            response_texts.append(error_msg)\n",
    "            \n",
    "            time.sleep(60)  # Longer wait on error\n",
    "    \n",
    "    # Write the combined JSON to file\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_responses, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nâœ“ Valid JSON file created: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— Error writing JSON file: {e}\")\n",
    "        # Fallback: write as pretty-printed string\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(json.dumps(all_responses, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # Add responses to dataframe\n",
    "    df['gemini_response'] = response_texts\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Alternative function if you want to create a JSON array instead\n",
    "def process_dataframe_with_gemini_array(df, output_file='gemini_responses.json'):\n",
    "    \"\"\"\n",
    "    Process each row's prompt and save as a JSON array\n",
    "    \"\"\"\n",
    "    responses_array = []\n",
    "    response_texts = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            prompt = row['question_prompt']\n",
    "            sub_industry = row['GICS Sub-Industry']\n",
    "            \n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Processing {sub_industry}\")\n",
    "            \n",
    "            # Send prompt to Gemini\n",
    "            response = model.generate_content(prompt)\n",
    "            response_text = response.text\n",
    "            \n",
    "            print('Response received')\n",
    "            \n",
    "            # Parse JSON from response\n",
    "            parsed_json = parse_json_from_response(response_text)\n",
    "            \n",
    "            if parsed_json:\n",
    "                # Add metadata\n",
    "                response_obj = {\n",
    "                    \"sub_industry\": sub_industry,\n",
    "                    \"data\": parsed_json,\n",
    "                    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "                responses_array.append(response_obj)\n",
    "                response_texts.append(json.dumps(parsed_json))\n",
    "                print(f\"Successfully parsed JSON for {sub_industry}\")\n",
    "            else:\n",
    "                # Store error\n",
    "                response_obj = {\n",
    "                    \"sub_industry\": sub_industry,\n",
    "                    \"error\": \"Failed to parse JSON\",\n",
    "                    \"raw_response\": response_text[:500],\n",
    "                    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                }\n",
    "                responses_array.append(response_obj)\n",
    "                response_texts.append(response_text)\n",
    "                print(f\"Failed to parse JSON for {sub_industry}\")\n",
    "            \n",
    "            print(f\"{'='*50}\\n\")\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {sub_industry}: {str(e)}\")\n",
    "            \n",
    "            response_obj = {\n",
    "                \"sub_industry\": sub_industry,\n",
    "                \"error\": str(e),\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            responses_array.append(response_obj)\n",
    "            response_texts.append(f\"Error: {str(e)}\")\n",
    "            \n",
    "            time.sleep(60)\n",
    "    \n",
    "    # Write JSON array to file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(responses_array, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nâœ“ Valid JSON array file created: {output_file}\")\n",
    "    \n",
    "    # Add responses to dataframe\n",
    "    df['gemini_response'] = response_texts\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Using the merged dictionary approach (all industries in one object)\n",
    "df_processed = process_dataframe_with_gemini(sp_analysis, 'dcf.json')\n",
    "\n",
    "# Or using the array approach (each industry as separate object in array)\n",
    "# df_processed = process_dataframe_with_gemini_array(sp_analysis, 'dcf_array.json')\n",
    "\n",
    "df_processed.to_csv('sp_analysis_with_responses.csv', index=False)\n",
    "print(\"Processing complete. Check 'dcf.json' for properly formatted JSON.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76a09f",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import os\n",
    "\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20')\n",
    "\n",
    "def process_dataframe_with_gemini(df, output_file='gemini_responses.json'):\n",
    "    \"\"\"\n",
    "    Process each row's prompt and save Gemini's response directly to JSON file\n",
    "    \"\"\"\n",
    "    # Create/open the JSON file for writing\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\")  # Initialize empty file\n",
    "    \n",
    "    responses = []\n",
    "    \n",
    "    # Process each row\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            prompt = row['question_prompt']\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Processing {row['GICS Sub-Industry']}\")\n",
    "            \n",
    "            # Send prompt to Gemini\n",
    "            response = model.generate_content(prompt)\n",
    "            response_text = response.text\n",
    "            print('works')\n",
    "            print(response_text)\n",
    "            \n",
    "            # Append JSON response to file\n",
    "            with open(output_file, 'a', encoding='utf-8') as f:\n",
    "                f.write(response_text)\n",
    "                f.write('\\n\\n')  # Add vertical space between entries\n",
    "            \n",
    "            print(f\"\\nGemini Response saved to {output_file}\") \n",
    "            print(f\"{'='*50}\\n\")\n",
    "            \n",
    "            responses.append(response_text)\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error: {str(e)}\"\n",
    "            print(f\"Error processing row {row['GICS Sub-Industry']}: {str(e)}\")\n",
    "            time.sleep(60)\n",
    "            \n",
    "            # Also write errors to file\n",
    "            with open(output_file, 'a', encoding='utf-8') as f:\n",
    "                f.write(error_msg)\n",
    "                f.write('\\n\\n')\n",
    "            \n",
    "            responses.append(error_msg)\n",
    "    \n",
    "    # Still add responses to dataframe if needed\n",
    "    df['gemini_response'] = responses\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "df_processed = process_dataframe_with_gemini(sp_analysis, 'dcf.json')\n",
    "df_processed.to_csv('sp_analysis_with_responses.csv', index=False)\n",
    "print(\"Processing complete. Check 'my_gemini_responses.json' for all responses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d16554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>IncomeStatement - Revenues - TotalRevenues</th>\n",
       "      <th>IncomeStatement - CostsAndExpenses - Food,Beverage&amp;PackagingCosts(companyOperated)</th>\n",
       "      <th>IncomeStatement - CostsAndExpenses - Selling,GeneralAndAdministrativeExpense(sg&amp;a)</th>\n",
       "      <th>IncomeStatement - CostsAndExpenses - DepreciationAndAmortization</th>\n",
       "      <th>IncomeStatement - CostsAndExpenses - TotalOperatingExpenses</th>\n",
       "      <th>IncomeStatement - OperatingIncome - OperatingIncome(loss)</th>\n",
       "      <th>IncomeStatement - NonOperatingIncomeExpense - Income(loss)FromEquityMethodInvestments</th>\n",
       "      <th>IncomeStatement - NonOperatingIncomeExpense - OtherNonOperatingIncome(expense)</th>\n",
       "      <th>IncomeStatement - IncomeBeforeTax - IncomeBeforeIncomeTaxes</th>\n",
       "      <th>...</th>\n",
       "      <th>Liabilities - UnrecognizedTaxBenefits(noncurrent)</th>\n",
       "      <th>Liabilities - OtherNoncurrentLiabilities</th>\n",
       "      <th>Liabilities - TotalLiabilities</th>\n",
       "      <th>Equity - CommonStock</th>\n",
       "      <th>Equity - RetainedEarnings</th>\n",
       "      <th>Equity - AccumulatedOtherComprehensiveIncome(loss)</th>\n",
       "      <th>Equity - NoncontrollingInterest(equitySection)</th>\n",
       "      <th>Equity - Total Stockholders' Equity</th>\n",
       "      <th>Equity - Total Liabilities and Stockholders' Equity</th>\n",
       "      <th>gemini_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CY2007</td>\n",
       "      <td>1.043500e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.293000e+09</td>\n",
       "      <td>542000000.0</td>\n",
       "      <td>9.078000e+09</td>\n",
       "      <td>1.357000e+09</td>\n",
       "      <td>-51000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.139000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Error: Empty prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CY2008</td>\n",
       "      <td>1.130400e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.342000e+09</td>\n",
       "      <td>556000000.0</td>\n",
       "      <td>9.787000e+09</td>\n",
       "      <td>1.517000e+09</td>\n",
       "      <td>-41000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.291000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>296000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.621000e+09</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>3.030000e+08</td>\n",
       "      <td>-418000000.0</td>\n",
       "      <td>14000000.0</td>\n",
       "      <td>-1.080000e+08</td>\n",
       "      <td>6.527000e+09</td>\n",
       "      <td>Error: Empty prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CY2009</td>\n",
       "      <td>1.083600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.221000e+09</td>\n",
       "      <td>580000000.0</td>\n",
       "      <td>9.246000e+09</td>\n",
       "      <td>1.590000e+09</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.396000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>301000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.034000e+09</td>\n",
       "      <td>253000000.0</td>\n",
       "      <td>9.960000e+08</td>\n",
       "      <td>-224000000.0</td>\n",
       "      <td>89000000.0</td>\n",
       "      <td>1.025000e+09</td>\n",
       "      <td>7.148000e+09</td>\n",
       "      <td>Error: Empty prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CY2010</td>\n",
       "      <td>1.134300e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.277000e+09</td>\n",
       "      <td>589000000.0</td>\n",
       "      <td>9.574000e+09</td>\n",
       "      <td>1.769000e+09</td>\n",
       "      <td>42000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.594000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>308000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.647000e+09</td>\n",
       "      <td>86000000.0</td>\n",
       "      <td>1.717000e+09</td>\n",
       "      <td>-227000000.0</td>\n",
       "      <td>93000000.0</td>\n",
       "      <td>1.576000e+09</td>\n",
       "      <td>8.316000e+09</td>\n",
       "      <td>Error: Empty prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CY2011</td>\n",
       "      <td>1.262600e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.372000e+09</td>\n",
       "      <td>637000000.0</td>\n",
       "      <td>1.081100e+10</td>\n",
       "      <td>1.815000e+09</td>\n",
       "      <td>47000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.659000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>348000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.918000e+09</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>2.052000e+09</td>\n",
       "      <td>-247000000.0</td>\n",
       "      <td>93000000.0</td>\n",
       "      <td>1.823000e+09</td>\n",
       "      <td>8.834000e+09</td>\n",
       "      <td>Error: Empty prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CY2012</td>\n",
       "      <td>1.363300e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.510000e+09</td>\n",
       "      <td>665000000.0</td>\n",
       "      <td>1.133900e+10</td>\n",
       "      <td>2.294000e+09</td>\n",
       "      <td>47000000.0</td>\n",
       "      <td>115000000.0</td>\n",
       "      <td>2.145000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>309000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.701000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.286000e+09</td>\n",
       "      <td>-132000000.0</td>\n",
       "      <td>99000000.0</td>\n",
       "      <td>2.154000e+09</td>\n",
       "      <td>9.013000e+09</td>\n",
       "      <td>Error: Empty prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CY2013</td>\n",
       "      <td>1.308400e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.412000e+09</td>\n",
       "      <td>721000000.0</td>\n",
       "      <td>1.128600e+10</td>\n",
       "      <td>1.798000e+09</td>\n",
       "      <td>26000000.0</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>1.551000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>243000000.0</td>\n",
       "      <td>1.244000e+09</td>\n",
       "      <td>6.427000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.102000e+09</td>\n",
       "      <td>64000000.0</td>\n",
       "      <td>63000000.0</td>\n",
       "      <td>2.166000e+09</td>\n",
       "      <td>8.695000e+09</td>\n",
       "      <td>Error: Empty prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CY2014</td>\n",
       "      <td>1.327900e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.419000e+09</td>\n",
       "      <td>328000000.0</td>\n",
       "      <td>1.172200e+10</td>\n",
       "      <td>1.517000e+09</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>41000000.0</td>\n",
       "      <td>1.374000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>115000000.0</td>\n",
       "      <td>1.244000e+09</td>\n",
       "      <td>6.721000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.737000e+09</td>\n",
       "      <td>-190000000.0</td>\n",
       "      <td>57000000.0</td>\n",
       "      <td>1.547000e+09</td>\n",
       "      <td>8.334000e+09</td>\n",
       "      <td>Error: Empty prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CY2015</td>\n",
       "      <td>3.951000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.504000e+09</td>\n",
       "      <td>26000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.410000e+08</td>\n",
       "      <td>41000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.787000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>98000000.0</td>\n",
       "      <td>9.580000e+08</td>\n",
       "      <td>7.086000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.150000e+09</td>\n",
       "      <td>-239000000.0</td>\n",
       "      <td>58000000.0</td>\n",
       "      <td>9.110000e+08</td>\n",
       "      <td>8.061000e+09</td>\n",
       "      <td>Error: Empty prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CY2015</td>\n",
       "      <td>3.951000e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.504000e+09</td>\n",
       "      <td>26000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.410000e+08</td>\n",
       "      <td>41000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.787000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Error: Empty prompt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    frame  IncomeStatement - Revenues - TotalRevenues  \\\n",
       "0  CY2007                                1.043500e+10   \n",
       "1  CY2008                                1.130400e+10   \n",
       "2  CY2009                                1.083600e+10   \n",
       "3  CY2010                                1.134300e+10   \n",
       "4  CY2011                                1.262600e+10   \n",
       "5  CY2012                                1.363300e+10   \n",
       "6  CY2013                                1.308400e+10   \n",
       "7  CY2014                                1.327900e+10   \n",
       "8  CY2015                                3.951000e+09   \n",
       "9  CY2015                                3.951000e+09   \n",
       "\n",
       "   IncomeStatement - CostsAndExpenses - Food,Beverage&PackagingCosts(companyOperated)  \\\n",
       "0                                                                                 NaN   \n",
       "1                                                                                 NaN   \n",
       "2                                                                                 NaN   \n",
       "3                                                                                 NaN   \n",
       "4                                                                                 NaN   \n",
       "5                                                                                 NaN   \n",
       "6                                                                                 NaN   \n",
       "7                                                                                 NaN   \n",
       "8                                                                                 NaN   \n",
       "9                                                                                 NaN   \n",
       "\n",
       "   IncomeStatement - CostsAndExpenses - Selling,GeneralAndAdministrativeExpense(sg&a)  \\\n",
       "0                                                                        1.293000e+09   \n",
       "1                                                                        1.342000e+09   \n",
       "2                                                                        1.221000e+09   \n",
       "3                                                                        1.277000e+09   \n",
       "4                                                                        1.372000e+09   \n",
       "5                                                                        1.510000e+09   \n",
       "6                                                                        1.412000e+09   \n",
       "7                                                                        1.419000e+09   \n",
       "8                                                                        1.504000e+09   \n",
       "9                                                                        1.504000e+09   \n",
       "\n",
       "   IncomeStatement - CostsAndExpenses - DepreciationAndAmortization  \\\n",
       "0                                                       542000000.0   \n",
       "1                                                       556000000.0   \n",
       "2                                                       580000000.0   \n",
       "3                                                       589000000.0   \n",
       "4                                                       637000000.0   \n",
       "5                                                       665000000.0   \n",
       "6                                                       721000000.0   \n",
       "7                                                       328000000.0   \n",
       "8                                                        26000000.0   \n",
       "9                                                        26000000.0   \n",
       "\n",
       "   IncomeStatement - CostsAndExpenses - TotalOperatingExpenses  \\\n",
       "0                                                 9.078000e+09   \n",
       "1                                                 9.787000e+09   \n",
       "2                                                 9.246000e+09   \n",
       "3                                                 9.574000e+09   \n",
       "4                                                 1.081100e+10   \n",
       "5                                                 1.133900e+10   \n",
       "6                                                 1.128600e+10   \n",
       "7                                                 1.172200e+10   \n",
       "8                                                          NaN   \n",
       "9                                                          NaN   \n",
       "\n",
       "   IncomeStatement - OperatingIncome - OperatingIncome(loss)  \\\n",
       "0                                               1.357000e+09   \n",
       "1                                               1.517000e+09   \n",
       "2                                               1.590000e+09   \n",
       "3                                               1.769000e+09   \n",
       "4                                               1.815000e+09   \n",
       "5                                               2.294000e+09   \n",
       "6                                               1.798000e+09   \n",
       "7                                               1.517000e+09   \n",
       "8                                               4.410000e+08   \n",
       "9                                               4.410000e+08   \n",
       "\n",
       "   IncomeStatement - NonOperatingIncomeExpense - Income(loss)FromEquityMethodInvestments  \\\n",
       "0                                                                            -51000000.0   \n",
       "1                                                                            -41000000.0   \n",
       "2                                                                             36000000.0   \n",
       "3                                                                             42000000.0   \n",
       "4                                                                             47000000.0   \n",
       "5                                                                             47000000.0   \n",
       "6                                                                             26000000.0   \n",
       "7                                                                             30000000.0   \n",
       "8                                                                             41000000.0   \n",
       "9                                                                             41000000.0   \n",
       "\n",
       "   IncomeStatement - NonOperatingIncomeExpense - OtherNonOperatingIncome(expense)  \\\n",
       "0                                                                             NaN   \n",
       "1                                                                             NaN   \n",
       "2                                                                             NaN   \n",
       "3                                                                             NaN   \n",
       "4                                                                             NaN   \n",
       "5                                                                     115000000.0   \n",
       "6                                                                      16000000.0   \n",
       "7                                                                      41000000.0   \n",
       "8                                                                             NaN   \n",
       "9                                                                             NaN   \n",
       "\n",
       "   IncomeStatement - IncomeBeforeTax - IncomeBeforeIncomeTaxes  ...  \\\n",
       "0                                                          NaN  ...   \n",
       "1                                                 1.291000e+09  ...   \n",
       "2                                                 1.396000e+09  ...   \n",
       "3                                                 1.594000e+09  ...   \n",
       "4                                                 1.659000e+09  ...   \n",
       "5                                                 2.145000e+09  ...   \n",
       "6                                                 1.551000e+09  ...   \n",
       "7                                                 1.374000e+09  ...   \n",
       "8                                                 1.787000e+09  ...   \n",
       "9                                                 1.787000e+09  ...   \n",
       "\n",
       "   Liabilities - UnrecognizedTaxBenefits(noncurrent)  \\\n",
       "0                                                NaN   \n",
       "1                                        296000000.0   \n",
       "2                                        301000000.0   \n",
       "3                                        308000000.0   \n",
       "4                                        348000000.0   \n",
       "5                                        309000000.0   \n",
       "6                                        243000000.0   \n",
       "7                                        115000000.0   \n",
       "8                                         98000000.0   \n",
       "9                                                NaN   \n",
       "\n",
       "   Liabilities - OtherNoncurrentLiabilities  Liabilities - TotalLiabilities  \\\n",
       "0                                       NaN                             NaN   \n",
       "1                                       NaN                    6.621000e+09   \n",
       "2                                       NaN                    6.034000e+09   \n",
       "3                                       NaN                    6.647000e+09   \n",
       "4                                       NaN                    6.918000e+09   \n",
       "5                                       NaN                    6.701000e+09   \n",
       "6                              1.244000e+09                    6.427000e+09   \n",
       "7                              1.244000e+09                    6.721000e+09   \n",
       "8                              9.580000e+08                    7.086000e+09   \n",
       "9                                       NaN                             NaN   \n",
       "\n",
       "   Equity - CommonStock  Equity - RetainedEarnings  \\\n",
       "0                   NaN                        NaN   \n",
       "1             7000000.0               3.030000e+08   \n",
       "2           253000000.0               9.960000e+08   \n",
       "3            86000000.0               1.717000e+09   \n",
       "4            18000000.0               2.052000e+09   \n",
       "5                   0.0               2.286000e+09   \n",
       "6                   0.0               2.102000e+09   \n",
       "7                   0.0               1.737000e+09   \n",
       "8                   0.0               1.150000e+09   \n",
       "9                   NaN                        NaN   \n",
       "\n",
       "   Equity - AccumulatedOtherComprehensiveIncome(loss)  \\\n",
       "0                                                 NaN   \n",
       "1                                        -418000000.0   \n",
       "2                                        -224000000.0   \n",
       "3                                        -227000000.0   \n",
       "4                                        -247000000.0   \n",
       "5                                        -132000000.0   \n",
       "6                                          64000000.0   \n",
       "7                                        -190000000.0   \n",
       "8                                        -239000000.0   \n",
       "9                                                 NaN   \n",
       "\n",
       "   Equity - NoncontrollingInterest(equitySection)  \\\n",
       "0                                             NaN   \n",
       "1                                      14000000.0   \n",
       "2                                      89000000.0   \n",
       "3                                      93000000.0   \n",
       "4                                      93000000.0   \n",
       "5                                      99000000.0   \n",
       "6                                      63000000.0   \n",
       "7                                      57000000.0   \n",
       "8                                      58000000.0   \n",
       "9                                             NaN   \n",
       "\n",
       "   Equity - Total Stockholders' Equity  \\\n",
       "0                         1.139000e+09   \n",
       "1                        -1.080000e+08   \n",
       "2                         1.025000e+09   \n",
       "3                         1.576000e+09   \n",
       "4                         1.823000e+09   \n",
       "5                         2.154000e+09   \n",
       "6                         2.166000e+09   \n",
       "7                         1.547000e+09   \n",
       "8                         9.110000e+08   \n",
       "9                                  NaN   \n",
       "\n",
       "   Equity - Total Liabilities and Stockholders' Equity      gemini_response  \n",
       "0                                                  NaN  Error: Empty prompt  \n",
       "1                                         6.527000e+09  Error: Empty prompt  \n",
       "2                                         7.148000e+09  Error: Empty prompt  \n",
       "3                                         8.316000e+09  Error: Empty prompt  \n",
       "4                                         8.834000e+09  Error: Empty prompt  \n",
       "5                                         9.013000e+09  Error: Empty prompt  \n",
       "6                                         8.695000e+09  Error: Empty prompt  \n",
       "7                                         8.334000e+09  Error: Empty prompt  \n",
       "8                                         8.061000e+09  Error: Empty prompt  \n",
       "9                                                  NaN  Error: Empty prompt  \n",
       "\n",
       "[10 rows x 73 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_processed.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1be12",
   "metadata": {},
   "source": [
    "# Here the goal is to have a DCF model for any company\n",
    "We will have the framework which means the previous years numbers etc. so we can do an analysis to figure out the prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ecab2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709f3f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dcf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdcf\u001b[49m.head(\u001b[32m10\u001b[39m).T\n",
      "\u001b[31mNameError\u001b[39m: name 'dcf' is not defined"
     ]
    }
   ],
   "source": [
    "dcf.head(10).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
